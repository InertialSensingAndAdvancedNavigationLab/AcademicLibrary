1


# Pedestrian Inertial Navigation: An Overview of Model and Data-Driven Approaches

Itzik Klein



_**Abstract**_ **—The task of indoor positioning is fundamental to**
**several applications, including navigation, healthcare, location-**
**based services, and security. An emerging field is inertial nav-**
**igation for pedestrians, which relies only on inertial sensors**
**for positioning. In this paper, we present inertial pedestrian**
**navigation models and learning approaches. Among these, are**
**methods and algorithms for shoe-mounted inertial sensors and**
**pedestrian dead reckoning (PDR) with unconstrained inertial**
**sensors. We also address three categories of data-driven PDR**
**strategies: activity-assisted, hybrid approaches, and learning-**
**based frameworks.**


I. I NTRODUCTION


Indoor positioning is a fundamental task for various applications, including navigation, health-monitoring, location-based
services, and security. Because global navigation satellite
system (GNSS) signals are not available indoors, positioning
relies on other approaches such as WiFi [1]–[3] or other
radio frequency signals [4], visual positioning [5], floor plan
matching [6], and inertial sensing solutions [7], [8]. Of the
latter, several approaches exists, including inertial navigation
system (INS), shoe-mounted INS (SM-INS), and pedestrian
dead reckoning (PDR).
For indoor navigation, low-performance inertial sensors are
commonly used, for example, those installed in smartphones
and wearable devices. Therefore, without external updates,
the classical INS algorithm, which requires three integrations
on the measured inertial data, results in large positioning
errors. To overcome this limitation, inertial sensors can be
mounted on a shoe. To limit the inertial drift, zero velocity
updates and other methods of information aiding are used.
But for unconstrained inertial sensors, like in smartphones,
information aiding is not applicable, therefore approaches like
PDR are used, which require less integrations on the inertial
readings.
The present paper is focused on SM-INS and PDR approaches,
as shown in Figure 1. Section II presents the model-based PDR
framework and explains each part and its role in a common
PDR algorithm. Section III describes the SM-INS approach,
with all relevant algorithms, including INS, nonlinear filtering,
zero velocity detector, and information aiding. Section IV
lists three strategies for data-driven PDR, including activityassisted, hybrid, and learning-based. Finally, Section V summarizes the paper.


I. Klein heads the Autonomous Navigation and Sensor Fusion Lab, Hatter
Department of Marine Technologies, Charney School of Marine Science,
University of Haifa, Haifa 3498838, Israel (e-mail: kitzik@univ@haifa.ac.il).



Fig. 1: Shoe-mounted INS (left) requires solving the INS
equations and a nonlinear filter with information aiding. The
PDR framework (right) is applicable to unconstrained inertial
sensors, such as those in smartphones.


II. M ODEL -B ASED P EDESTRIAN D EAD R ECKONING


Inertial sensors, such as accelerometers and gyroscopes, are
required for using model-based PDR algorithms. Smartphones
or wearable devices with inertial sensors are commonly used
for this purpose. An exception is shoe-mounted inertial sensors
(discussed below in Section III).
Model-based PDR consists of four stages (Figure 2):


1) **Step detection** : The pedestrian steps are detected generally based on accelerometer readings.
2) **Step-length estimation** : Several approaches may be
used to estimate pedestrian step-length, including
regression-based, biomechanical models, and empirical
relationships.
3) **Heading determination** : The heading of the pedestrian
is estimated from the gyroscope and/or magnetometer
readings.
4) **Position update** : The current pedestrian position is
determined based on initial conditions, heading angle
(stage 3), and step-length size (stage 2).

As with any dead-reckoning method, the user’s initial position
must be known before undertaking the PDR cycle. Additionally, most step-length algorithms require a calibration phase to
determine their parameters. Finally, we note that most modelbased PDR approaches assume that the user is walking on
the same plane (floor), allowing only the estimation of the
pedestrian’s 2D position, excluding altitude.
In the following subsections, we elaborate on each stage in
the model-based PDR approach and provide frequently used
implementation methods.


_A. Step detection approaches_


Steps can be detected in several ways. Although some approaches have been derived for specific inertial sensor locations, with appropriate parameter tuning they can be applied


2


Finally, the standard deviation (STD) of the specific force
magnitude, after reducing its mean, is calculated by



_n_ 2
�( _f_ _m,k_ _−_ _f_ [¯] _mag_ ) [2]

_k_ =1 � [1]



2

(5)



_σ_ _f_ =



1

_n_
�



_n_
�



Fig. 2: Model-based PDR stages.


also for other inertial locations.

As noted in [9], step detection methods can be of four types:
peak detection, zero crossing, autocorrelation, and spectral
analysis. The peak detection method detects the maximum
peaks of the accelerometer signal to determine the user step
instances [10], [11]. In zero crossing detection, the zero
crossing of the accelerometer signal is monitored for step
detection [12], [13]. The cyclic nature of walking leads to
strong periodicity in inertial sensor readings. It is possible to
extract a cycle from a sequence of sensor data by looking
for maxima in the mean-adjusted autocorrelation of the data
over a period of time. Autocorrelation-based step detection
can be applied to accelerometer [14] or gyroscopes readings

[15]. Steps can also be detected in the frequency domain, for
example, by using Fourier [16] or wavelet transforms [17].
Of the methods mentioned above, peak detection is the most
popular. These approaches are typically based on the magnitude threshold of the specific force value and the minimum
step period. In this case, a step is defined as the interval
between two successive peaks. Moreover, because PDR is a
dead-reckoning approach, without external aiding, only short
time scenarios can be considered. Thus, the inertial frame (iframe) is defined at the user’s starting point. For simplicity,
we assume that the body frame (b-frame) coincides with the
sensitive axes of the inertial sensors.

To formulate the peak detection method, we denote the specific
force vector expressed in the body frame, **f** _ib_ _[b]_ [, as]


**f** _ib_ _[b]_ [= [] _[f]_ _[x]_ _[f]_ _[y]_ _[f]_ _[z]_ []] _[T]_ (1)


The magnitude of the specific force vector (1) at time _k_ is



_f_ _mag,k_ =
�



_f_ _x,k_ [2] [+] _[ f]_ _y,k_ [ 2] [+] _[ f]_ _z,k_ [ 2] (2)



The mean of the specific force magnitude throughout the
trajectory is defined by



Two parameters are needed to apply a basic peak detection
approach:


1) The minimum time interval between steps, defined empirically.
2) The minimum peak height, i.e., the minimum value
allowed for a valid peak. It is common practice to use
1 _._ 5 _σ_ _f_ as the minimum value.

We consider the following scenario to illustrate the peak
detection algorithm: The user walks holding a smartphone
in texting mode, that is,approximately waist-high. The user
makes 26 steps to cover a distance of 25 _._ 4 meters. The specific
force was measured by the smartphone accelerometers. Its
magnitude, calculated by (2), and magnitude mean value (4)
are shown in Figure 3. Next, the mean is subtracted as in (4)
and the STD is calculated by (5). Finally, the STD is multiplied
by a factor of 1 _._ 5 and the resulting value is adopted as the
minimum peak height. The minimum time interval between
steps was set to 0.3 seconds. Using these two parameters, a
simple maxima search is performed to find the user steps.
Figure 4 shows the specific force magnitude after subtracting


Fig. 3: Specific force magnitude as a function of time and its
average value. This recording was taken with a smartphone in
texting mode by a pedestrian walking for 25.4 meters.


its mean. The red circles show maxima values identified as
steps. The peak-detection algorithm manged to detect all 26
steps. Note, however, that such approaches are sensitive to user
dynamics (walking speed) and sensor location.


_B. Step-length estimation_


Pedestrian step-length can be estimated using several approaches, including regression-based, biomechanical models,
and empirical relationships. The underlying idea behind these



¯
_f_ _mag_ = [1]

_n_



_n_
� _f_ _mag,k_ (3)


_k_ =1



where _n_ is the number of samples. Next, The mean of the
specific force magnitude (4) is subtracted from the magnitude
of the specific force vector (2)


_f_ _m,k_ = _f_ _mag,k_ _−_ _f_ [¯] _mag_ (4)


Fig. 4: Identified user steps. This recording was taken with a
smartphone in texting mode by a pedestrian walking for 25.4

meters.


approaches is that a step can be detected based on accelerometer readings. Therefore, many approaches in the literature
attempt to establish a relationship between the specific force
exhibited during a step and the length of the step. In a recent
study, the use of smartphone inertial sensors for estimating
step-length was analyzed and compared with 13 representative
model-based step-length estimation models [18]. Lately, [19]
provided a survey of step-length from various perspectives,
including the research method used, the length of the test path,
various walking speeds, the location of the sensor device on
the user’s body, and the accuracy achieved in estimating steplength.
We consider three step-length approaches:


1) **SL1** : A constant step-length approach that assumes that
all steps during a walk have an equal length and are a
function of the user’s gender and height [20]


_s_ _c_ = _k_ _c_ _h_ [˙] (6)


where _s_ _c_ is the constant step-length, _h_ is the user height,
and _k_ _c_ is a gain equal to 0 _._ 415 for men and 0 _._ 413 for
women. As it is based solely on user height, this is one
of the simplest approaches to estimating step-length. Yet,
as a constant value approach, it fails to cope with varying
step-lengths.
2) **SL2** : The Weinberg [21] is a biomechanical approach,
based on the inverted pendulum model. Originally, it
relied on the difference between the maximum and

minimum vertical acceleration values during a step.
Later, it was shown to operate successfully using the
specific force magnitude instead [22]. Based on the
specific force magnitude, the Weinberg approach uses
the formula:


_s_ _w_ = _k_ _w_ ( _f_ _mag,max_ _−_ _f_ _mag,min_ ) [1] _[/]_ [4] (7)


where _k_ _w_ is the Weinberg gain, _s_ _w_ is the Weinbergbased step-length, _f_ _mag,max_ is the maximum value of



3


the specific force during the step interval, and _f_ _mag,min_
is the minimum value of the specific force during the
step interval. Before using the approach, a calibration
procedure, with the user walking a certain distance,
should be applied to determine the gain, _s_ _w_ . Taking
the sum operator on both sides of (7) along the trajectory, allows determining the gain because the sum of
the step-lengths is the known travelled distance. Thus,
Weinberg’s approach relies on a single empirical gain,
which must be calibrated before its use.

3) **SL3** : Adaptive step-length estimation. The step-length
of a pedestrian is not constant and varies with walking
speed, step frequency, acceleration variance, and other
parameters. To increase accuracy in estimating walking distances, adaptive step-length estimation algorithms
have been proposed. Of these, in [23], the step-length
is a function of step frequency and the variance of the
specific force during the step, as given by:


_s_ _a_ = _k_ _a,_ 1 _· SF_ + _k_ _a,_ 2 _· σ_ _f_ + _k_ _a,_ 3 (8)


where SF is the step frequency defined as the inverse
of the time duration of the step, _σ_ _f_ is the specific force
variance (5), and _k_ _a,_ 1 _−_ _k_ _a,_ 3 are predefined empirical
gains. As in the Weinberg approach, the determination
of the empirical gains requires a calibration procedure.


Returning to our numeric example from Section II-B, we
tested the three step-length approaches: SL1-SL3. For SL1, the
walking user was a 190 cm-tall male. Calibration procedures
with the same user were carried out to obtain the gains of
approaches SL2 and SL3. The estimated distances of the three
approaches are shown in Figure 5. Although the user walked
at a constant pace to make sure that his steps were equal,
the constant-length approach, SL1, performed worse than the
adaptive approaches. SL2 and SL3 obtained a distance error
of less than 2% of the travelled distance.

Figure 6 shows the the lengths of each of the 26 steps made


Fig. 5: Estimated user distance of the three step-length approaches. The recording was obtained with a smartphone in
texting mode by a pedestrian walking for 25.4 meters.


during the trajectory. In SL1, a constant step-length of 79cm
was obtained. In both SL2 and SL3, the average step-length
was 99cm, reflecting the actual step-length.
Step-length approaches are sensitive to user characteristics


Fig. 6: Lengths of each of the 26 steps made during the
trajectory. This recording was taken with a smartphone in
texting mode by a pedestrian walking for 25.4 meters.


(like height and weight), inertial sensors location, and walking
speeds.


_C. Heading and walking direction_


To estimate the pedestrian’s trajectory, it is necessary to
estimate the walking direction and heading. In some cases, the
direction of walking does not coincide with the direction of
the inertial sensor’s sensitive axis. For example, when using
the smartphone, the user may point it with an offset to the
walking direction, as illustrated in Figure 7. The figure shows


Fig. 7: Heading geometry defined relative to the starting point
of the trajectory. The figure shows the offset angle between
the smartphone inertial sensors (red) and the user’s walking
direction (blue).



4


the heading geometry defined relative to the starting point of
the trajectory. From the geometry we define:


_ψ_ _u_ = _ψ_ _p_ _−_ _ψ_ _s_ (9)


where _ψ_ _u_ is the user’s heading (walking direction), _ψ_ _p_ is
the heading angle of the smartphone (or any other inertial
sensor), and _ψ_ _s_, is the sliding (offset) angle between the
smartphone and the user. Equation (9) represents a general
walking scenario. To better illustrate the difference, consider
the scenario shown in Figure 8, where a user holding a
smartphone starts walking while the smartphone is aligned to
the walking direction (segment A). During the walking, the
user maintains the same direction but changes the smartphone
direction by 45 _[◦]_, as shown in segment B. Next, simultaneously,
the user changes walking direction by 45 _[◦]_ and smartphone
direction by 90 _[◦]_, aligning the two, as shown in segment C.
Finally, in segment D, the user rotates the phone by 45 _[◦]_

relative to the walking direction. The user trajectory and both
smartphone and user heading angles are illustrated in Figure 8.
Two spacial cases may occur: (a) the inertial sensors are


Fig. 8: A user walks holding the smartphone at different angles
relative to the walking direction. The lower part of the figure
shows the user trajectory and the upper part the heading angles
of the user and smartphone across the trajectory.


held in the same direction as the walking direction, satisfying
_ψ_ _s_ ( _t_ ) = 0 _, ∀t_, for example, a user walking and holding
the smartphone in texting mode; (b) the inertial sensors are
rigidly mounted to the user, resulting in a constant offset angle
_ψ_ _s_ ( _t_ ) = _ψ_ _s,c_ _, ∀t_ .
One of the most commonly used methods for estimating the
heading of smartphones, _ψ_ _p_, is based on fusing data from
accelerometers, magnetometers, and gyroscopes in an attitude
and heading reference system (AHRS) framework. There are
many types of AHRS approaches, including the Kalman filter [24], [25], nonlinear estimation [26], [27], complementary
filtering [28]–[30], and hybrid-learning approaches [31]–[33].
Regardless of the AHRS algorithm choice, they all rely on
the kinematic equations of the gyroscope. Following [8], we


provide a simplified description of these equations, assuming
initial zero roll and pitch angles, and that the x-axis of the
smartphone is aligned with the walking direction, resulting
in an initial zero heading. This corresponds to an initial
quaternion of **q** 0 _∈_ R [4] :


**q** 0 = 1 + 0 **i** + 0 **j** + 0 **k** (10)


where 1, **i** _,_ **j** _,_ **k** are the quaternion basis elements.
Given the gyroscope’s measurement, [ _ω_ _x_ _ω_ _y_ _ω_ _z_ ] _[T]_, the kinematic equation for the quaternion (its rate of change in time)
is











(11)




= _x_ _k−_ 1 + _s_ _k_ cos( _ψ_ _u,k_ )
� � _y_ _k−_ 1 + _s_ _k_ sin( _ψ_ _u,k_ )



˙
_q_ = [1]

2









_−q_ 2 _−q_ 3 _−q_ 4

_q_ 1 _q_ 4 _−q_ 3

_−q_ 4 _q_ 1 _q_ 2

_q_ 3 _−q_ 2 _−q_ 1



_ω_ _x_

 _ω_ _y_

 _ω_ _z_



(17)
�



Given ˙ _q_ and the previous quaternion, the current quaternion
can be calculated to construct the transformation matrix from
the reference frame to the body frame:









5


The (14)-(16) approach for finding the change in the user’s
walking direction is valid assuming that the angular velocity
is constant during the time interval ∆ _t_, which holds for most
gyroscopes sampling at a high-rate. Notice further that to filter
out the user acceleration using a low-pass filter, the user should
be walking. In transient walking motion, as at the beginning
or end of walking, we expect a degradation in filtering quality,
leading to large heading errors.


_D. Two-dimensional positioning_


Given the estimated step size, _s_, and the user’s walking
direction angle, _ψ_ _u_, the two-dimensional PDR user position
vector is:

_x_ _k_ = _x_ _k−_ 1 + _s_ _k_ cos( _ψ_ _u,k_ )

(17)

� _y_ _k_ � � _y_ _k−_ 1 + _s_ _k_ sin( _ψ_ _u,k_ ) �


where _x_ and _y_ are the two-dimensional position components
and _k_ is the current epoch.
Algorithm 1 summarizes the two-dimensional model-based
PDR method.


**Algorithm 1:** Two-dimensional model-based PDR

**Input: f** _[b]_ _,_ _**ω**_ _[b]_ _, x_ _k−_ 1 _, y_ _k−_ 1 _, s_ _k_ _, ψ_ _u,k_ _, ψ_ _s,k_ _, ψ_ _p,k_

**1** **Step detection: f** _[b]_ and (1)-(5) ;

**2** **step-length estimation: f** _[b]_ and one approach out of
(6), (7), or (8) ;

**3** **Heading determination: if** _ψ_ _s,k_ = 0 **then**

**4** _**ω**_ _[b]_ and (11)-(13) such that _ψ_ _u,k_ = _ψ_ _p,k_ ;

**5** **else**

**6** **f** _[b]_ and (14)-(16);


**7** **Two-dimensional positioning:** _x_ _k−_ 1 _, y_ _k−_ 1 _, s_ _k_ _, ψ_ _u,k_
and (17) ;
**Output:** _x_ _k_ _, y_ _k_


_E. Three-dimensional PDR_


Most PDR approaches assume that the user walks in the
same plane, without vertical movement. Yet, in typical walking
environments vertical movement is required, for example,
when using staircases, elevators, or escalators. A typical solution for solving the altitude problem is to use a barometer
to determine the change in altitude, as applied in [41], [42].
Given a barometer, the 3D PDR algorithm, for each sensor
role, is presented in Figure 9. Yet, as pointed out in [43],


Fig. 9: Model-based 3D PDR using a barometer for altitude
estimation.


not all smartphones or wearable devices have a barometer. In



**T** _[b]_ _r_ [=]



_q_ 1 [2] [+] _[ q]_ 2 [2] _[−]_ _[q]_ 3 [2] _[−]_ _[q]_ 4 [2] 2( _q_ 2 _q_ 3 _−_ _q_ 1 _q_ 4 ) 2( _q_ 1 _q_ 3 + _q_ 2 _q_ 4 )



2( _q_ 2 _q_ 3 + _q_ 1 _q_ 4 ) _q_ 1 [2] _[−]_ _[q]_ 2 [2] [+] _[ q]_ 3 [2] _[−]_ _[q]_ 4 [2] 2( _q_ 3 _q_ 4 _−_ _q_ 1 _q_ 2 )
 2( _q_ 2 _q_ 4 _−_ _q_ 1 _q_ 3 ) 2( _q_ 1 _q_ 2 + _q_ 3 _q_ 4 ) _q_ 1 [2] _[−]_ _[q]_ 2 [2] _[−]_ _[q]_ 3 [2] [+] _[ q]_ 4 [2]



(12)
Using (12), the smartphone heading is calculated by


_ψ_ _p_ = _atan_ 2 �2( _q_ 2 _q_ 3 _−_ _q_ 1 _q_ 4 ) _,_ 1 _−_ 2( _q_ 3 [2] [+] _[ q]_ 4 [2] [)] � (13)


As noted, using (13) for the estimation of the user’s walking
direction is valid only when the smartphone is aligned with
the user’s walking path so that _ψ_ _s_ = 0 and thus _ψ_ _u_ = _ψ_ _p_ .
If this is not the case, other approaches to estimate the user’s
walking direction are needed. The walking direction may be
extracted from acceleration measurements using a kinematic
“rolling-foot” model [34], by principle component analysis of
the accelerometer readings [35], or using gravity-based [36],

[37] and deep learning approaches [38], [39].
Here, we describe a simple yet efficient gravity-based approach for estimating the user’s walking direction. First, the
gravity direction vector is obtained and the angular velocity is
projected to obtain its vertical component, which is integrated
to find the walking direction. As stated in [40], to reduce
or eliminate the large temporal variations typically associated
with the acceleration of a pedestrian in motion, it is necessary
to apply low-pass filtering to each axis of the force vector.
Then, the gravity vector direction is given by

_**γ**_ _g_ = _||_ _[−]_ **f** _LP F_ **[f]** _[LP F]_ _||_ (14)


where _γ_ _g_ is the gravity direction vector and **f** _LP F_ is the filtered
specific force vector in the sensor frame.
Denoting the vertical projection of the gyroscope reading
by _ω_ _v_ and the measured angular velocity by _**ω**_, it can be
calculated at any instance of time by


_ω_ _v_ = _**γ**_ _[T]_ _g_ _**[ω]**_ (15)


As _ω_ _v_ measures the pedestrian’s turning rate in the horizontal
plane, an approximation for the change in the walking direction during the time interval ∆ _t_ is


∆ _ψ_ _u_ = _ω_ _v_ ∆ _t_ (16)


these cases, the altitude can be estimated using accelerometer
measurements. In [44], a modified Weinberg approach was
suggested to estimate the user’s steps during movement on a
staircase and a calibration phase is required to estimate the
Weinberg gain. A later study, [43], proposed estimating the
change in height by identifying peaks in the motion of the
user during movement on a staircase in the course of which
the user is changing position. This approach does not require
prior calibration.


III. S HOE -M OUNTED INS


In SM-INS (or foot-mounted) devices, the inertial sensors
are rigidly mounted on a shoe [45], [46], so that zero velocity events are identified and information aiding can be
applied to mitigate the inertial drift [47]. Therefore, instead
of experiencing a velocity drift caused by a strapdown INS
mechanism, a shoe-mounted INS produces a saw-tooth like
velocity error behaviour. Figure 10 illustrates this assuming
ideal initial conditions and only accelerometer bias. In this


Fig. 10: Illustration of the INS velocity solution drift (without
aiding) and the shoe-mounted INS with information aiding
during zero velocity instances.


example, every one-second stationary condition is identified
and information aiding is applied to nullify velocity drift. In
practice, the same velocity error behavior is observed even
when taking into account all accelerometer and gyroscope

errors.

The shoe-mounted INS framework, using an extended Kalman
filter (EKF), is illustrated in Figure 11. Note that any other
nonlinear filter can be applied instead. The INS navigation
solution is produced in accordance with the inertial conditions
and inertial readings. The inertial measurements, together with
the INS solution, are used in the EKF prediction phase. Next,
an algorithm to detect zero velocity instances is applied. If
such instances are detected, information aiding is used in the
EKF update phase to produce a corrected navigation solution.
Otherwise, the INS solution is not corrected by the filter. We
examine each component of the shoe-mounted INS in detail
below.



6


Fig. 11: Shoe-mounted INS framework.


_A. Inertial Navigation_

The INS equations of motion are a set of first order differential
equations. Given initial conditions and inertial measurements,
they can be solved to give the navigation solution, namely the
position, velocity, and orientation. These equations are valid
for any platform, regardless of its operating environment [7].
In shoe-mounted INS, however, some simplification is applied,
reducing the complexity of the INS equations of motion.
Generally, low-performance inertial sensors are used in shoemounted INS, therefore, angular velocity vector of the earth
can be neglected. The transport rate is also neglected because
the user velocity is relatively low. Last, it is assumed that the
body frame coincides with the inertial sensor frame located on
the shoe, as illustrated in Figure 12. Taking those assumptions


Fig. 12: Reference frames associated with a typical shoemounted INS scenario.


into account, the continuous form of the INS equation of
motion is:

˙
**v** _[r]_ = **T** _[b]_ _r_ **[f]** _[b]_ _ib_ [+] **[ g]** _[r]_ (18)


where ˙ **v** _[r]_ is the velocity vector expressed in the reference
frame, **f** _[b]_ _ib_ [is the specific force vector expressed in the body]
frame, **T** _[b]_ _r_ [is the reference to body transformation matrix]
defined in (12), and **g** _[r]_ is the local gravity vector defined by:


**g** _[r]_ = [0 _,_ 0 _, g_ ] _[T]_ (19)


where _g_ is the local gravity, assumed constant during the
motion.
The position rate of change, ˙ **p** _[r]_, is the integration on the
velocity vector:

˙
**p** _[r]_ = **v** _[r]_ (20)


Last, the transformation matrix rate of change is


˙ _b_
**T** _r_ [=] **[ T]** _[b]_ _r_ _**[ω]**_ _[b]_ _ib_ (21)


where _ω_ _ib_ _[b]_ [is the measured gyroscope angular velocity vector.]
Given inertial conditions, the INS equations of motion, (18),
(20), and (21) are integrated to obtain the navigation solution.
The choice of the numeric integration algorithms is a tradeoff between precision and processing capability. For a detailed
discussion of this topic, refer to [7], [48]. In SM-INS, the Pad´e
approximation is regularly used to propagate the transformation matrix [49], [50]:


**T** _[b]_ _r,k_ [=] **[ T]** _[b]_ _r,k−_ 1 [(2] **[I]** [3] [+] **[ Ω]** _[k]_ [∆] _[t]_ [) (2] **[I]** [3] _[−]_ **[Ω]** _[k]_ [∆] _[t]_ [)] _[−]_ [1] (22)


where ∆ _t_ is the time-step, _k_ is the current epoch, and **Ω** _k_ is
the skew symmetric of the measured angular velocity



7


An error-state EKF implementation is used with an error-state

vector


_δ_ **x** = � _δ_ **p** _r_ _δ_ **v** _[r]_ _ϵ_ _[r]_ **b** _a_ **b** _g_ � T _∈_ R 15 (30)


where _δ_ **p** _[r]_ is the position error-state vector, _δ_ **v** _[r]_ is the velocity
error-state vector, and _**ϵ**_ _[r]_ is misalignment error-state.
The linearized error-state model is [48]


_δ_ ˙ **x** = **F** _δ_ **x** + **Gw** (31)


where **F** is the system matrix, **G** is the shaping matrix, and
_δ_ **w** is the noise vector. The residuals of the accelerometers

and gyros are modeled as random walk processes although
any other suitable models may be used instead, such as the
first-order Gauss-Markov process. The system matrix is given
by






_._ (32)




**F** =









**0** 3 _×_ 3 **I** 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3
**F** _vp_ **0** 3 _×_ 3 **F** _vϵ_ **T** _[n]_ _b_ **0** 3 _×_ 3
**0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **T** _[n]_ _b_
**0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3
**0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3



where _F_ _ij_ are 3 _×_ 3 submatrices obtained from the linearization
of the nonlinear equation of motion (more details on the
internalization process can be found in navigation textbooks
such as [8], [48]). The shaping matrix is given by





(23)







(33)




**Ω** _k_ =



0 _−ω_ _z,k_ _ω_ _y,k_

 _ω_ _z,k_ 0 _−ω_ _x,k_

 _−ω_ _y,k_ _ω_ _x,k_ 0



**G** =









**0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3
**T** _[n]_ _b_ **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3
**0** 3 _×_ 3 **T** _[n]_ _b_ **0** 3 _×_ 3 **0** 3 _×_ 3
**0** 3 _×_ 3 **0** 3 _×_ 3 **I** 3 **0** 3 _×_ 3
**0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **I** 3



The velocity is updated using the Euler method:


**v** _[r]_ _k_ [=] **[ v]** _[r]_ _k−_ 1 [+ ∆] _[t]_ **[v]** [˙] _[r]_ (24)


where ˙ **v** _[r]_ is defined in (18). Similarly, the position update is
given by:
**p** _[r]_ _k_ [=] **[ p]** _[r]_ _k−_ 1 [+ ∆] _[t]_ **[p]** [˙] _[r]_ (25)


where ˙ **p** _[r]_ is defined in (20).


_B. Navigation Filter_


The nonlinear nature of the INS equations of motion necessitates a nonlinear filter when INS is fused with external sensors
or information, as in SM-INS. Before designing the filter, we
define the inertial sensor measurement error model as:


˜ _b_
_**f**_ _ib_ [=] _**[ f]**_ _[ b]_ _ib_ [+] **[ b]** _[a]_ [+] **[ w]** _[a]_ (26)

_**ω**_ ˜ _[b]_ _ib_ [=] _**[ ω]**_ _[b]_ _ib_ [+] **[ b]** _[g]_ [+] **[ w]** _[g]_ (27)


where **w** _a_ and **w** _g_ are the zero mean white Gaussian noise of
the accelerometer and gyroscope measurement, respectively,
and the sensor biases are modeled as random walk processes


**b** ˙ _a_ = **w** _ab_ (28)
**b** ˙ _g_ = **w** _gb_ (29)


where **b** _a_ is the accelerometer bias, **b** _g_ is the gyroscope bias,
and **w** _ab_ and **w** _gb_ are the zero mean white Gaussian noise of
the accelerometer and gyroscope bias modeling, respectively.



and the noise vector is


T
**w** = � **w** _a_ **w** _g_ **w** _ab_ **w** _ab_ � (34)


The implementation algorithm for the prediction phase of the
EKF error-state closed loop is


ˆ
_δ_ **x** _[−]_ _k_ = 0 (35)

**P** _[−]_ _k_ = **Φ** _k−_ 1 **P** [+] _k−_ 1 **[Φ]** _k_ [T] _−_ 1 [+] **[ Q]** _[k][−]_ [1] (36)


where _δ_ **x** _[−]_ _k_ [is the] _[ a priori]_ [ estimate of the error-state,] **[ P]** _[−]_ _k_
is the covariance of the _a priori estimation error_, **Φ** _k_ is the
state transition matrix, and **Q** _k_ is the process noise covariance
assumed to be constant throughout the trajectory.
The EKF update phase is:


ˆ
_δ_ **x** [+] _k_ = **K** _k_ _δ_ **z** _k_ (37)

**P** [+] _k_ = [ **I** _−_ **K** _k_ **H** _k_ ] **P** _[−]_ _k_ (38)

**K** _k_ = **P** _[−]_ _k_ **[H]** _k_ [T] [[] **[H]** _[k]_ **[P]** _[−]_ _k_ **[H]** _k_ [T] [+] **[ R]** _[k]_ []] _[−]_ [1] (39)


where _δ_ **x** [+] _k_ [is the] _[ a posteriori]_ [ estimate of the error-state,] **[ P]** [+] _k_
is the covariance of the _a posteriori_ estimation error, _δ_ **z** _k_ is
the measurement residual vector, **K** _k_ is the Kalman gain, **R** _k_
is the measurement noise covariance assumed to be constant

for all samples, and **H** _k_ is the measurement matrix.


_C. Zero Velocity Detectors_


The function of zero velocity detectors (ZVD) in SM-INS is
to determine whether information aiding can be applied at
the filter update stage (37)-(39). In a recent review of ZVD,
Wahlstr¨om and Skog [51] recount the history of foot-mounted
inertial navigation, characterize the main sources of error, and
analyze current approaches to robust ZVD. These methods
include heuristic approaches, adaptive thresholding, gait cycle
segmentation, other model-based approaches, as well as datadriven methods.

There exist several heuristic ZVD that rely on different inertial
features, such as the acceleration variance or magnitude, the
angular rate energy detector, and the stance hypothesis optimal
detection (SHOE) detector. As pointed out in [52], ZVD can
be formulated as a likelihood ratio check. To this end, let _H_ 0
denote a hypothesis that the inertial sensor unit is moving and
_H_ 1 a hypotheses that the inertial sensor unit is stationary. Note
that stationary conditions occur during walking in the _stance_
phase or while standing still. The likelihood-ratio test based
on inertial measurements, **z** _j_, decides on hypothesis _H_ 1 if and
only if

[(] **[z]** _[j]_ _[|][H]_ [1] [)]
_L_ ( **z** _j_ ) = _[p]_ (40)

_p_ ( **z** _j_ _|H_ 0 ) _[> γ]_


_j_ + _w_ _f_
where _γ_ is some user-defined threshold and **z** _j_ ) = _m_ _nj−w_ _b_
with _w_ _f_ and _w_ _b_ as the forward and backward window length
applied to the required set of measurements.
A multi-condition bringing together both accelerometer and
gyroscope measurements was proposed in [50]. It includes
three conditions for declaring a foot to be stationary:


1) **Acceleration magnitude** . Although referred to as acceleration, this is actually a condition concerning the
_specific force_ magnitude defined by:


1 _γ_ _fmag,min_ _<_ **f** _mag,k_ _< γ_ _fmag,max_
C1 = (41)
0 otherwise
�


where **f** _mag,k_ is defined in (2), and _γ_ _fmag,min_ and
_γ_ _fmag,max_ are the minimum and maximum threshold
values, respectively.
2) **Local acceleration variance** . Defines the foot activity

as



8


Detection of a stationary foot requires that all three logical
conditions be satisfied simultaneously, so a logical ”AND”
is applied, and the result is filtered out with a neighboring
window median filter.
Rather than use heuristic or other model-based approaches for
ZVD, several papers have recently explored the possibility of
using machine learning approaches to identify zero velocity
instances. For example, [53] used support vector machines and

[54] a long short-term memory (LSTM) neural network.


_D. Information Aiding_


Once a zero velocity instance is detected, information aiding
can be applied in the EKF update phase (37)-(39). Mostly,
two types of information aiding are used in SM-INS: (1) zero
velocity update (ZVU) and (2) zero angular rate (ZAR) [47].


1) **Zero velocity update**
The principle of this aiding states that while in stationary
conditions, the velocity vector in the reference frame is
zero. The ZUV measurement residual is given by:


_δ_ **z** **ZVU** = **v** _[r]_ INS _[−]_ **[0]** [3] _[×]_ [1] [ =] **[ H]** **[ZVU]** _[δ]_ **[x]** [ +] _**[ ν]**_ **[ZVU]** (46)


where **v** _[r]_ INS [is the calculated INS velocity vector (24) and]
_**ν**_ **ZVU** is zero mean white Gaussian measurement noise.
The corresponding measurement matrix is defined by:


**H** **ZVU** = � **0** 3 _×_ 3 **I** 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 � _._ (47)


2) **Zero angular rate**
Similarly to ZVU, while in stationary conditions, the
angular velocity vector in the reference frame is zero.
The ZAR measurement residual is given by:


_δ_ **z** **ZAR** = _**ω**_ _[b]_ _ib,_ INS _[−]_ **[0]** [3] _[×]_ [1] [=] **[ H]** **ZAR** _[δ]_ **[x]** [ +] _**[ ν]**_ **ZAR** [=] **[ b]** _[g]_ [+] _**[ ν]**_ **ZAR**
(48)
where _**ω**_ _[b]_ _ib,_ INS [is the measured INS angular rate vector,]
_**ν**_ **ZAR** is zero mean white Gaussian measurement noise,
and **b** _g_ is the gyroscope bias vector expressed in the
body frame. The corresponding measurement matrix is
defined by:


**H** **ZAR** = � **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **0** 3 _×_ 3 **I** 3 � _._ (49)


_E. Summary and Analytical Assessment_


Algorithm 2 summarizes the SM-INS approach. The output of
the algorithm is the updated error-state vector used to correct
the INS solution and inertial sensor errors.

Next, we provide a simplified analytical assessment comparing
the distance errors of the INS solution, model-based PDR, and
SM-INS. For this, we assume that only an accelerometer bias
of _b_ _a_ = 5mg is present in the system. For short time periods,
the INS position error is approximated by [7]:

_δp_ INS = [1] (50)

2 _[b]_ _[a]_ _[t]_ [2]


where _t_ is the time.

To assess the distance error of model-based PDR, we follow

[55], which proposes the MoRPI framework, a horizontal
PDR-like approach for mobile robots. It was shown that the



1
_σ_ _f_ [2] [=] 2 _w_ + 1



_j_ = _k_ + _w_
� ( **f** _mag,k_ _−_ [¯] **f** _mag_ ) [2] (42)

_j_ = _k−w_



where _w_ is the window size and [¯] **f** _mag_ is defined in (4).
The second condition is satisfied when

C2 = 1 _σ_ _f_ [2] _[> γ]_ _[σ]_ _f_ (43)
0 otherwise
�


where _γ_ _σ_ _f_ is the local acceleration variance value.
3) **Angular velocity magnitude** . This condition requires
that the angular velocity magnitude

_**ω**_ _mag,k_ = ~~�~~ _ω_ _x,k_ [2] [+] _[ ω]_ _y,k_ [2] [+] _[ ω]_ _z,k_ [2] (44)


must be below a given threshold _γ_ _σ_ _ω_

C3 = 1 _σ_ _f_ [2] _[> γ]_ _[σ]_ _ω_ (45)
0 otherwise
�


**Algorithm 2:** Shoe-mounted INS Algorithm

**1** **Raw data Input: f** _[b]_ _,_ _**ω**_ _[b]_

**2** **INS initial conditions Input: p** _k_ _,_ **v** _k_ _,_ **T** _[r]_ _b,k_
**3** **EKF Input: P** _k_ _,_ **Q** _,_ **F** _,_ **G** _, δ_ **x** _k_

**4** **Information aiding Input: R** _,_ **H** _, δ_ **z** _k_

**5** **Zero velocity detectors Input:** _γ_

**6** **INS:** Propagate INS equations of motion (22)-(25)
given initial conditions and inertial sensor readings;

**7** **EKF Prediction:** Given initial covariances, apply
(35)-(36) ;

**8** **Zero velocity condition:** Employ three logical
conditions (41)-(45). **if** _stationary condition holds_
**then**


**9** **EKF update** : Update phase (37)-(39) using
information aiding (46)-(49)


**10** ; **Output: P** _k_ +1 _, δ_ **x** _k_ +1


position error using the Weinberg step-length approach (7) is
the sum of all peak-to-peak distance errors



9


Fig. 13: Analytical assessment of the distance errors achieved
by the INS, model-based PDR, and SM-INS.


_•_ **Hybrid PDR approaches** : The heading angle or steplength are regressed by a data-driven approach while the
other by using a model-based method.

_•_ **Learning-based PDR** : Rather than being based on models, PDR positioning relies only on learning methods to
perform the positioning task.
The above-mentioned categories as well as the model-based
PDR are illustrated in Figure 14. In the next section, a brief
introduction to neural networks (NN) provides basic concepts
for those who are unfamiliar with them.


Fig. 14: Illustration of model-based PDR and three types of
learning-based PDR approaches.



_δp_ PDR =



_N_
� ∆ _k_ _w_ ∆ _f_ _j_ (51)

_j_ =1



where _N_ is the number of steps, ∆ _k_ _w_ is the error in the
Weinberg gain, and ∆ _f_ _j_ is


∆ _f_ _j_ = ( _f_ _mag,max_ _−_ _f_ _mag,min_ ) [1] _[/]_ [4] (52)


For this example, we set ∆ _k_ _w_ = 5%.
To produce the SM-INS distance error, the error was propagated using (51) during the filter prediction phase, and
when zero velocity was detected, it was assumed that the
filer manages to correct 90% of the existing drift. In the
examined scenario, stationary conditions were detected every
one second.

Figure 13 shows the distance error of the approaches for a
duration of 30 seconds. Because of the inertial measurement

errors and the dead-reckoning nature, the distance solution
of all three approaches drift, although at different rates. The
INS reaches a distance error of 22 _._ 5m; the model-based PDR
obtains a distance error of 3m; and the SM-INS performs best,
achieving a distance error of 0 _._ 75m. This error represents an
improvement of 75% over the model-based PDR approach.
In real world scenarios, this improvement may be higher,
depending on several factors, including the walking duration.


IV. D ATA -D RIVEN P EDESTRIAN D EAD R ECKONING


Both machine learning and deep learning approaches learn
from data, therefore they are referred to also as data-driven
approaches. These approaches are used in a variety of navigation tasks [56]–[59], including PDR [60], as described below.
Data-driven PDR can be categorized into three types:


_•_ **Activity-assisted PDR** : Data-driven approaches are used
to classify the user motion and inertial sensor location.
This information is used within the model-based PDR

algorithm.



_A. A Brief Introduction to Neural Networks_

A typical NN consist of three types of layers: _input layer_,
holding the initial data for the entire network, _output layer_,
producing the result of the network, and _hidden layer_, referring
to all intermediate layers between the input and output layers.
The output of the network is refereed to as the predicted
value, which is compared to the true value. To this end,
a loss function (cost function) is chosen to measure the
difference between predicted and true values. Thus, the loss
function is used as a criterion in the optimization process
for obtaining undated network parameters. The optimization
process is applied until the loss value is lower than a predefined
threshold. A cycle of this process is illustrated in Figure 15.
From a mathematical point of view, the j-th hidden layer **h** _j_
is defined as



**h** _j_ = _a_



_m_
�
� _i_ =0



_x_ _i_ _× w_ _i_

_i_ =0



�



(53)


Fig. 15: A single cycle of the NN optimization process in its
training phase.


where _a_ is a nonlinear activation function, _x_ _i_ is the _i_,
_i_ = 0 _. . . m_, input to the layer, and _w_ _i_ are the corresponding
weights. The input layer **l** in _∈_ R _[n][×][k]_ contains the input data of
dimension _n_ to the network, where _k_ stands for the sequence
length. For example, using the specific force vector for a
sequence of 30 samples gives _n_ = 3 and _k_ = 30. The
output layer, **l** out _∈_ R _[p]_, gives the output with dimension _p_ .
The complete network, **n**, is represented using a composition
of functions, where each function is a layer in the network:


**n** = **l** in _◦_ **h** 1 _· · · ◦_ **h** _f_ _◦_ **l** out (54)


where **h** _f_ is the last hidden layer in the network. Note that the
network performed the following mapping:


**n** : R _[n][×][k]_ _→_ R _[p]_ (55)


A detailed explanation of NN can be found in [61], [62] and

[63].


_B. Activity-Assisted PDR_


One of the critical phases in model-based PDR is the steplength estimation. As addressed in Section II-B, commonly,
an empirical gain is required to estimate the step-length. This
gain was found to be sensitive to the user activity mode
(walking normally/slow/fast, standing, running) [64] and to the
smartphone activity, which implies the location of the inertial
sensors [65]. For example, when using the smartphone sensors,
the location could be texting, when writing a message, or
pocket, when the smartphone is placed in the user’s pocket.
Each of such mode results in a different gain value for the
step-length estimation phase. One solution to this problem is
to take an average gain value of all expected walking mode
and smartphone locations during the pedestrian trajectory. Yet,
as shown in [66], even an average gain value results in a 10%
position error because of gain inaccuracy alone. To mitigate
the influence of the human activity and sensor location, a
dedicated machine learning algorithm is added to the modelbased PDR stages, as illustrated in Figure 16, to create an
activity-assisted PDR framework. Notice that, nevertheless,
the burden of prior gain calibration is needed for all modes
and sensor locations expected in the pedestrian trajectory.
As soon as the classification learning algorithm identifies the



10


current mode, the appropriate gain is selected for the PDR
algorithm. To train the learning algorithm, a data acquisition


Fig. 16: Activity-assisted PDR stages. Machine learning algorithms are embedded in the model-based PDR for activity and
location recognition.


phase is conducted to collect inertial sensor data. Next, a
preproccssing phase is applied, including handling missing
data, normalization, noise reduction, and outlier rejection. If a
machine-learning algorithm is used for classification, certain
features are required. These features are extracted based on
the specific force and angular velocity vector components.
Feature types include statistical, time domain, cross-sensor,
and frequency domain features. As the feature set is created
and the required activity or location classes are defined, the
training process is performed with a goal of finding the most
efficient classifier for the given task.
The same data acquisition and prepossessing phases are used
with deep learning approaches but the feature extraction part is
not required because the network creates its own features from
the raw inertial measurements. For classification problems, a
commonly used loss function is the cross entropy loss, which
evaluates the difference between the predicted and true class
probability distributions.
After the classifier has been designed, during the inference
phase, raw inertial data (or features) are input to the classifier
to output the human activity or the inertial sensor location. An
example of this cycle is illustrated in Figure 17, where raw
inertial sensor data are plugged into a smartphone recognition
network to classify the smartphone location texting, pocket,
and talking.
See [67] to get a better understanding of recent advances
in pedestrian-related activity recognition. Note that, as stated
in [68], supervised networks are trained on a set of defined
user modes (smartphone locations or user activities), available
during the training process. As a result, when the classifier
encounters an unknown mode, it must identify it as one of
the original modes that it was trained on. It is likely that
such classification errors will reduce the accuracy of the PDR
solution, therefore, appropriate algorithms should be applied
to identify unknown modes.


11


regression problem, the mean square error (MSE) loss
is commonly applied:



_L_ MSE = [1]

_N_



_N_
�(ˆ _x_ _i_ _−_ _x_ _i_ ) [2] (56)


_i_ =1



Fig. 17: Inertial sensors raw data is plugged into a smartphone
recognition network to classify the smartphone location texting, pocket, or talking.


_C. Hybrid PDR Approaches_


Data-driven approaches to PDR were initially hybrid
approaches. This means that they provide only one of the
two quantities required for PDR. Those are the step-length
and user heading. The second one is provided using a modelbased PDR approach. Although recent approaches focus on a
complete learning-based framework, as described in the next
subsection, hybrid PDR still has utility because it requires a
lighter computational load. PDR step-length estimation is of
interest in healthcare and biomechanical applications.


1) **Step-length learning** . Generally, data-driven approaches
are aimed to regress the step-length estimation. They
replace both the step detection and step-length estimation in a model-based procedure (Figure 2), so that both
the heading and the user position estimation are use
model-based approaches, as illustrated in Figure 18. In

[22], three StepNet architectures for the regression task
are proposed. Two of them require the step detection
phase and regress the step-length within the pedestrian
step cycle (varying time intervals); the third, omits
the step detection phase and regresses the change in
distance at a predefined (constant) time interval. The last
one demonstrated the best performance. Subsequently,
the accuracy of step regression approaches was further
improved by using magnetometer readings as well [69].
A variety of neural network architectures can be used for


Fig. 18: Hybrid PDR with step-length data-driven methods.


the regression task but these are beyond the scope of this
paper. Regardless of the architecture chosen, to solve the



where _N_ is the number of samples, ˆ _x_ _i_ is the estimated
value of sample _i_, and _x_ _i_ is the corresponding true value.
In the training process, the network is optimized by
minimizing the loss function.
2) **Heading learning** . Similarly, only the user heading can
be regressed using data-driven approaches within the
model-based PDR framework, as shown in Figure 19. As
any other regression problem, the MSE loss (56) can be
used, but to better reflect the circular nature of heading,
other loss functions may be considered. For example, in

[39], the following heading loss was suggested:



_L_ Heading = [1]

_N_



_N_
�(sin( _ψ_ [ˆ] _i_ ) _−_ sin( _ψ_ _i_ )) [2] +(cos( _ψ_ [ˆ] _i_ ) _−_ cos( _ψ_ _i_ )) [2]


_i_ =1



(57)
where _ψ_ is the heading angle.


Fig. 19: Hybrid PDR with heading regression data-driven
methods.


_D. Learning-Based PDR Frameworks_


In learning-based PDR approaches, the entire model-based
PDR algorithm is replaced by neural network architectures to
estimate the pedestrian’s position. In general, such approaches
fall into two categories:


1) **Pedestrian position regression** . Following the same line
of thought as in model-based PDR, such approaches
regress the change in heading and distance to estimate
the user position. IONet [70] examined LSTM and
a bidirectional LSTM architecture, whereas [71] used
residual networks (ResNets) for the regression only after
the smartphone location was classified using a different
network.

As both the change in distance and heading are regressed
simultaneously, the loss function accounts for both of
them, as for example:



_N_



_L_ PDR = [1]

_N_



_N_
�



�( _d_ [ˆ] _i_ _−_ _d_ _i_ ) [2] + _λ_ _N_ [1]

_i_ =1



_N_
�( _δψ_ [ˆ] _i_ _−_ _δψ_ _i_ ) [2] (58)


_i_ =1



where _d_ is the distance, _δψ_ is the change in heading,
and _λ_ is a factor to balance the two losses.


2) **Pedestrian velocity regression** . This type of approach
regresses the velocity of the user and integrates the
data to determine the position of the user based on that
velocity. The first work in this field, named RIDI [72],
regressed the user velocity and used it to correct the
user acceleration. Next, double integration was applied
to the corrected acceleration to estimate the pedestrian
position. By building upon RIDI, RoNIN [73] offers
a heading-agnostic coordinate frame representing the
input and output of the network. They examined three
different network architectures based on ResNet, LSTM,
and temporal convolutional layers. In contrast to other
approaches, RoNIN uses the device orientation together
with the inertial readings to provide input to the network,
as opposed to using only the inertial readings.


V. S UMMARY

Inertial navigation for pedestrians is an emerging discipline
that has wide applications in many fields, including healthcare,
security, and indoor location-based services. In this work, we
presented model and learning approaches to inertial pedestrian
navigation. We provided detailed algorithms for shoe-mounted
inertial sensors and classical PDR with unconstrained inertial

sensors. These algorithms include the INS equations of motion
and the EKF framework aided by information in stationary
conditions. For PDR, we described methods for solving each
phase of the algorithm for step detection, step-length estimation, and heading determination. Following these model-based
approaches, we addressed three categories of data-driven PDR:
activity-assisted and hybrid approaches, and learning-based
frameworks.


R EFERENCES


[1] F. Liu, J. Liu, Y. Yin, W. Wang, D. Hu, P. Chen, and Q. Niu, “Survey
on WiFi-based indoor positioning techniques,” _IET communications_,
vol. 14, no. 9, pp. 1372–1383, 2020.

[2] C. Yang and H.-R. Shao, “WiFi-based indoor positioning,” _IEEE Com-_
_munications Magazine_, vol. 53, no. 3, pp. 150–157, 2015.

[3] R. Kumar, J. Torres-Sospedra, and V. K. Chaurasiya, “H2lwrf-pdr: An
efficient indoor positioning algorithm using a single wi-fi access point
and pedestrian dead reckoning,” _Internet of Things_, p. 101271, 2024.

[4] R. F. Brena, J. P. Garc´ıa-V´azquez, C. E. Galv´an-Tejada, D. Mu˜nozRodriguez, C. Vargas-Rosales, J. Fangmeyer _et al._, “Evolution of indoor
positioning technologies: A survey,” _Journal of Sensors_, vol. 20, 2017.

[5] D. Khan, Z. Cheng, H. Uchiyama, S. Ali, M. Asshad, and K. Kiyokawa,
“Recent advances in vision-based indoor navigation: A systematic
literature review,” _Computers & Graphics_, vol. 104, pp. 24–45, 2022.

[6] Z. Zhou, W. Feng, P. Li, Z. Liu, X. Xu, and Y. Yao, “A fusion method of
pedestrian dead reckoning and pseudo indoor plan based on conditional
random field,” _Measurement_, vol. 207, p. 112417, 2023.

[7] D. Titterton and J. L. Weston, _Strapdown inertial navigation technology_ .
IET, 2004, vol. 17.

[8] J. Farrell, _Aided navigation: GPS with high rate sensors_ . McGraw-Hill,
Inc., 2008.

[9] R. Harle, “A survey of indoor inertial positioning systems for pedestrians,” _IEEE Communications Surveys & Tutorials_, vol. 15, no. 3, pp.
1281–1293, 2013.

[10] L. Fang, P. J. Antsaklis, L. A. Montestruque, M. B. McMickell,
M. Lemmon, Y. Sun, H. Fang, I. Koutroulis, M. Haenggi, M. Xie
_et al._, “Design of a wireless assisted pedestrian dead reckoning systemthe NavMote experience,” _IEEE transactions on Instrumentation and_
_Measurement_, vol. 54, no. 6, pp. 2342–2358, 2005.

[11] K. Tumkur and S. Subbiah, “Modeling human walking for step detection
and stride determination by 3-axis accelerometer readings in pedometer,”
in _2012 Fourth International Conference on Computational Intelligence,_
_Modelling and Simulation_, 2012, pp. 199–204.



12


[12] J. Park, Y. Kim, and J. Lee, “Waist mounted pedestrian dead-reckoning
system,” in _2012 9th International Conference on Ubiquitous Robots_
_and Ambient Intelligence (URAI)_, 2012, pp. 335–336.

[13] J. Seo, Y. Chiang, T. H. Laine, and A. M. Khan, “Step counting
on smartphones using advanced zero-crossing and linear regression,”
in _Proceedings of the 9th International Conference on Ubiquitous_
_Information Management and Communication_, 2015, pp. 1–7.

[14] J. Santos, A. Costa, and M. J. Nicolau, “Autocorrelation analysis of
accelerometer signal to detect and count steps of smartphone users,”
in _2019 International Conference on Indoor Positioning and Indoor_
_Navigation (IPIN)_ . IEEE, 2019, pp. 1–7.

[15] M. B. Rhudy and J. M. Mahoney, “A comprehensive comparison of
simple step counting techniques using wrist-and ankle-mounted accelerometer and gyroscope signals,” _Journal of Medical Engineering_
_and Technology_, vol. 42, no. 3, pp. 236–243, 2018.

[16] A. C. Dirican and S. Aksoy, “Step counting using smartphone accelerometer and fast fourier transform,” _Sigma J. Eng. Nat. Sci_, vol. 8,
pp. 175–182, 2017.

[17] J.-H. Wang, J.-J. Ding, Y. Chen, and H.-H. Chen, “Real time
accelerometer-based gait recognition using adaptive windowed wavelet
transforms,” in _2012 ieee asia pacific conference on circuits and systems_ .
IEEE, 2012, pp. 591–594.

[18] M. Vezoˇcnik and M. B. Juric, “Average step length estimation models’
evaluation using inertial sensors: A review,” _IEEE sensors journal_,
vol. 19, no. 2, pp. 396–403, 2018.

[19] R. Soni and S. Trapasiya, “A survey of step length estimation models
based on inertial sensors for indoor navigation systems,” _International_
_Journal of Communication Systems_, vol. 35, no. 4, p. e5053, 2022.

[20] A. R. Pratama, Widyawan, and R. Hidayat, “Smartphone-based pedestrian dead reckoning as an indoor positioning system,” in _2012 Inter-_
_national Conference on System Engineering and Technology (ICSET)_,
2012, pp. 1–6.

[21] H. Weinberg, “Using the ADXL202 in pedometer and personal navigation applications,” _Analog Devices AN-602 application note_, vol. 2,
no. 2, pp. 1–6, 2002.

[22] I. Klein and O. Asraf, “Stepnet—deep learning approaches for step
length estimation,” _IEEE Access_, vol. 8, pp. 85 706–85 713, 2020.

[23] S. H. Shin and C. G. Park, “Adaptive step length estimation algorithm
using optimal parameters and movement status awareness,” _Medical_
_Engineering and Physics_, vol. 33, no. 9, pp. 1064–1071, 2011.

[24] D. Choukroun, I. Y. Bar-Itzhack, and Y. Oshman, “Novel quaternion
Kalman filter,” _IEEE Transactions on Aerospace and Electronic Systems_,
vol. 42, no. 1, pp. 174–190, 2006.

[25] J. K. Lee, E. J. Park, and S. N. Robinovitch, “Estimation of attitude
and external acceleration using inertial sensor measurement during
various dynamic conditions,” _IEEE transactions on instrumentation and_
_measurement_, vol. 61, no. 8, pp. 2262–2273, 2012.

[26] A. M. Sabatini, “Kalman-filter-based orientation determination using
inertial/magnetic sensors: Observability analysis and performance evaluation,” _Sensors_, vol. 11, no. 10, pp. 9182–9206, 2011.

[27] R. Munguia and A. Grau, “Attitude and heading system based on EKF
total state configuration,” in _2011 IEEE International Symposium on_
_Industrial Electronics_ . IEEE, 2011, pp. 2147–2152.

[28] R. Mahony, T. Hamel, and J.-M. Pflimlin, “Nonlinear complementary
filters on the special orthogonal group,” _IEEE Transactions on automatic_
_control_, vol. 53, no. 5, pp. 1203–1218, 2008.

[29] H. Fourati, N. Manamanni, L. Afilal, and Y. Handrich, “A nonlinear
filtering approach for the attitude and dynamic body acceleration estimation based on inertial and magnetic sensors: Bio-logging application,”
_IEEE Sensors Journal_, vol. 11, no. 1, pp. 233–244, 2010.

[30] S. O. Madgwick, A. J. Harrison, and R. Vaidyanathan, “Estimation of
IMU and MARG orientation using a gradient descent algorithm,” in
_2011 IEEE international conference on rehabilitation robotics_ . IEEE,
2011, pp. 1–7.

[31] E. Vertzberger and I. Klein, “Attitude adaptive estimation with smartphone classification for pedestrian navigation,” _IEEE Sensors Journal_,
vol. 21, no. 7, pp. 9341–9348, 2021.

[32] ——, “Attitude and heading adaptive estimation using a data driven
approach,” in _2021 International Conference on Indoor Positioning and_
_Indoor Navigation (IPIN)_ . IEEE, 2021, pp. 1–6.

[33] ——, “Adaptive attitude estimation using a hybrid model-learning
approach,” _IEEE Transactions on Instrumentation and Measurement_,
vol. 71, pp. 1–9, 2022.

[34] R. Leonardo, G. Rodrigues, M. Barandas, P. Alves, R. Santos, and
H. Gamboa, “Determination of the walking direction of a pedestrian
from acceleration data,” in _2019 International Conference on Indoor_
_Positioning and Indoor Navigation (IPIN)_ . IEEE, 2019, pp. 1–6.


[35] Z.-A. Deng, G. Wang, Y. Hu, and D. Wu, “Heading estimation for
indoor pedestrian navigation using a smartphone in the pocket,” _Sensors_,
vol. 15, no. 9, pp. 21 518–21 536, 2015.

[36] A. Manos, I. Klein, and T. Hazan, “Gravity direction estimation and
heading determination for pedestrian navigation,” in _2018 International_
_Conference on Indoor Positioning and Indoor Navigation (IPIN)_ . IEEE,
2018, pp. 206–212.

[37] V. Thio, K. B. Anonsen, and J. K. Bekkeng, “Relative heading estimation [˚]
for pedestrians based on the gravity vector,” _IEEE Sensors Journal_,
vol. 21, no. 6, pp. 8218–8225, 2021.

[38] A. Manos, T. Hazan, and I. Klein, “Walking direction estimation
using smartphone sensors: A deep network-based framework,” _IEEE_
_Transactions on Instrumentation and Measurement_, vol. 71, pp. 1–12,
2022.

[39] Q. Wang, H. Luo, L. Ye, A. Men, F. Zhao, Y. Huang, and C. Ou,
“Pedestrian heading estimation based on spatial transformer networks
and hierarchical LSTM,” _IEEE Access_, vol. 7, pp. 162 309–162 322,
2019.

[40] A. Manos, I. Klein, and T. Hazan, “Gravity-based methods for heading
computation in pedestrian dead reckoning,” _Sensors_, vol. 19, no. 5, p.
1170, 2019.

[41] Y.-K. Kim, S.-H. Choi, H.-W. Kim, and J.-M. Lee, “Performance
improvement and height estimation of pedestrian dead-reckoning system
using a low cost MEMS sensor,” in _2012 12th International Conference_
_on Control, Automation and Systems_, 2012, pp. 1655–1660.

[42] S. Asano, Y. Wakuda, N. Koshizuka, and K. Sakamura, “A robust
pedestrian dead-reckoning positioning based on pedestrian behavior and
sensor validity,” in _Proceedings of the 2012 IEEE/ION Position, Location_
_and Navigation Symposium_, 2012, pp. 328–333.

[43] S. Boim, G. Even-Tzur, and I. Klein, “Height difference determination using smartphones based accelerometers,” _IEEE Sensors Journal_,
vol. 22, no. 6, pp. 4908–4915, 2021.

[44] K. Itzik and L. Yaakov, “Step-length estimation during movement
on stairs,” in _2019 27th Mediterranean Conference on Control and_
_Automation (MED)_ . IEEE, 2019, pp. 518–523.

[45] E. Foxlin, “Pedestrian tracking with shoe-mounted inertial sensors,”
_IEEE Computer Graphics and Applications_, vol. 25, no. 6, pp. 38–46,
2005.

[46] J.-O. Nilsson, I. Skog, P. H¨andel, and K. Hari, “Foot-mounted INS for
everybody-an open-source embedded implementation,” in _Proceedings_
_of the 2012 IEEE/ION Position, Location and Navigation Symposium_ .
Ieee, 2012, pp. 140–145.

[47] D. Engelsman and I. Klein, “Information-aided inertial navigation:
A review,” _IEEE Transactions on Instrumentation and Measurement_,
vol. 72, pp. 1–18, 2023.

[48] P. D. Groves, _Principles of GNSS, Inertial and Multisensor Integrated_
_Navigation Systems_ . Artech House, 2013.

[49] C. Fischer, P. T. Sukumar, and M. Hazas, “Tutorial: Implementing a
pedestrian tracker using inertial sensors,” _IEEE pervasive computing_,
vol. 12, no. 2, pp. 17–27, 2012.

[50] A. R. Jim´enez, F. Seco, J. C. Prieto, and J. Guevara, “Indoor pedestrian
navigation using an INS/EKF framework for yaw drift reduction and
a foot-mounted imu,” in _2010 7th workshop on positioning, navigation_
_and communication_ . IEEE, 2010, pp. 135–143.

[51] J. Wahlstr¨om and I. Skog, “Fifteen years of progress at zero velocity:
A review,” _IEEE Sensors Journal_, vol. 21, no. 2, pp. 1139–1151, 2021.

[52] I. Skog, P. Handel, J.-O. Nilsson, and J. Rantakokko, “Zero-velocity
detection—an algorithm evaluation,” _IEEE Transactions on Biomedical_
_Engineering_, vol. 57, no. 11, pp. 2657–2666, 2010.

[53] S. Y. Park, H. Ju, and C. G. Park, “Stance phase detection of multiple
actions for military drill using foot-mounted IMU,” _sensors_, vol. 14,
p. 16, 2016.

[54] B. Wagstaff, V. Peretroukhin, and J. Kelly, “Robust data-driven zerovelocity detection for foot-mounted inertial navigation,” _IEEE Sensors_
_Journal_, vol. 20, no. 2, pp. 957–967, 2019.

[55] A. Etzion and I. Klein, “MoRPI: Mobile robot pure inertial navigation,”
_IEEE Journal of Indoor and Seamless Positioning and Navigation_, vol. 1,
pp. 141–150, 2023.

[56] Y. Li, R. Chen, X. Niu, Y. Zhuang, Z. Gao, X. Hu, and N. El-Sheimy,
“Inertial sensing meets machine learning: Opportunity or challenge?”
_IEEE Transactions on Intelligent Transportation Systems_, 2021.

[57] I. Klein, “Data-driven meets navigation: Concepts, models, and experimental validation,” in _2022 DGON Inertial Sensors and Systems (ISS)_ .
IEEE, 2022, pp. 1–21.

[58] C. Chen and X. Pan, “Deep learning for inertial positioning: A survey,”
_arXiv preprint arXiv:2303.03757_, 2023.



13


[59] N. Cohen and I. Klein, “Inertial navigation meets deep learning:
A survey of current trends and future directions,” _arXiv preprint_
_arXiv:2307.00014_, 2023.

[60] Q. Wang, M. Fu, J. Wang, H. Luo, L. Sun, Z. Ma, W. Li, C. Zhang,
R. Huang, X. Li _et al._, “Recent advances in pedestrian inertial navigation
based on smartphone: A review,” _IEEE Sensors Journal_, vol. 22, no. 23,
pp. 22 319–22 343, 2022.

[61] I. Goodfellow, Y. Bengio, and A. Courville, _Deep learning_ . MIT press,
2016.

[62] A. Zhang, Z. C. Lipton, M. Li, and A. J. Smola, _Dive into deep learning_ .
Cambridge University Press, 2023.

[63] S. J. Prince, _Understanding Deep Learning_ . MIT press, 2023.

[64] M. Elhoushi, J. Georgy, A. Noureldin, and M. J. Korenberg, “A
survey on approaches of motion mode recognition using sensors,” _IEEE_
_Transactions on intelligent transportation systems_, vol. 18, no. 7, pp.
1662–1686, 2016.

[65] I. Klein, “Smartphone location recognition: A deep learning-based
approach,” _Sensors_, vol. 20, no. 1, p. 214, 2019.

[66] I. Klein, Y. Solaz, and G. Ohayon, “Pedestrian dead reckoning with
smartphone mode recognition,” _IEEE Sensors Journal_, vol. 18, no. 18,
pp. 7577–7584, 2018.

[67] Q. Wang, H. Luo, J. Wang, L. Sun, Z. Ma, C. Zhang, M. Fu, and
F. Zhao, “Recent advances in pedestrian navigation activity recognition:
A review,” _IEEE Sensors Journal_, vol. 22, no. 8, pp. 7499–7518, 2022.

[68] N. Daniel, F. Goldberg, and I. Klein, “Smartphone location recognition
with unknown modes in deep feature space,” _Sensors_, vol. 21, no. 14,
p. 4807, 2021.

[69] F. Bo, J. Li, and W. Wang, “Mode-independent stride length estimation
with IMUs in smartphones,” _IEEE Sensors Journal_, vol. 22, no. 6, pp.
5824–5833, 2022.

[70] C. Chen, X. Lu, A. Markham, and N. Trigoni, “IONet: Learning to
cure the curse of drift in inertial odometry,” in _Proceedings of the AAAI_
_Conference on Artificial Intelligence_, vol. 32, no. 1, 2018.

[71] O. Asraf, F. Shama, and I. Klein, “PDRNet: A deep-learning pedestrian
dead reckoning framework,” _IEEE Sensors Journal_, vol. 22, no. 6, pp.
4932–4939, 2021.

[72] H. Yan, Q. Shan, and Y. Furukawa, “RIDI: Robust IMU double integration,” in _Proceedings of the European conference on computer vision_
_(ECCV)_, 2018, pp. 621–636.

[73] S. Herath, H. Yan, and Y. Furukawa, “RoNIN: Robust neural inertial
navigation in the wild: Benchmark, evaluations, & new methods,” in
_2020 IEEE international conference on robotics and automation (ICRA)_ .
IEEE, 2020, pp. 3146–3152.


