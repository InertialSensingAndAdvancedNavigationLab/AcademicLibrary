## Robust Online Calibration for UWB-Aided Visual-Inertial Navigation with Bias Correction

Yizhi Zhou, Jie Xu, Jiawei Xia, Zechen Hu, Weizi Li, Xuan Wang



_**Abstract**_ **— This paper presents a novel robust online cal-**
**ibration framework for Ultra-Wideband (UWB) anchors in**
**UWB-aided Visual-Inertial Navigation Systems (VINS). Accu-**
**rate anchor positioning, a process known as calibration, is**
**crucial for integrating UWB ranging measurements into state**
**estimation. While several prior works have demonstrated sat-**
**isfactory results by using robot-aided systems to autonomously**
**calibrate UWB systems, there are still some limitations: 1)**
**these approaches assume accurate robot localization during**
**the initialization step, ignoring localization errors that can**
**compromise calibration robustness, and 2) the calibration**
**results are highly sensitive to the initial guess of the UWB**
**anchors’ positions, reducing the practical applicability of these**
**methods in real-world scenarios. Our approach addresses these**
**challenges by explicitly incorporating the impact of robot**
**localization uncertainties into the calibration process, ensuring**
**robust initialization. To further enhance the robustness of**
**the calibration results against initialization errors, we propose**
**a tightly-coupled Schmidt Kalman Filter (SKF)-based online**
**refinement method, making the system suitable for practical**
**applications. Simulations and real-world experiments validate**
**the improved accuracy and robustness of our approach.**


I. I NTRODUCTION


Visual-inertial navigation system (VINS) is favored in
robot state estimation due to its accuracy, reliability, and
lightweight design [1], [2]. Nevertheless, VINS suffers from
cumulative drift due to inherent limitations in visual-based

localization methods. While GPS provides a natural solution
for external localization information in outdoor environ
ments, its reliance on open spaces makes it unsuitable for
use in GPS-denied or indoor settings. To address this, many
recent works incorporate Ultra Wideband (UWB) measurements into the VINS to leverage the global observation
provided by UWB for better localization performance [3]–

[5].
Specifically, UWB-aided VINS utilizes ranging measurements between the robot and the UWB anchor to enhance

robot state estimation. Accurate robot localization requires
precise knowledge of these UWB anchor positions, a process
known as UWB calibration. Many previous studies have
proposed self-calibration, where a robot autonomously calibrates the anchor positions using the geometric relations
between its position and the anchor positions, subsequently
integrating these calibration results into the VINS [6], [7].
Most UWB self-calibration methods typically involve two
key steps: an initialization phase to estimate coarse anchor


Y. Zhou, J. Xia, Z. Hu and X. Wang are with the Department of
Electrical and Computer Engineering, George Mason University. J. Xu is
with the Department of Electrical and Computer Engineering, University of
California, Riverside. W. Li is with the Department of Electrical Engineering
and Computer Science, University of Tennessee, Knoxville.
This research is supported by NSF IIS-2153426 and ECCS-2332210.



Fig. 1: System Overview: The proposed robot-aided UWB
calibration system contains two stages: A robust initialization
stage and a SKF-based refinement stage.


positions, followed by a refinement phase to improve these
estimates. These methods fall into two categories: (i) looselycoupled methods, where calibration is handled by a separate
estimator independent of robot localization, and (ii) tightlycoupled methods, where both the robot state and UWB state
are jointly estimated within a single framework. Tightlycoupled methods offer greater flexibility [8] and outperform
loosely-coupled approaches in both anchor calibration and
robot localization [4].

However, during the initialization phase, many existing
works implicitly assume that the localization of robots is
accurate. This assumption neglects the impact of localization
uncertainties, which can lead to poor initial estimates of
UWB anchor positions. Additionally, the performance of
tightly-coupled calibration systems are heavily sensitive to
the accuracy of initial UWB parameters [9]. In practice,
obtaining precise initial guesses is challenging, potentially
degrading system performance and, in some cases, causing
system failure.

_Statement of Contribution:_ To address the challenges identified in UWB calibration, we propose a robust calibration
method for improving both the performance and reliability
of existing calibration frameworks. The main contributions
of this paper are as follows:


_•_ We propose a novel UWB initialization method that explicitly accounts for uncertainty in robot localization during
the initialization process, improving both the performance
and robustness of calibration in the presence of various
robot localization uncertainties.


_•_ We show, through experiments and analysis, that the initialization phase of UWB calibration can significantly impact the overall performance of the calibration system. We


propose a tightly-coupled Schmidt Kalman Filter (SKF)based online calibration method to reduce the influence of
initialization errors on the calibration process.

_•_ We perform extensive simulations and experiments to validate the performance of the initialization and calibration
methods compared with baselines.


II. R ELATED W ORKS


UWB measurements have been widely utilized to enhance
robot localization in numerous studies. In early researches

[10]–[14], anchor positions were calibrated offline and used
as prior knowledge for drift-free state estimation. While these
methods effectively reduce the drift in VINS, performing
offline calibration becomes challenging in dynamic or largescale environments.

Several studies have explored the use of raw UWB
measurements and robot localization information for self
calibration [15]. Typically, self-calibration of UWB involves
two key steps: an initialization phase to estimate coarse anchor positions, followed by a refinement phase to improve the
initial estimates. In [3], a consistent visual-inertial-rangingodometry system is proposed, where the anchor positions are
initially estimated by solving a least squares problem and
are then jointly optimized with the VINS state in a tightlycoupled manner. Refs. [7], [9] observed that the robot’s
trajectory can significantly influence the calibration process,
and design path-planning algorithms to compute an optimal
trajectory for improved calibration accuracy. The studies
in [7], [16] notice that the ranging measurement can be
deteriorated by additional distance-dependent biases due to
the signal block in cluttered environments. Even though the
anchor position is precisely calibrated, the inconstant bias
may introduce additional errors. Therefore, the bias term
of the ranging measurements are introduced to improve the
calibration. In [17], a fully distributed calibration framework
is introduced to initialize large-scale UWB networks, significantly reducing computational complexity on the robot’s
side. For the purpose of robust calibration, multiple studies
have pointed out a crucial fact that the calibration results are
sensitive to the initial guess and hence aim to enhance the
initial guess for robust calibration performance [4], [9], [18].
To avoid the non-line-of-sight (NLOS) problem, an object
detection-based calibration method is proposed in [4] that
directly uses visual measurements to initialize the anchor
positions.

Nevertheless, none of the above mentioned works consider
the fact that the robustness of the calibration is highly
sensitive to the accuracy of the robot’s localization and
the initialization values. Therefore, these approaches still
have the following limitations: 1) Anchor initialization is
based on the assumption of accurate robot positioning,
which compromises the robustness of the estimated anchor
positions; and 2) Jointly estimating the robot state and
anchor positions, if the anchor has an inaccurate initial guess,
can significantly degrade the robot’s localization, leading to
further inaccuracies in the calibration process.



III. P RELIMINARIES


_A. Problem Formulation_


Consider a robot in a 3-D environment equipped with
a visual-inertial sensor for ego-motion measurement and a
UWB tag for distance measurement. We first define the
IMU and camera frames as _I_ and _C_, respectively, while _G_
represents the global frame. There are _M_ position-unknown
UWB, denoted as _[G]_ **p** _a_ _i_ _, i_ = _{_ 1 _,_ 2 _, ..., M_ _}_, to be estimated
in our setup.
The UWB tag on the robot can provide the ranging
measurement between the robot and the UWB anchor _i_
at timestep _t_ _k_, denoted as _d_ _i,k_ . Given the UAV’s pose
_G_
( _[I]_ _G_ _[k]_ **[R]** _[,]_ _[G]_ **[ p]** _[I]_ _k_ [)][ and the anchor position] **p** _a_ _i_, the ranging
measurement is described by the following model:


_⊤I_ _G_
_d_ _i,k_ = _β_ _i_ ( _∥_ _[G]_ **p** _I_ _k_ + _[I]_ _G_ _[k]_ **[R]** **p** _T_ _−_ **p** _a_ _i_ _∥_ + **n** _u_ ) + _γ_ _i_ (1)


_I_
where **n** _u_ _∼N_ (0 _,_ **Q** _d_ ), and **p** _T_ represents UAV tag’s
position in its IMU frame, which can be easily calibrated
offline. Two bias terms _β_ _i_ and _γ_ _i_, firstly introduced in [7],
are included to better reflect, in practice, the difference of
UWB sensor reading and the true distance. It is important to
note that _β_ _i_ and _γ_ _i_ are path-dependent biases [7], designed
to capture the position dependency of the range error.
In the UWB-aided VINS, the UWB should be calibrated
at first, so that the UWB ranging measurements can participate the estimation of robot position. This paper primarily
focuses on UWB calibration rather than robot localization.

The objective is to use a UAV equipped with a visualinertial sensor to automatically calibrate the UWB, i.e.,
estimate ( _[G]_ **p** _a_ _i_ _, β_ _i_ _, γ_ _i_ ), while ensuring robust and consistent
calibration results by accounting for the uncertainty in robot
localization.


_B. System Overview_


We propose a two-phase calibration scheme for the UWBaided VINS as shown in Fig. 1. It is important to note that
the method of this paper focuses solely on the robot-aided
calibration phase, rather than UWB-aided robot localization.
In particular, the proposed calibration system consists of
two phases: a robust initialization phase (Sec. V) and a
SKF-based online refinement phase (Sec. VI-B). In the
first phase, the objective is to find an initial guess of the
_G_
anchor position **p** _a_ _i_ and the unknown bias parameters
( _β_ _i_ _, γ_ _i_ ). The VINS runs normally after the visual-inertial
initialization is completed. Once the UWB tag receives a
ranging measurement and the ID from any of the anchors,
the ranging measurement and the robot pose estimate will be
stored for initialization. Since the robot localization results

are directly used to initialize the UWB, the uncertainty
of robot localization also affects the UWB estimation. To

ensure robust estimation, we incorporate VINS uncertainty
into the initialization process. Once the initialization phase
is completed, the system transfers to the online refinement
phase to improve the initial UWB guess in the second stage.


IV. VINS-A IDED C ALIBRATION S YSTEM


In this section, we extend the standard Multi-State Constraint Kalman Filter (MSCKF)-based VINS [19] framework
to incorporate additional calibration for the UWB system.


_A. System State and Model_


The state vector at each timestep _t_ _k_, denoted as **x** _k_, is
defined by


**x** _k_ ≜ � **x** _⊤r_ _k_ **x** _[⊤]_ _U_ _k_ � = � **x** _⊤I_ _k_ **x** _[⊤]_ _C_ _k_ **x** _[⊤]_ _U_ _k_ � _⊤_

**x** _I_ _k_ = � _IG_ _k_ **[q]** _[⊤]_ **b** _[⊤]_ _g_ _G_ **v** _I⊤_ _k_ **b** _[⊤]_ _a_ _G_ **p** _⊤I_ _k_ � _⊤_



**x** _C_ _k_ = � _CG_ _k_ **[q]** _[⊤]_ _G_ **p** _⊤C_ _k_ _..._ _GC_ _k−N_ **q** _[⊤]_ _G_ **p** _⊤C_ _k−N_



� _⊤_



_G_ _⊤_ _⊤_
**x** _U_ _k_ = � **p** _a_ _β_ _γ_ � (2)


where **x** _r_ _k_ denotes the active MSCKF state. The **x** _I_ _k_ is the
IMU state including IMU’s orientation, position, velocity,
and biases; **x** _C_ _k_ is the clone of historical IMU poses when
features are observed by camera; **x** _C_ _k_ denotes the clone of
the historical cameras states. **x** _U_ _k_ denotes the UWB state
which contains the anchor position _[G]_ **p** _[⊤]_ _a_ _k_ [the UWB model]
parameters ( _β, γ_ ). For simplicity, we consider only a single
UWB anchor in our analysis; Nevertheless, this framework
can be easily extended to multiple anchors. To represent the
system’s covariance matrix more clearly, we introduce the
following partitioning for the covariance





 (3)



**P** _k|k_ =



**P** _II_ _k|k_ **P** _IC_ _k|k_ **P** _IU_ _k|k_



**P** _[⊤]_ _IC_ _k|k_ **P** _CC_ _k|k_ **P** _CU_ _k|k_

 **P** _[⊤]_ _IU_ _k|k_ **P** _[⊤]_ _CU_ _k|k_ **P** _UU_ _k|k_



where **P** _II_ _k|k_ _∈_ R [15] _[×]_ [15] is the covariance of the IMU
state, **P** _CC_ _k|k_ _∈_ R [6] _[N]_ _[×]_ [6] _[N]_ is the covariance of the camera
estimate, and **P** _UU_ _k|k_ _∈_ R [5] _[×]_ [5] is the covariance of the
UWB state; **P** _IC_ _k|k_ _,_ **P** _IU_ _k|k_ _,_ **P** _CU_ _k|k_ denotes the corresponding cross-correlations. The covariance matrix will be initially
constructed upon completion of the initialization step, as
described in (Sec. V).
The state **x** _k_ will be propagated forward with IMU’s linear
velocity and acceleration measurements based on the IMU
kinematic model [20]. To propagate the state covariance
matrix, we linearize the IMU kinematics and compute the
state transition matrix **Φ** ( _t_ _k_ +1 _, t_ _k_ ) [20]. With notation (3),
the corresponding state covariance can be propagated as





 (4)



timestep _t_ _k_, the corresponding feature measurement can be
obtained through the following model


**z** _C,k_ = Λ( _[C]_ _[k]_ **p** _f_ ) + **n** _c_
_C_ _k_ **p** _f_ = _CI_ **[R]** _[I]_ _G_ _[k]_ **[R]** [(] _[G]_ **[p]** _[f]_ _[ −]_ _[G]_ **[p]** _[I]_ _k_ [) +] _[ C]_ **[p]** _[I]_ (5)


where **n** _c_ _∼N_ (0 _,_ **Q** _c_ ) is the white Gaussian noise with
covariance **Q** _c_ . The _[C]_ _[k]_ **p** _f_ is the landmark position in the

_·_
camera frame, and the projection function Λ( ) is defined
as Λ(� _x_ _y_ _z_ [�] _[⊤]_ ) = � _x/z_ _y/z_ [�] _[⊤]_ . By linearizing the
measurement equation, the camera measurements can be
incorporated into the EKF update, as detailed in [19].
**UWB update model:** Once the robot receives a ranging
measurement from the anchor, this measurement will be
used for state update. Given the measurement model (1),
we linearize it at the current estimate ˆ **x** _I_ _k_ as


_d_ ˜ _k_ = **H** _I_ _k_ ˜ **x** _I_ _k_ + **H** _U_ _k_ ˜ **x** _U_ _k_ + **n** _u_ (6)


Since our formulation and derivation assume only a single
anchor, we simplify the notation by omitting the subscript _i_
in the variable _d_ _i,k_ in the following derivation. The Jacobian
corresponding to the IMU state, denoted as **H** _I_ _k_, and the
Jacobian corresponding to the UWB state, which includes
( _[G]_ **p** _a_ _, β, γ_ ), denoted as **H** _U_ _k_, can be computed as:


**H** _I_ _k_ = **H** _p_ � _−⌊_ _[I]_ _G_ **[R]** [ˆ] _[⊤][I]_ **[p]** _[T]_ _[ ×⌋]_ **0** 3 _×_ 9 **I** 3 �

**H** _U_ _k_ = � _−_ **H** _p_ **H** _β_ 1 [�] (7)


where the matrices **H** _p_ and **H** _β_ can be computed as

_β_ ˆ _G_ **p** ˆ _I_ _k_ + _[I]_ _G_ _k_ **[R]** [ˆ] _[⊤][I]_ **[p]** _[T]_ _[ −]_ _[G]_ **[p]** [ˆ] _[a]_ _⊤_
� �
**H** _p_ = _∥_ _[G]_ **p** ˆ _I_ _k_ + _[I]_ _G_ _[k]_ **[R]** [ˆ] _[⊤][I]_ **[p]** _[T]_ _[ −]_ _[G]_ **[p]** [ˆ] _[a]_ _[∥]_

**H** _β_ = _∥_ _[G]_ **p** ˆ _I_ _k_ + _[I]_ _G_ _[k]_ **[R]** [ˆ] _[⊤][I]_ **[p]** _[T]_ _[ −]_ _[G]_ **[p]** [ˆ] _[a]_ _[∥]_ (8)


V. R OBUST I NITIALIZATION BY S TOCHASTIC

O PTIMIZATION


To integrate the ranging measurement into the navigation
system, an initial estimate of the UWB anchor position _[G]_ **p** _a_
and the model parameters ( _β, γ_ ) is required for the anchor.
To simplify the initialization during implementation, we
temporarily fix the value of _β_ = 1 at this stage, and update
it in the next refinement stage. We assume that the robot’s
state, as obtained through the VINS, along with ranging
measurements, are readily accessible during the initialization
phase, stored within a time window of length _m_ .

_Remark 1:_ The parameter _β_ in the UWB model (1) is
typically very close to 1 in actual test results. In fact, many
papers simply assume this value to be 1 for practical use [3],

[16]. Therefore, during the initialization stage, we set _β_ to 1
as an initial guess. It is then refined in the subsequent stage
(see refinement stage in Sec. IV).


_A. Robust Initialization Formulation_


Building on the previous analysis, the uncertainty in the
UAV’s pose estimate can significantly affect UWB calibration and must be considered for robust performance.
Although VINS drift is small during the initialization phase,
neglecting this uncertainty can lead to inconsistencies in



**P** _k_ +1 _|k_ =



**P** _II_ _k_ +1 _|k_ **P** _IC_ _k_ +1 _|k_ **P** _IU_ _k_ +1 _|k_



**P** _[⊤]_ _IC_ _k_ +1 _|k_ **P** _CC_ _k|k_ **P** _CU_ _k|k_

 **P** _[⊤]_ _IU_ _k_ +1 _|k_ **P** _[⊤]_ _CU_ _k|k_ **P** _UU_ _k|k_



where **P** _II_ _k_ +1 _|k_ is the propagated IMU covariance.
**P** _IC_ _k_ +1 _|k_ = **Φ** ( _t_ _k_ +1 _, t_ _k_ ) **P** _IC_ _k|k_, and **P** _IU_ _k_ +1 _|k_ =
**Φ** ( _t_ _k_ +1 _, t_ _k_ ) **P** _IU_ _k|k_ .


_B. Measurement Update Model_


**Camera update model:** When a static landmark of the
environment, denoted as _[G]_ **p** _f_, is tracked by the camera at


the estimator and degrade initialization accuracy. To address
this, we propose a robust initialization method that explicitly
integrates UAV pose uncertainty into the calibration process.
Specifically, we formulate the following stochastic robust
approximation problem [21, Sec. 6.4] to estimate the UWB
state ( _[G]_ **p** _a_ _, γ_ ), treating the robot’s state as a stochastic
variable



Fig. 2: To ensure a consistent state estimation, we need to
compute the covariance of the UWB state and its crosscorrelations with the existing MSCKF state. This step is
crucial for maintaining the integrity of the filter, as it properly
accounts for the uncertainties associated with the newly
introduced UWB state.


where _h_ ( _·_ ) satisfies the UWB measurement model (1). Then
we linearize the stacked measurement model, which yields



min
_G_ **p** _a_ _,γ_



_m_
� E **x** _Ik_ ( _∥d_ _k_ _−_ _h_ ( **x** _I_ _k_ _,_ **x** _U_ ) _∥_ [2] ) (9)


_k_ =1



_where the above expectation_ E( _·_ ) _is taken over the instantia-_
_tions of all possible robot (IMU) state_ **x** _I_ _k_ . This accounts for
the fact that **x** _I_ _k_ is a random variable subject to uncertainties.
_d_ _k_ is the collected ranging measurement. _h_ ( _·_ ) is the UWB
measurement function, referenced in (1). **x** _U_ _k_ = ( _[G]_ **p** _a_ _i_ _, γ_ _i_ ) is
the UWB state to be estimated. Since the cost in (9) involves
an expectation which cannot be directly solved, a common
approach is to approximate the expectation and reformulating
the problem into a regular optimization formulation. In
particular, we linearize the measurement function **h** ( _·_ ) at the
current UAV’s state estimate ˆ **x** _I_ _k_ using the first-order Taylor
expansion to approximate the cost function (9) as


_m_
� E **x** _Ik_ ( _∥d_ _k_ _−_ _h_ ( **x** _I_ _k_ _,_ **x** _U_ ) _∥_ [2] ) _≈_


_k_ =1



�
**d** � = � **H** _A_ **H** _B_ � [�] **X** � _I_
**x** _U_



+ ¯ **n** _u_ (13)
�



_m_
�


_k_ =1



(15)
�



**X** _I_
��� **x** � _U_



**n** ¯ _u_ 1
+ ¯
� � **n** _u_ 2



� _∥d_ _k_ _−_ _h_ (ˆ **x** _I_ _k_ _,_ **x** _U_ ) _∥_ [2] + trace( **H** _I_ _k_ **P** _II_ _k_ **H** _[⊤]_ _I_ _k_ [)] � (10)



where ¯ **n** _u_ represents the stacked noise vector, and **H** _A_ and
**H** _B_ are the corresponding measurement jacobians given by


**H** _A_ = diag( **H** _I_ 0 _, · · ·,_ **H** _I_ _k_ )
**H** _B_ = diag( **H** _U_ 0 _, · · ·,_ **H** _U_ _k_ ) (14)


We then decompose the linearized system (13) into two
subsystems using QR decomposition, expressed as:

**d** �� 1 = **H** _A_ 1 **H** _A_ 2 **X** � _I_ + **n** ¯¯ _u_ 1 (15)
� **d** 2 � � **H** _B_ 1 **0** ��� **x** _U_ � � **n** _u_ 2 �


Then, the covariance of the UWB state and its correlations
to the existing state **x** _I_ _k_ and **x** _C_ _k_ can be computed and used
to augmented to the current covariance following [1].


_B. FIM-based Analysis_


This section presents an analysis of the effectiveness
and performance of the proposed robust initialization using
the Fisher Information Matrix (FIM) [23], which quantifies
the information contained in the observed data about the

unknown parameter being estimated. Mathematically, it is
defined as the expectation of the outer product of the gradient
of the log-likelihood function [23]:



�



= � **HH** _BA_ 11 **H0** _A_ 2



where the jacobian **H** _I_ _k_ is computed in (7), and the term
trace( **H** _[⊤]_ _I_ _k_ **[P]** _[II]_ _k_ **[H]** _[I]_ _k_ [)][ denotes the contribution of the UAV’s]
pose uncertainty to the UWB estimation. By incorporating
this term into the cost function, the uncertainty of the UAV’s
pose is explicitly considered in the optimization process,
leading to a more robust initialization. This approximated
cost function can then be efficiently minimized using iterative
methods such as Gradient Descent or Gauss-Newton. A more

detailed derivation of this approximation process is provided
in App. A of the supplementary material [22].
This coarse estimate will serve as an initial guess for
the tightly-coupled online refinement approach described
in the following section. Before the refinement step, the
state covariance has to be initialized in accordance with

the structure of (3). In particular, we have to initialize the
covariance of the UWB state and its correlations with the

existing state variables as shown in Figure 2. We adopt
a method very similar to the "state variable initialization"
method described in [1]. We first define a state **X** _I_ that
contains the IMU state from timestep _k_ = 0 to _k_ = _m_

as


_⊤_ _⊤_
**X** _I_ = � **x** _I_ 0 **x** _[⊤]_ _I_ 1 _· · ·_ **x** _[⊤]_ _I_ _m_ � (11)


and then stack all the available UWB measurements **d** =
_⊤_
� **d** 0 _· · ·_ **d** _m_ � to construct a stacked measurement model

as


**d** = **h** ( **X** _I_ _,_ **x** _U_ )

**h** ( **X** _I_ _,_ **x** _U_ ) = [ _h_ ( **x** _I_ 0 _,_ **x** _U_ ) _, ..., h_ ( **x** _I_ _m_ _,_ **x** _U_ )] _[⊤]_ (12)



(17)


where **Σ** = diag(Σ 0 _, · · ·,_ Σ _k_ _, · · ·_ Σ _m_ ) denotes the covariance which quantifies the overall system uncertainty. In most
existing works [6], [9], the term Σ _k_ is typically regarded
as the measurement covariance **Q** _d_ . However, as previously



� _⊤_ [�]



**F** = E



_∂ℓ_ ( **d** ; **x** _U_ )

_∂_ **x** _U_

��



_∂ℓ_ ( **d** ; **x** _U_ )
�� _∂_ **x** _U_



_,_ (16)



where the definition of **d** is provided in (12) and **x** _U_ denotes
the UWB state to be estimated; _ℓ_ ( **d** ; **x** _U_ ) represents the loglikelihood function of the measurement model. To calculate
this log-likelihood function _ℓ_ ( **d** ; **x** _U_ ), we first formulate
the corresponding likelihood function, denoted as **p** ( **d** ; **x** _U_ ),
based on the stacked measurement model (12), as follows



1
**p** ( **d** ; **x** _U_ ) = _N_



1 ( **d** _−_ **h** ) _[⊤]_ **Σ** _[−]_ [1] ( **d** _−_ **h** )
2 2 [exp] � �
det(Σ)



_N_
(2 _π_ ) 2


analyzed, uncertainty arises not only from measurement
noise but also from the robot’s localization error. Therefore, it
is crucial to explicitly account for localization uncertainty in
the covariance term **Σ** during initialization. In our approach,
we model the localization uncertainty **P** _II_ _k_ as additional
measurement noise, leading to the modified covariance formulation:


Σ _k_ = **Q** _d_ + **H** _I_ _k_ **P** _II_ _k_ **H** _[⊤]_ _I_ _k_ (18)


It is important to note that the covariance Σ _k_ is also a
function of the UWB estimate **x** _U_, as the value of the
jacobian **H** _I_ _k_ depends on the UWB state **x** _U_, as derived
in Sec. IV-B of the paper. Therefore, both the mean and
covariance of **d** are functions of **x** _U_ . Such a distribution can
be written as **d** _∼N_ ( **h** ( **x** _U_ ) _,_ **Σ** ( **x** _U_ )), which is referred to
as the _General Gaussian Distribution_ [24, Section 3.9]. For
this _General Gaussian Distribution_, there is also a general
expression of the FIM according to [24, Section 3.9], where
the ( _i, j_ )-th element of **F** is given as



camera measurements or UWB ranging measurements as
follow:


**x** ˆ _k_ +1 _|k_ +1 = ˆ **x** _k_ +1 _|k_ ⊞ **Kr**

**P** _k_ +1 _|k_ +1 = **P** _k_ +1 _|k_ _−_ **KSK** _[⊤]_ (20)


where **r** denotes the measurement residual; The Kalman gain
**K** and the innovation **S** can be computed as



**K** = � **KK** _Ur_



� = **P** _k_ +1 _|k_ _−_ � **HH** _[⊤]_ _r_ _[⊤]_ _U_



**S** = � **H** _r_ **H** _U_ � **P** _k_ +1 _|k_



**H** _[⊤]_ _r_
� **H** _[⊤]_ _U_



**S** _[−]_ [1] (21)
�


+ **Q** (22)
�



�



_∂_ **h** ( **x** _U_ )
**F** _ij_ =
� _∂_ **x** _[i]_ _U_



_⊤_
_∂_ **h** ( **x** _U_ )
**Σ** ( **x** _[i]_ _U_ [)] _[−]_ [1]
� � _∂_ **x** _[j]_ _U_



+



_∂_ **x** _[j]_ _U_



�



1
2 **[trace]**



�



**Σ** ( **x** _[i]_ _U_ [)] _[−]_ [1] _[ ∂]_ **[h]** [(] **[x]** _[U]_ [)]




**[h]** [(] **[x]** _[U]_ [)]

**Σ** ( **x** _[i]_ _U_ [)] _[−]_ [1] _[ ∂]_ **[h]** [(] **[x]** _[U]_ [)]
_∂_ **x** _[i]_ _U_ _∂_ **x** _[j]_



where we partition the gain **K** into two parts **K** _r_ and
**K** _U_, denoting the Kalman gain for the active MSCKF state
**x** _r_ and the UWB state **x** _U_, respectively; **H** _r_ and **H** _U_ are
the corresponding state Jacobians. **Q** is the measurement
covariance, which can be either the UWB covariance **Q** _d_ or
the camera covariance **Q** _c_, depending the on measurement
type. This system tightly couples the IMU, camera, and
UWB, allowing for the joint estimation of both the robot
state and the UWB state, where the robot’s localization aids
UWB calibration through a unified estimator. Nevertheless,
the performance of the EKF-based method is highly sensitive
to two key factors: the initial UWB parameters and the
accuracy of the UWB model. If UWB measurements are
naively fused with incorrect initial guesses or an inaccurate
model, it can degrade robot localization performance and
adversely affect UWB calibration results. To better illustrate
this, we conduct numerical tests (cf. Sec. VII-A) to explore
how these factors affect the overall system performance,
which motivates the proposed SKF-based framework for the
UWB calibration.

During the UWB calibration, the robot localization provided by VINS is generally accurate as long as the robot’s
motion is minimal without aggressive maneuvers, whereas
the UWB parameters are uncalibrated and may not be sufficiently accurate. In such cases, using UWB measurements to
update the state with poorly initialized parameters—such as
an incorrect anchor position—can degrade localization accuracy and thus impact UWB calibration. This phenomenon is
confirmed by the simulations described in Sec. VII-A. We
observe that the initialized anchor positions can exhibit significant errors in the z-direction if the robot does not undergo
substantial vertical motion changes during the initialization
process. This initialization error can further lead to additional
localization inaccuracies when the UWB measurements are

used to update the state, causing the refinement step to fail.
**Accuracy of the UWB model:** The accuracy of UWB
measurements can be influenced by several factors, such as
anchor configurations [16] and the presence of obstacles [25].
Although the measurement model in (1) shows satisfactory
performance, it still imperfect that may not accurately capture errors across different scenarios. Deriving a universally
accepted model and determining the noise level is a nontrivial
task. To test the performance with different noise levels
and model parameters, we conduct extensive Monte-Carlo
simulations as described in Sec. VII-A. From Table I, we



(19)



where **x** _[i]_ _U_ [and] **[ x]** _[j]_ _U_ [denotes the] _[ i]_ [-th and] _[ j]_ [-th element of the]
state vector **x** _U_, respectively. A more detailed derivation
and analysis of the FIM is provided in App. B of the
supplementary material [22].

_Remark 2:_ Due to that **Σ** is a function of **x** _U_, the second
term of (19) is non-zero, unlike the FIM with a zeromean Gaussian assumption. Since det( **F** ) is inversely proportional to the uncertainty level, from (19), we can make a
simple inference about the algorithm’s performance: 1) As
the uncertainty in robot localization **x** _I_ _k_ increases, det( **F** )
decreases, leading to reduced initialization accuracy; 2) Static
robot motion or motion constrained to a single plane, such
as movement limited to the xy-plane, can cause det( **F** ) to
become singular, making it unsolvable.


VI. SKF- BASED O NLINE R EFINEMENT

After obtaining an initial estimate of the unknown UWB
parameters, the next step is to refine this estimate, in the following represented as **x** _U_ = _{_ _[G]_ **p** _a_ _i_ _, β_ _i_ _, γ_ _i_ _}_, to obtain a more
accurate calibration. In this section, we propose a SKF-based
estimator built upon the previously discussed MSCKF-based
calibration system (Sec. IV), to perform robust refinement in
a tightly-coupled fashion.


_A. Issues of Standard EKF-based Update_

Before introducing the proposed SKF-based framework,
we first analyze the issues of the standard EKF-based approach and provide numerical tests to demonstrate it, which
motivates the proposed SKF-based approach. According to
the standard EKF, [1] the system state is updated by either


1 Throughout this paper, ˆ **x** _k_ +1 _|k_, ˆ **x** _k_ +1 _|k_ +1 denotes the prior and posterior estimate at time _t_ _k_ +1, respectively. The operator ⊞ denotes the EKF
update process, where the state estimate is corrected using the update _δ_ **x**
as ˆ **x** _k_ +1 _|k_ +1 = ˆ **x** _k_ +1 _|k_ ⊞ _δ_ **x**


observe that both robot localization and UWB calibration can

only be improved when the noise parameters are properly
tuned and the model is accurately defined. If the noise
parameters are tuned too low compared to the true noise
value, fusing the UWB measurements to update the state
will result in inconsistent estimation, ultimately degrading
localization accuracy even with a good initialized UWB
parameters.


_B. SKF-based Update_

As discussed in the previous section, tightly-coupled
VINS-aided UWB calibration heavily relies on the accuracy
of the initialized UWB parameters and the selection of the
measurement model. However, in practice, both of these
factors are highly susceptible to environmental influences,
making it challenging to achieve optimal results simultaneously. Therefore, to achieve accurate UWB calibration
while ensure the performance of robot localization to avoid
potential inaccuracies, we propose to leverage the SchmidtKalman filter (SKF) [26]. The SKF updates only a selected
subset of state variables while keeping the estimates of other
variables fixed. We encourage the readers to refer to [26]
for more detailed introduction. However, it still maintains
consistency by accurately tracking all correlations.
Specifically, during the UWB update, we only update the
UWB state and set the gain of the active MSCKF state to
zero based on the SKF.



**x** ˆ _k_ +1 _|k_ +1 = ˆ **x** _k_ +1 _|k_ ⊞ � **K0** _U_



**r**
�



**P** _k_ +1 _|k_ +1 = **P** _k_ +1 _|k_ _−_ �∆ **P0** _[⊤]_ _rU_ ∆∆ **PP** _UUrU_



(23)
�



(a) Simulated trajectory (b) Anchor initialization errors
Fig. 3: Comparison of RI and LSI under various robot
localization errors.


refinement) across various scenarios, parameter settings, and
noise levels. In the simulation, we utilize the visual-inertial
measurements from the _Euroc datasets_ [28], and simulate
additional UWB ranging measurements from four UWB anchors, with a measurement density of 0 _._ 10 _m_ and a frequency
of 10 _Hz_ . The bias terms ( _β, γ_ ) are set to (0 _._ 9 _, −_ 0 _._ 3m).
The used simulation platform is provided from [20]. The
simulation platform used in this work is provided by [20].


**Robust initialization:** We first evaluate the initialization
performance under varying levels of localization uncertainty.
Monte Carlo simulations were conducted in _Matlab_ by generating UWB measurements and random UAV trajectories
with different localization errors _σ_ _r_ . The anchor position is
�10 10 10 [�] _[⊤]_ . From Fig. 3, when the robot doesn’t have
significant localization error due to it’s small and smooth
motion, the robust initialization (RI) method does not show
significant improvement compared to standard least squares
initialization (LSI) method. However, as the localization
error increases, the error of the LSI method grows rapidly,
whereas the proposed RI method demonstrates robustness
against localization errors. Similar results are observed in
the simulation experiments based on the _Euroc dataset_ . The
proposed RI method outperforms LSI in more challenging
datasets that feature aggressive robot maneuvers.


**SKF-based online refinement:** Based on the setting from
Fig. 1, we first present the results from _MH01, Euroc datasets_
as a representative example to analyze the algorithm’s performance. As shown in Fig. 5, due to the robot’s limited motion
in the z-axis during the UWB initialization, the UWB initial
estimate has a large error in that direction (as we analyzed
in (cf. Sec. V-B)). Thus, the EKF exhibits significant localization errors in the second stage, as it directly fuses the
UWB ranging measurements to update the UAV state using
an imperfect initial UWB estimate from the initialization
step, which negatively impacts both localization accuracy and
calibration. In contrast, the proposed SKF only uses UWB
measurements to update the UWB state during calibration,
ensuring that localization is not affected by inaccurate initial
UWB values and improving the calibration as well. We also
present the estimation results for all trajectories, as illustrated
in Figure 4.
We further evaluate the performance of the SKF-based
method across different UWB initial values and model

accuracies. We introduce additional error _**σ**_ _I_ to the anchor
parameters to simulate varying initialization errors and adjust



with


_⊤_
∆ **P** _rU_ = **K** _r_ **H** _x_ � **P** _[⊤]_ _rU_ **P** _[⊤]_ _UU_ � _,_ ∆ **P** _UU_ = **K** _U_ **SK** _[⊤]_ _U_
(24)


where **P** _rU_ denotes the cross-covariance of between the
active MSCKF state and the UWB state as defined in (3).
Obviously, the active MSCKF state and its covariance do
not change during the UWB calibration, whereas the UWB
state is still being updated and the correlation is still being
tracked. The ranging measurements only update the UWB
state and its correlation, and even with a poor initial guess of
the UWB state or an inaccurate model parameters, the robot’s
localization will remain unaffected during the calibration.
Note that the visual-measurement is still updated based on
the standard EKF as illustrated in Sec. VI-A. To ensure

the consistency of the estimator, we employ First Estimate
Jacobians (FEJ) when computing the Jacobian [27]. The
proposed SKF-based approach guarantees the performance
of robot localization during the UWB calibration, thereby
enhancing the robustness of the calibration process.


VII. E XPERIMENTS AND V ALIDATIONS


_A. Simulated Experiments_

This section presents the simulation experiments to evaluate the performance and robustness of the proposed calibration method (robust initialization and SKF-based online


(a) (c) (d)
(b)

Fig. 4: Estimated trajectories for all trajectory sequences of the _EuRoC MH_ dataset.



TABLE I: Comparison of SKF and EKF under various initial
error _**σ**_ _I_ and noise parameter _**σ**_ _U_ ( _[G]_ **p** � _a_ denotes the anchor
positioning error)


_**σ**_ _I_ ( _m_ ) _**σ**_ _U_ PRMSE (m) _G_ **p** � _a_ (m)

SKF 0.452 0.312
0.1 1.0
EKF **0.379** **0.271**


SKF 0.487 **0.346**
0.3 1.0
EKF **0.466** 0.349


SKF **0.489** **0.352**
0.3 0.9
EKF 0.546 0.408


SKF **0.495** **0.422**
0.5 0.9
EKF 0.679 0.771


(a) EKF (b) SKF
Fig. 5: Comparison of SKF vs. EKF refinement


the UWB noise by multiplying it with a factor, _**σ**_ _U_ (with
_**σ**_ _U_ = 1 indicating accurately tuned noise). As shown in
Table I, we observe that the EKF outperforms the proposed
SKF when the model is accurate and the UWB parameters
have a precise initial guess, as it incorporates the ranging
measurements to jointly update both the robot state and
the UWB state. Nevertheless, achieving both conditions
simultaneously is difficult in real-world scenarios. Extensive
experimental results still demonstrate that a imperfect initial
guess of the UWB parameter can degrade the localization
accuracy of the EKF-based method, which consequently
hurts the calibration results, while the SKF-based method
maintains a robust localization performance across different
initial values. Since the SKF only uses the ranging measurements to update the UWB state without correcting the active
MSCKF state, the accuracy of the initial guess has minimal
effect on localization performance. This effectively reduces
the dependency on the precision of the initial guess.


_B. Real-world Experiments_


We further validate the proposed method by a real-world
dataset, _NTU-VIRAL_ [29], which provides measurement data
of IMU, stereo camera, and UWB ranging measurements



from three anchors.


**Experimental settings:** As illustrated in Fig. 1, the trajectory data of each dataset is divided into three parts for
testing (as we don’t need the complete robot trajectory that
is too for calibration). The first two parts are used to evaluate
the two stages of the proposed calibration framework: robust
initialization and SKF-based online refinement. The third
stage, UWB-aided UAV localization, is performed based
on the completion of the calibration process to evaluate its
effectiveness. In other word, in each running of the trajectory sequence, the robot will first perform the calibration
process then incorporate the calibrated UWB to update the
estimate. Since the the focus of this paper is the robot-aided
calibration process, here we mainly present the calibration
results ( _specifically_ the robot localization and anchor estimation during the calibration process), and compared the
full algorithm results ( _RI+SKF_ ) with _FEJ-VIRO_ [3] (referred
to as VIRO for simplicity), and _RI(proposed)+EKF_ . The
robot localization performance during calibration is evaluated
using the root mean square error (RMSE).


**Calibration results analysis:** Table II presents the trajectory
accuracy and anchor estimation accuracy for all methods.
Since we only used a portion of the trajectory for calibration, the results are based solely on that segment of the
trajectory. We observe that the proposed RI method improves
anchor estimation across all trajectory trials. Additionally,
_RI+EKF_ achieves the best performance in both localization
and calibration when the robot avoids aggressive motion and
its movement is not restricted to a single plane during the
initialization phase, with VIRO showing almost comparable
results. This is because the robot’s smooth motion ensures an

accurate UWB initialization process. With a reliable initial
UWB estimate, both methods update the robot and UWB
states jointly using EKF during the refinement phase, leading
to more accurate state estimation and calibration than SKF,
which only updates the UWB state during calibration. However, this approach significantly limits the robot’s movement.
If the robot experiences larger drifts during initialization, it
compromises the accuracy of the process. The joint EKF
update of the robot and UWB states, when based on an
inaccurate initial UWB estimate, further degrades both localization and calibration in the EKF-based _VIRO_ and _RI+EKF_

methods. In such cases, the SKF method proves more robust,
as it better calibrates the UWB, ensuring that localization is
less affected by a poor initial UWB estimate.


TABLE II: Performance of the proposed calibration method
in _NTU-VIRAL dataset_ (on calibration trajectory segments
only)


Dataset Algorithms PRMSE (m) ORMSE (deg) _G_ **p** � _a_ (m)



eee01


eee03


nya01



VIRO 0.351 5.725 0.485

RI+EKF 0.300 5.723 0.408

RI+SKF **0.287** **5.626** **0.346**


VIRO 0.329 4.867 0.425

RI+EKF **0.289** **4.865** **0.422**

RI+SKF 0.325 4.871 0.429


VIRO 0.326 4.652 0.412

RI+EKF 0.319 4.674 0.388

RI+SKF **0.301** **4.600** **0.375**


VIII. C ONCLUSION



This paper presents a robust online calibration framework
for UWB-aided VINS systems, addressing the limitations of
previous methods that were sensitive to localization errors
and initial anchor guesses. By incorporating robot localization uncertainty into the UWB initialization process and
employing a tightly-coupled SKF-based online refinement,
the proposed method significantly enhances calibration accuracy and robustness. Extensive simulated and real-world
experiments validate the effectiveness of the approach. In
the future, we plan to extend the framework proposed in
this paper to develop active planning-based calibration algorithms. The focus will be on studying the impact of robot
trajectories, localization errors, and anchor placement on the
calibration results.


R EFERENCES


[1] P. Geneva, K. Eckenhoff, W. Lee, Y. Yang, and G. Huang, “Openvins:
A research platform for visual-inertial estimation,” in _2020 IEEE_
_International Conference on Robotics and Automation (ICRA)_, 2020,
pp. 4666–4672.

[2] T. Qin, P. Li, and S. Shen, “Vins-mono: A robust and versatile monocular visual-inertial state estimator,” _IEEE Transactions on Robotics_,
vol. 34, no. 4, pp. 1004–1020, 2018.

[3] S. Jia, Y. Jiao, Z. Zhang, R. Xiong, and Y. Wang, “Fej-viro: A
consistent first-estimate jacobian visual-inertial-ranging odometry,” in
_2022 IEEE/RSJ International Conference on Intelligent Robots and_
_Systems (IROS)_, 2022, pp. 1336–1343.

[4] C. Hu, P. Huang, and W. Wang, “Tightly coupled visual-inertial-uwb
indoor localization system with multiple position-unknown anchors,”
_IEEE Robotics and Automation Letters_, vol. 9, no. 1, pp. 351–358,
2024.

[5] T.-M. Nguyen, M. Cao, S. Yuan, Y. Lyu, T. H. Nguyen, and L. Xie,
“Liro: Tightly coupled lidar-inertia-ranging odometry,” in _2021 IEEE_
_International Conference on Robotics and Automation (ICRA)_, 2021,
pp. 14 484–14 490.

[6] J. Hu, Y. Li, Y. Lei, Z. Xu, M. Lv, and J. Han, “Robust and adaptive
calibration of uwb-aided vision navigation system for uavs,” _IEEE_
_Robotics and Automation Letters_, vol. 8, no. 12, pp. 8247–8254, 2023.

[7] J. Blueml, A. Fornasier, and S. Weiss, “Bias compensated uwb anchor initialization using information-theoretic supported triangulation
points,” in _2021 IEEE International Conference on Robotics and_
_Automation (ICRA)_, 2021, pp. 5490–5496.

[8] T. H. Nguyen, T.-M. Nguyen, and L. Xie, “Tightly-coupled singleanchor ultra-wideband-aided monocular visual odometry system,” in
_2020 IEEE International Conference on Robotics and Automation_
_(ICRA)_, 2020, pp. 665–671.

[9] T. H. Nguyen and L. Xie, “Estimating odometry scale and uwb
anchor location based on semidefinite programming optimization,”
_IEEE Robotics and Automation Letters_, vol. 7, no. 3, pp. 7359–7366,
2022.




[10] C. Wang, H. Zhang, T.-M. Nguyen, and L. Xie, “Ultra-wideband aided
fast localization and mapping system,” in _2017 IEEE/RSJ International_
_Conference on Intelligent Robots and Systems (IROS)_, 2017, pp. 1602–
1609.

[11] F. J. Perez-Grau, F. Caballero, L. Merino, and A. Viguria, “Multimodal mapping and localization of unmanned aerial robots based on
ultra-wideband and rgb-d sensing,” in _2017 IEEE/RSJ International_
_Conference on Intelligent Robots and Systems (IROS)_, 2017, pp. 3495–
3502.

[12] J.-R. Zhan and H.-Y. Lin, “Improving visual inertial odometry with
uwb positioning for uav indoor navigation,” in _2022 26th International_
_Conference on Pattern Recognition (ICPR)_, 2022, pp. 4189–4195.

[13] B. Yang, J. Li, and H. Zhang, “Uvip: Robust uwb aided visual-inertial
positioning system for complex indoor environments,” in _2021 IEEE_
_International Conference on Robotics and Automation (ICRA)_, 2021,
pp. 5454–5460.

[14] S. Shin, E. Lee, J. Choi, and H. Myung, “Mir-vio:mutual information
residual-based visual inertial odometry with uwb fusion for robust
localization,” in _2021 21st International Conference on Control, Au-_
_tomation and Systems (ICCAS)_, 2021, pp. 91–96.

[15] S. Zheng, Z. Li, Y. Liu, H. Zhang, P. Zheng, X. Liang, Y. Li, X. Bu, and
X. Zou, “Uwb-vio fusion for accurate and robust relative localization
of round robotic teams,” _IEEE Robotics and Automation Letters_, vol. 7,
no. 4, pp. 11 950–11 957, 2022.

[16] W. Zhao, J. Panerati, and A. P. Schoellig, “Learning-based bias
correction for time difference of arrival ultra-wideband localization of
resource-constrained mobile robots,” _IEEE Robotics and Automation_
_Letters_, vol. 6, no. 2, pp. 3639–3646, 2021.

[17] S. Jia, R. Xiong, and Y. Wang, “Distributed initialization for visualinertial-ranging odometry with position-unknown uwb network,” in
_2023 IEEE International Conference on Robotics and Automation_
_(ICRA)_, 2023, pp. 6246–6252.

[18] G. Delama, F. Shamsfakhr, S. Weiss, D. Fontanelli, and A. Fomasier,
“Uvio: An uwb-aided visual-inertial odometry framework with biascompensated anchors initialization,” in _2023 IEEE/RSJ International_
_Conference on Intelligent Robots and Systems (IROS)_, 2023, pp. 7111–
7118.

[19] A. I. Mourikis and S. I. Roumeliotis, “A multi-state constraint kalman
filter for vision-aided inertial navigation,” in _Proceedings 2007 IEEE_
_International Conference on Robotics and Automation_, 2007, pp.
3565–3572.

[20] K. Sun, K. Mohta, B. Pfrommer, M. Watterson, S. Liu, Y. Mulgaonkar,
C. J. Taylor, and V. Kumar, “Robust stereo visual inertial odometry
for fast autonomous flight,” _IEEE Robotics and Automation Letters_,
vol. 3, no. 2, pp. 965–972, 2018.

[21] S. Boyd and L. Vandenberghe, _Convex Optimization_ . Cambridge
University Press, 2004.

[22] Y. Zhou, “Supplementary materials: A consistent and tightly-coupled
visual-inertial-ranging odometry on lie groups,” 2025. [Online].
[Available: https://mason.gmu.edu/~xwang64/papers/rcvin_supp.pdf](https://mason.gmu.edu/~xwang64/papers/rcvin_supp.pdf)

[23] Z. Wang and G. Dissanayake, “Observability analysis of slam using
fisher information matrix,” in _2008 10th International Conference on_
_Control, Automation, Robotics and Vision_, 2008, pp. 1242–1247.

[24] S. M. Kay, _Fundamentals of Statistical Signal Processing: Estimation_
_Theory_ . Upper Saddle River, NJ, USA: Prentice-Hall, Inc., 1993.

[25] D.-H. Kim, G.-R. Kwon, J.-Y. Pyun, and J.-W. Kim, “Nlos identification in uwb channel for indoor positioning,” in _2018 15th IEEE Annual_
_Consumer Communications & Networking Conference (CCNC)_, 2018,
pp. 1–4.

[26] K. Eckenhoff, P. Geneva, N. Merrill, and G. Huang, “Schmidt-ekfbased visual-inertial moving object tracking,” in _2020 IEEE Inter-_
_national Conference on Robotics and Automation (ICRA)_, 2020, pp.
651–657.

[27] G. P. Huang, A. I. Mourikis, and S. I. Roumeliotis, “A firstestimates jacobian ekf for improving slam consistency,” in _Experimen-_
_tal Robotics_, O. Khatib, V. Kumar, and G. J. Pappas, Eds. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2009, pp. 373–382.

[28] M. Burri, J. Nikolic, P. Gohl, T. Schneider, J. Rehder, S. Omari, M. W.
Achtelik, and R. Siegwart, “The euroc micro aerial vehicle datasets,”
_The International Journal of Robotics Research_, vol. 35, no. 10, pp.
1157–1163, 2016.

[29] T.-M. Nguyen, S. Yuan, M. Cao, Y. Lyu, T. H. Nguyen, and L. Xie,
“Ntu viral: A visual-inertial-ranging-lidar dataset, from an aerial
vehicle viewpoint,” _The International Journal of Robotics Research_,
vol. 41, no. 3, pp. 270–280, 2022.


