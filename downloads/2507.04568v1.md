## **The Difference between the Left and Right Invariant Extended** **Kalman Filter**

P REPRINT _[⋆]_



**Yixiao Ge** _[∗]_
Systems Theory and Robotics Group
School of Engineering
Australian National University
ACT, 2601, Australia

```
  Yixiao.Ge@anu.edu.au

```


**Giulio Delama**
Control of Networked Systems Group
University of Klagenfurt
Klagenfurt, Austria
```
  giulio.delama@aau.at

```


**Martin Scheiber**
Control of Networked Systems Group
University of Klagenfurt
Klagenfurt, Austria
```
  martin.scheiber@aau.at

```


**Alessandro Fornasier**
Hexagon Robotics
Z¨urich, Switzerland
```
alessandrofornasierphd@gmail.com

```

**Stephan Weiss**
Control of Networked Systems Group
University of Klagenfurt
Klagenfurt, Austria
```
    stephan.weiss@aau.at

```


**Pieter van Goor**
Robotics and Mechatronics (RaM) Group
EEMCS Faculty
University of Twente
Enschede, The Netherlands
```
  p.c.h.vangoor@utwente.nl

```

**Robert Mahony**
Systems Theory and Robotics Group
School of Engineering
Australian National University
ACT, 2601, Australia
```
  Robert.Mahony@anu.edu.au

```


July 8, 2025


**A** **BSTRACT**


The extended Kalman filter (EKF) has been the industry standard for state estimation problems over the
past sixty years. The Invariant Extended Kalman Filter (IEKF) [1] is a recent development of the EKF for
the class of group-affine systems on Lie groups that has shown superior performance for inertial navigation
problems. The IEKF comes in two versions, left- and right- handed respectively, and there is a perception
in the robotics community that these filters are different and one should choose the handedness of the IEKF
to match handedness of the measurement model for a given filtering problem. In this paper, we revisit these
algorithms and demonstrate that the left- and right- IEKF algorithms (with reset step) are identical, that is, the
choice of the handedness does not affect the IEKF’s performance when the reset step is properly implemented.
The reset step was not originally proposed as part of the IEKF, however, we provide simulations to show that
the reset step improves asymptotic performance of all versions of the the filter, and should be included in
all high performance algorithms. The GNSS-aided inertial navigation system (INS) is used as a motivating
example to demonstrate the equivalence of the two filters.


**1** **Introduction**


The Extended Kalman filter (EKF) has been the industry standard nonlinear state estimation algorithm for the past sixty years

[2, 3]. The original formulation of the EKF was developed for systems evolving on global Euclidean spaces [4], however,
the first application of EKF, where it was applied to attitude estimation problem in the Apollo mission [5], involved a system
evolving on the special orthogonal group **SO** (3). The advent of uncrewed aerial vehicles (UAVs) led to increased research
focus on the attitude filtering problem [6, 7]. This in turn led to a surge in the development of filtering algorithms for systems
evolving on general Lie groups and homogeneous spaces. Motivated by the attitude estimation problem and the more general
question of building inertial navigation systems, Bonnabel _et al._ proposed the Invariant Extended Kalman Filter (IEKF), a


_⋆_ Under review


P REPRINT


general filtering methodology for systems on lie groups, in a series of works [8, 9]. In [10, 11], Chirikjian _et al._ showed that
for left invariant kinematics on Lie groups, the error linearisation in the propagation stage is global, an important foundation
for high performance filtering algorithms. In [1], Barrau and Bonnabel identified a class of ‘group affine’ systems, for which
they showed that the IEKF provides global error linearisation in the predict step. Indeed, if the system admits a group-affine
structure with left- (resp. right-) invariant inputs and right- (resp. left) equivariant outputs, then under a specific choice of
covariance gains the convergence rate and basin of attraction of the IEKF becomes _trajectory-independent_ [12]. In a parallel
research thread, Mahony _et al._ [13, 14, 15] proposed the equivariant filter (EqF), a general filter design methodology for systems
evolving on homogeneous spaces, which specialises to the IEKF when the symmetry Lie groups and the state space are the

same.


The IEKF is an error-state EKF that is derived by linearising the error dynamics, where the state estimation error can be defined
using the _left-_ or _right-invariant_ error defined on a Lie group. The choice of the handedness of the error state leads to two
different formulations of the IEKF, the left (L-IEKF) and the right (R-IEKF) filters. There has been a long-standing argument
in the literature that the choice of the handedness of the IEKF should be made to match the measurement model [1]. Leftversus right- observation models are also sometimes referred to as the _spatial_ or _global_ measurements versus _ego_ or _local_
measurements [16]. Typical spatial measurement models include global navigation satellite system (GNSS) measurements,
while ego measurements are provided by body frame sensors such as inertial measurement units (IMUs), wheel odometers and
cameras [17].


In this paper, we use the concept of concentrated Gaussian distributions [18, 19] to derive the left- and right- IEKFs. We go on to
show that the left- and right- IEKF algorithms (including reset step) are stochastically equivalent; that is, they generate identical
updates of the concentrated Gaussian parameters. The conclusion is that the choice to implement an IEKF (including reset step)
with either left- or right-invariant error is arbitrary. Nevertheless, we go on to provide some analysis of the potential differences.
Firstly, discretising the continuous-time filter equations in the left- or right- representations introduces error between the filters
and choosing the representation for which the error dynamics are closest to linear will yield some advantage. However, if the
update is expressed explicitly as a discrete equivariant update, then equivalence is recovered (A). Secondly, choosing not to
implement the reset step also breaks the equivalence. We show empirically that the matched filter appears to benefit slightly
during the transient phase, at least for the INS problem considered. However, we also demonstrate empirically that the reset
step appears to always benefit the asymptotic phase of the filter in all algorithms, a result that aligns with prior work in the
literature [20]. We have chosen to focus on the popular imperfect IEKF filters [1] for which the question of left- versus rightimplementations is most contested in the literature. However, the main results of the paper apply to all of the filters discussed
in the recent paper [21], including the IEKF [1] and the TFG-IEKF [22]. Furthermore, since the filter is implemented on the
lifted system on the Lie group, the results also apply to the more general Equivariant Filters [14]. This paper is complementary
to the very recent parallel work by Maurer _et al._ [23], which contains some closely related equivalence proofs. In this paper,
we go further in analysing discrete-time systems, considering equivariant outputs, and investigating the role of the reset step in
the R-IEKF and L-IEKF.


**2** **Preliminaries**


Let _M_ be a smooth manifold with dimension _m_ . The tangent space at a point _ξ ∈_ _M_ is denoted T _ξ_ _M_ . The tangent bundle is
denoted T _M_ . Given a differentiable function between smooth manifolds _h_ : _M →_ _N_, its derivative at _ξ_ _[◦]_ is written as


D _ξ_ _|_ _ξ_ _◦_ _h_ ( _ξ_ ) : T _ξ_ _◦_ _M →_ T _h_ ( _ξ_ _◦_ ) _N ._


The notation D _h_ : T _M →_ T _N_ denotes the differential of _h_ with an implicit base point.


Let **G** be a general Lie group with dimension _n_, associated with the Lie algebra g. Let id denote the identity element of **G** .
Given arbitrary _X, Y ∈_ **G**, the left and right translations are denoted by L _X_ _,_ R _X_ : **G** _→_ **G**, and are defined by


L _X_ ( _Y_ ) := _XY,_ R _X_ ( _Y_ ) := _Y X._


The Lie algebra g is isomorphic to a vector space R _[n]_ with the same dimension. We use wedge ( _·_ ) _[∧]_ : R _[n]_ _→_ g and vee
( _·_ ) _[∨]_ : g _→_ R _[n]_ operators to map between the Lie algebra and the vector space. The Adjoint map for the group **G**, Ad _X_ : g _→_ g
is defined by
Ad _X_ [ _u_ _[∧]_ ] = DL _X_ _◦_ DR _X_ _−_ 1 [ _u_ _[∧]_ ] _,_
for every _X ∈_ **G** and _u_ _[∧]_ _∈_ g, where DL _X_, and DR _X_ denote the differentials of the left and right translations, respectively.
The adjoint map for the Lie algebra ad _u_ _∧_ : g _→_ g is given by


ad _u_ _∧_ _v_ _[∧]_ = [ _u_ _[∧]_ _, v_ _[∧]_ ] _,_


and is equivalent to the Lie bracket. Given particular wedge and vee maps, the Adjoint matrix Ad _[∨]_ _X_ _[∈]_ [R] _[n][×][n]_ [ and adjoint matrix]
ad _[∨]_ _u_ _[∈]_ [R] _[n][×][n]_ [ are defined by]


Ad _[∨]_ _X_ _[u]_ [ = (Ad] _[X]_ _[u]_ _[∧]_ [)] _[∨]_ _[,]_

ad _[∨]_ _u_ _[v]_ [ = (] _[u]_ _[∧]_ _[v]_ _[∧]_ _[−]_ _[v]_ _[∧]_ _[u]_ _[∧]_ [)] _[∨]_ [= [] _[u]_ _[∧]_ _[, v]_ _[∧]_ []] _[∨]_ _[.]_


2


P REPRINT


Let exp **G** : g _→_ **G** denote the exponential map from the Lie algebra to the group. For matrix Lie groups such as **SO** (3) _,_ **SE** (3),
this map is simply the matrix exponential. Let **G** _[′]_ _⊂_ **G** be the subset of **G** where the exponential map is invertible, then one
can define the logarithm map log **G** : **G** _[′]_ _→_ g and log _[∨]_ **G** [:] **[ G]** _[′]_ _[ →]_ [R] _[n]_ [.]


**3** **Problem Description**


Consider a system evolving on an _m_ -dimensional Lie group **G** . The input space L is a _ℓ_ -dimensional linear space. The
continuous-time noise-free system dynamics are given by


_X_ ˙ = _f_ _v_ ( _X_ ) = _X_ Λ( _X, v_ ) _,_ (1)


where _X ∈_ **G** denotes the state of the system, and _f_ : L _→_ X( **G** ), _v �→_ _f_ _v_ _∈_ X( **G** ) is the system function with left
trivialization Λ : **G** _×_ L _→_ g given by Λ( _X, v_ ) := _X_ _[−]_ [1] _f_ _v_ ( _X_ ). For example, if the system has a spatial velocity _W ∈_ g such
that _X_ ˙ = _WX,_

then the model that we use is ˙
_X_ = _X_ Ad _X_ _−_ 1 _W_ = _X_ Λ( _X, W_ ) _._

**Remark 3.1.** _While the left-handed trivialisation is the standard representation in the literature, it is, of course, possible to_
_redo all the theory in right-handed trivialisation. However, since most robotics systems admit both spatial and body velocities,_
_such as the INS problem discussed in Sec. 6, there is no simplification in the formulas obtained in choosing one handedness_
_over the other._


In this work, we assume that the noise process entering the system dynamics is left-invariant, that is, the noise process can be
written as a stochastic differential equation


1
d _X_ = _X_ Λ( _X, v_ )d _t_ + Υ[ _Q_ 2 d _w_ ] (2)
� �


where d _w_ is a Brownian motion in R _[ℓ]_, Υ[ _·_ ] : R _[ℓ]_ _→_ g is a constant linear operator, and _Q ∈_ S + ( _ℓ_ ) is a positive definite
matrix. This model corresponds to the models considered recently in the literature [24, 23]. Understanding the noise model in
invariant filtering is still an active topic [13], however, the authors believe that sensible alternative choices of noise models will
not change the equivalence proof, and the assumption made here is sufficiently general to cover most of the cases in practice.


The configuration output is a discrete measurement process given by the output function _h_ : **G** _→_ R _[n]_


_y_ ( _t_ _k_ ) = _h_ ( _X_ ( _t_ _k_ )) + _ν_ _k_ _ν_ _k_ _∼_ **N** (0 _, R_ _k_ ) _,_ (3)


at times _{t_ 1 _, . . ., t_ _k_ _, . . .}_ and where _ν_ _k_ is a zero-mean white noise with covariance _R_ _k_ _∈_ S + ( _n_ ).


Systems of this form given by (1) and (3) are termed _hybrid_ systems and provide a good model for filter design for most
robotic systems with fast input measurements and slow configuration measurements. We also consider fully discrete-time
implementations of the IEKF in A.


**4** **Left and Right IEKF Definition**


In this section, we present a formal definition of the L-IEKF and R-IEKF. We start with the probability distributions associated
with the two filters and derive the IEKFs in terms of the predict, update and reset steps for Kalman filters [20].


**4.1** **Concentrated Gaussian Distribution**


The underlying goal of a stochastic filter is to estimate the probability density function of the system state given the measured
inputs and outputs. We use the concept of extended concentrated Gaussian distribution [10, 15, 19] to model the information
state of the system. Note that concentrated Gaussians depend on handedness, that is, they can be defined using left multiplication
or right multiplication. The two representations can be shown to be equivalent through the Ad operation.


For an _m_ -dimensional random variable _g ∈_ **G**, the left-concentrated Gaussian distribution (L-CGD) is defined as


_p_ [L] ( _g_ ; _x, µ,_ Σ) = _α_ exp _−_ [1] **G** � _x_ _[−]_ [1] _g_ � _−_ _µ_ _[∨]_ _|_ Σ _−_ 1 _,_ (4)
� 2 _[|]_ [log] _[∨]_ �


where _x ∈_ **G** is termed the _reference point_, _µ ∈_ g is termed the _mean_ and _α ∈_ R is the normalising factor. The _covariance_
Σ _∈_ S + ( _m_ ) is an _m × m_ symmetric and positive definite matrix. This is equivalent to defining a random variable


_g_ = _x_ exp **G** ( _ϵ_ ) _,_ _ϵ ∼_ **N** ( _µ_ _[∨]_ _,_ Σ) _,_


where **N** denotes the Gaussian process on R _[m]_ .


3


P REPRINT


Similarly, the right-concentrated Gaussian distribution (R-CGD) is defined as


_p_ [R] ( _g_ ; _x, µ,_ Σ) = _α_ exp _−_ [1] **G** � _gx_ _[−]_ [1] [�] _−_ _µ_ _[∨]_ _|_ Σ _−_ 1 _,_ (5)
� 2 _[|]_ [log] _[∨]_ �


which is equivalent to the random variable definition


_g_ = exp **G** ( _ϵ_ ) _x,_ _ϵ ∼_ **N** ( _µ_ _[∨]_ _,_ Σ) _._


For the rest of this paper, we will use **N** [L] _x_ L [(] _[µ]_ [L] _[,]_ [ Σ] [L] [)][ and] **[ N]** _x_ [R] R [(] _[µ]_ [R] _[,]_ [ Σ] [R] [)][ to denote the L-CGD and R-CGD, respectively. The]
log-likelihood of a L-CGD is defined by

_L_ L ( _µ_ L _, x_ L _,_ Σ L ) := [1] 2 _[|]_ [ log] **[G]** [(] _[x]_ L _[−]_ [1] _[g]_ [)] _[ −]_ _[µ]_ [L] _[|]_ [2] Σ _[−]_ L [1] _[.]_


where we treat the scaling factor as a cumulant offset and ignore it. The log-likelihood of a R-CGD is

_L_ R ( _µ_ R _, x_ R _,_ Σ R ) := 2 [1] _[|]_ [ log] **[G]** [(] _[gx]_ R _[−]_ [1] [)] _[ −]_ _[µ]_ [R] _[|]_ [2] Σ _[−]_ R [1] _[.]_


The information state of the L-IEKF with L-CGD for state representation is finite dimensional and is parameterised by a triple
( _µ_ L _, x_ L _,_ Σ L ) _∈_ g _×_ **G** _×_ S + ( _m_ ), representing the offset (or mean), the reference state (or group mean), and the covariance,
respectively. When the offset _µ_ = 0 then the reference is the group mean as understood by a classical concentrated Gaussian

[10]. The R-IEKF state is similarly composed of ( _µ_ R _, x_ R _,_ Σ R ) _∈_ g _×_ **G** _×_ S + ( _m_ ).


If _x_ R = _x_ L then one has


exp **G** ( _ε_ R ) _x_ R = _x_ R _x_ _[−]_ R [1] [exp] **G** [(] _[ε]_ [R] [)] _[x]_ [R]
= _x_ L exp **G** (Ad _x_ _−_ R 1 _[ε]_ [R] [)] _[.]_


It follows that if _x_ R = _x_ L and



_ε_ L = Ad _x_ _−_ R 1 _[ε]_ [R] _[ ∼]_ **[N]** [(Ad] _[x]_ _[−]_ R [1] _[µ]_ [R] _[,]_ [ Ad] _x_ _[∨]_ _[−]_ R [1] [Σ] [R] [Ad] _x_ _[∨]_ _[−]_ R [1]



_⊤_
)



then the information state captured by the two filters is identical. This property is used to prove the equivalence of the two
filters in the following sections (see also [17]).


The underlying integration measure associated with the definition of left- and right- concentrated Gaussians is implicit in the
Euclidean coordinates placed on the Lie algebra. In the case where the Lie group is unimodal, it is possible to define a biinvariant Haar measure directly on the group [18]. Choosing a different measure will subtly alter the global structure of the
pdf on the group, however, the local structure of the pdf will not be affected and in particular, the second-order statistics (mean
and covariance) expressed in the algebra coordinates will be unchanged. The EKF trajectory tracks only the local second-order
statistics of the probability densities in local coordinates. It follows that changing the measure on the group will not change the
EKF algorithm, even though the associated pdf is different.


**Remark 4.1.** _By EKF algorithms, we mean algorithms where the filter steps are based on linearisation of the underlying system._
_Algorithms such as the well-known unscented Kalman filter (UKF) [25], or where integral properties of the distributions are_
_used [24], are not true EKFs in this sense. The authors note that the UKF has been shown to have advantages in certain_
_situations and there is active research into other more sophisticated algorithms that may lead to new filters that outperform the_
_more classical IEKF. The focus of the paper is only on proving the equivalence of the left- and right- version of the IEKF._


**4.2** **IEKF definition**


In this section, we define the IEKF dynamics for a hybrid system given by (1) and (3), that is, with continuous propagation
and discrete measurement update. The meaning of the parameters for a left or right filter implementation will be interpreted in
terms of the left or right concentrated Gaussian distributions, respectively.


**4.2.1** **Notation**


An IEKF is often stated as an algorithm with states ( _X,_ [ˆ] Σ), however, in order to properly capture the reset step inherent in the
EKF formulation, we use the extended concentrated Gaussian to model the filter state, given by ( _µ,_ _X,_ [ˆ] Σ). Considering the
reset step explicitly requires notation that captures the state of the filter through the three stages of the filter: _predict_, _update_
and _reset_ . We will use the following notation for the state of the filter:


predict update reset
_X_ _k|k_ _X_ _k_ _[−]_ +1 _|k_ _X_ _k_ [+] +1 _|k_ _X_ _k_ +1 _|k_ +1


4


P REPRINT


Here, the full state of the filter is referred to without superscripts. We use a superscript ‘-’ to indicate prediction without update.
The ‘+’ indicates that the new information available at time _k_ + 1 has been used to update the state, but expressed in the old
coordinates. Finally, the reset step returns the full filter state in the new coordinates.


In the rest of this section, we will formulate the L-IEKF and R-IEKF by defining the error dynamics and deriving each single
filter step. Since the whole discussion occurs for filter step _k_ + 1 we will suppress the index and replace it by a subscript that
indicates the different filter handedness. In particular, we will use the notation


predict
( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) `�` ( _µ_ _[−]_ L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] _[−]_ L [)]


```
       �

```

new filter step


```
          �

```

new filter step update


( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) ( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L [+] _[,]_ [ Σ]


```
   �

```

reset ( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L [+] _[,]_ [ Σ] [+] L [)]


```
                           �

```

for the _k_ + 1 step of the L-IEKF and use analogous notation for the R-IEKF. Where the particular filter step is important we
will write ( _µ_ L ( _t_ _k_ ) _,_ _X_ [ˆ] L ( _t_ _k_ ) _,_ Σ L ( _t_ _k_ )) and analogously for the right-handed implementation. Even though the notations used in
different steps are different, the values of some elements remain the same across steps, for example, both _µ_ L and _µ_ _[−]_ L [are zero,]
which we discuss in the following sections.


**4.2.2** **Error definition**


The propagation step of the filter is associated with how the infinitesimal error in the neighbourhood of the true trajectory
propagates. For a classical error-state EKF, the error used is the Euclidean difference in local coordinates. In the case of
systems on Lie-groups, there is an intrinsic definition of error, termed the _left-_ or _right-invariant_ errors given by


_E_ L := _X_ [ˆ] _[−]_ [1] _X,_ and _E_ R := _XX_ [ˆ] _[−]_ [1] _._


respectively. Note that it is also possible to study the inverses of these errors, namely _E_ L _[−]_ [1] = _X_ _[−]_ [1] [ ˆ] _X_ and _E_ R _[−]_ [1] = _XX_ [ˆ] _[−]_ [1], but
it is well established that inverting the error does not change the filter.


Let _v_ _m_ denote the measured velocity, the error dynamics are given by


d
L _[X]_ [ + ˆ] _[X]_ L _[−]_ [1] _[X]_ [Λ(] _[X, v]_ [)]
d _t_ _[E]_ [L] [ =] _[ −]_ [Λ( ˆ] _[X]_ [L] _[, v]_ _[m]_ [) ˆ] _[X]_ _[−]_ [1]

= _−_ Λ( _X_ [ˆ] L _, v_ _m_ ) _E_ L + _E_ L Λ( _X, v_ ) _,_

d ˆ
Λ( _X, v_ ) _−_ Λ( _X_ [ˆ] R _, v_ _m_ ) _X_ R _[−]_ [1]
d _t_ _[E]_ [R] [ =] _[ X]_ � �


```
         �

```

= _E_ R Ad _X_ ˆ R


```
    �

```

Λ( _X, v_ ) _−_ Λ( _X_ [ˆ] R _, v_ _m_ ) _._
� �


```
                           �

```

Recalling (2), then for the case of left-invariant error one has


d _E_ L = _−_ Λ( _X_ [ˆ] L _, v_ _m_ ) _E_ L d _t_ + _E_ L Λ( _X, v_ )d _t_


1
= _−_ Λ( _X, v_ [ˆ] )d _t_ + Υ[ _Q_ 2 d _w_ ] _E_ L + _E_ L Λ( _X, v_ )d _t_
� �


1
= _−_ Λ( _X, v_ [ˆ] ) _E_ L + _E_ L Λ( _X, v_ ) d _t −_ Υ[ _Q_ 2 d _w_ ] _E_ L
� �


1
= _−_ Λ( _X, v_ [ˆ] ) _E_ L + _E_ L Λ( _X, v_ ) d _t −_ DR _E_ L Υ[ _Q_ 2 d _w_ ] _._ (6)
� �


For the case of right-handed error one has


```
             �

```

d _E_ R = _E_ R Ad _X_ ˆ R


= _E_ R Ad _X_ ˆ R


= _E_ R Ad _X_ ˆ R


```
      �

```

Λ( _X, v_ ) _−_ Λ( _X, v_ [ˆ] _m_ ) d _t_
� �


1
Λ( _X, v_ )d _t −_ Λ( _X, v_ [ˆ] )d _t −_ Υ[ _Q_ 2 d _w_ ]
� �


Λ( _X, v_ ) _−_ Λ( _X, v_ [ˆ] ) d _t_
� �


1
_−_ DL _E_ R Ad _X_ ˆ R [Υ[] _[Q]_ 2 d _w_ ] _._ (7)


```
                           �

```

Note that in both cases the noise enters linearly in the Υ term. In the case of the left-handed error coordinates there is a simple
DR _E_ L that is suppressed in the linearisation (9). Conversely, in the right-handed error term there is an Ad _X_ ˆ R [Υ][ term through]
which the noise enters (11). While the noise appears to be ”transformed” by the adjoint, it is still linear in the underlying noise
process as Ad _X_ ˆ R [is a linear operator on the Lie algebra.]


5


P REPRINT


**4.2.3** **Predict**


Consider the system dynamics (1), the L-IEKF and R-IEKF dynamics in the predict step are obtained through propagating the
reference state by the continuous-time system model, and propagating the covariance by linearising the error dynamics (6) and
(7) of _E_ L and _E_ R, respectively.

**Definition 4.2** (L-IEKF prediction dynamics) **.** _Let_ ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) _denote the L-IEKF state with µ_ L = 0 _at time t_ _k_ _. Note that the_
_subscript k has been dropped. The prediction is given by integrating the dynamics_ (1) _over the interval_ [ _t_ _k_ _, t_ _k_ +1 ] _:_
_µ_ ˙ L = 0 _,_ _µ_ L ( _t_ _k_ ) = 0
_X_ ˙ˆ L = _f_ _v_ _m_ ( ˆ _X_ L ) _,_ _X_ ˆ L ( _t_ _k_ ) = ˆ _X_ L
˙Σ L = _A_ L Σ L + Σ L _A_ _[⊤]_ L [+] _[ B]_ [L] _[QB]_ L _[⊤]_ Σ L ( _t_ _k_ ) = Σ L

_where A_ L _and B_ L _are the linearisation of the system_ (1)
_A_ L := D _X_ _|_ _X_ ˆ L [Λ(] _[X, v]_ _[m]_ [)] _[ ·]_ [ DL] _X_ [ ˆ] L [(] _[I]_ [)] _[ −]_ [ad] _[∨]_ Λ( _X_ [ˆ] L _,v_ _m_ ) _[,]_ (8)

_B_ L := D _u_ _|_ _v_ _m_ Λ( _X_ [ˆ] L _, u_ ) = Υ _._ (9)

_The output is_

_µ_ _[−]_ L [= 0] _[,]_
_X_ ˆ L _[−]_ [= ˆ] _[X]_ [L] [(] _[t]_ _[k]_ [+1] [)] _[,]_


Σ _[−]_ L [= Σ] [L] [(] _[t]_ _[k]_ [+1] [)] _[.]_

**Definition 4.3** (R-IEKF prediction dynamics) **.** _Let_ ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) _denote the R-IEKF state with µ_ R = 0 _at time t_ _k_ _. Note that_
_the subscript k has been dropped. The prediction is given by integrating the dynamics_ (1) _over the interval_ [ _t_ _k_ _, t_ _k_ +1 ] _:_
_µ_ ˙ R = 0 _,_ _µ_ R ( _t_ _k_ ) = 0
_X_ ˙ˆ R = _f_ _v_ _m_ ( ˆ _X_ R ) _,_ _X_ ˆ R ( _t_ _k_ ) = ˆ _X_ R
˙Σ R = _A_ R Σ R + Σ R _A_ _[⊤]_ R [+] _[ B]_ [R] _[QB]_ R _[⊤]_ Σ L ( _t_ _k_ ) = Σ L
_where A_ R _, B_ R _are the linearisation matrices, defined by_
_A_ R = Ad _X_ ˆ R [D] _[X]_ _[|]_ _X_ [ ˆ] R [Λ(] _[X, v]_ _[m]_ [)] _[ ·]_ [ DR] _X_ [ ˆ] R [(] _[I]_ [)] _[,]_ (10)

_B_ R = Ad _X_ ˆ R [D] _[u]_ _[|]_ _[v]_ _[m]_ [Λ( ˆ] _[X]_ [R] _[, u]_ [) = Ad] _X_ _[∨]_ ˆ R [Υ] (11)

_Note the_ Ad _X_ ˆ R _[term that naturally appears in the][ B]_ [R] _[ matrix associated with the change of handedness in the representation.]_
_In particular, the B_ R _term is not constant along the trajectory. The output is_

_µ_ _[−]_ R [= 0] _[,]_
_X_ ˆ R _[−]_ [= ˆ] _[X]_ [R] [(] _[t]_ _[k]_ [+1] [)] _[,]_


Σ _[−]_ R [= Σ] [R] [(] _[t]_ _[k]_ [+1] [)] _[.]_


With the initial condition represented by **N** _X_ ˆ ( _t_ _k_ ) [(0] _[,]_ [ Σ(] _[t]_ _[k]_ [))][ at time] _[ t]_ _[k]_ [, the prediction step consists of integrating the ODEs]
given in Definitions 4.2 and 4.3 until _t_ _k_ +1 when the new measurement comes in. At the end of the propagation step, the
estimated state is represented by **N** _X_ ˆ _[−]_ ( _t_ _k_ +1 ) [(0] _[,]_ [ Σ] _[−]_ [(] _[t]_ _[k]_ [+1] [))][.]


**4.2.4** **General Measurement Update**


The aim of this step is to update the filter estimate by incorporating the new measurement _y_ _k_ +1 . We first consider the measurement update for the generic measurement model (3). Note that the subscript step _k_ + 1 has been suppressed in all states
and replaced by the filter handedness in all equations. We also suppress the index _y_ = _y_ _k_ +1 on the measurement to respect the
convention, although the same measurement is used for both handedness.

**Definition 4.4** (L-IEKF measurement update) **.** _Let_ ( _µ_ _[−]_ L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] _[−]_ L [)] _[ denote the L-IEKF state with][ µ]_ _[−]_ L [= 0] _[ and let][ y][ be a mea-]_
_surement as described in_ (3) _. The posterior L-IEKF state_ ( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] [+] L [)] _[ is obtained through the]_ [ update step] _[ by]_

_S_ L := _C_ L Σ _[−]_ L _[C]_ L _[⊤]_ [+] _[ R,]_

_K_ L := Σ _[−]_ L _[C]_ L _[⊤]_ _[S]_ L _[−]_ [1] _[,]_

_µ_ [+] L [=] _[ K]_ [L] [(] _[y][ −]_ _[h]_ [( ˆ] _[X]_ L _[−]_ [))] _[,]_

Σ [+] L [= (] _[I][ −]_ _[K]_ [L] _[C]_ [L] [)Σ] _[−]_ L _[,]_
_where C_ L _is the linearisation matrix defined by_
_C_ L := D _X_ _|_ _X_ ˆ L _[−]_ _[h]_ [(] _[X]_ [)] _[ ·]_ [ DL] _X_ [ ˆ] L _[−]_ [(] _[I]_ [)] _[.]_ (12)


6


P REPRINT


**Definition 4.5** (R-IEKF measurement update) **.** _Let_ ( _µ_ _[−]_ R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] _[−]_ R [)] _[ denote the R-IEKF state with][ µ]_ _[−]_ R [= 0] _[ and let][ y][ be a]_
_measurement as described in_ (3) _. The posterior R-IEKF state_ ( _µ_ [+] R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] [+] R [)] _[ is obtained through the]_ [ update step] _[ by]_


_S_ R := _C_ R Σ _[−]_ R _[C]_ R _[⊤]_ [+] _[ R,]_

_K_ R := Σ _[−]_ R _[C]_ R _[⊤]_ _[S]_ R _[−]_ [1] _[,]_

_µ_ [+] R [=] _[ K]_ [R] [(] _[y][ −]_ _[h]_ [( ˆ] _[X]_ R _[−]_ [))] _[,]_

Σ [+] R [= (] _[I][ −]_ _[K]_ [R] _[C]_ [R] [)Σ] _[−]_ R _[,]_


_where C_ R _is the linearisation matrix defined by_


_C_ R := D _X_ _|_ _X_ ˆ R _[−]_ _[h]_ [(] _[X]_ [)] _[ ·]_ [ DR] [ ˆ] _X_ R _[−]_ [(] _[I]_ [)] _[.]_ (13)


The two update steps are identical apart from notation and the DL _X_ ˆ L [or][ DR] [ ˆ] _X_ R [terms in the] _[ C]_ [ matrix.]


In the update step, the measurement _y_ and noise process _ν_ _∼_ **N** (0 _, R_ ) are used to estimate a fused density
**N** _X_ ˆ _[−]_ ( _t_ _k_ +1 ) [(] _[µ]_ [+] [(] _[t]_ _[k]_ [+1] [)] _[,]_ [ Σ] [+] [(] _[t]_ _[k]_ [+1] [))][. Note that the update step involves a Bayesian fusion in local exponential coordinates, which]

leads to a non-zero offset _µ_ [+] ( _t_ _k_ +1 ) and does not change the reference _X_ [ˆ] _[−]_ ( _t_ _k_ +1 ).


One could define _X_ L [+] [=] _[ X]_ L _[−]_ [(and] _[ X]_ R [+] [=] _[ X]_ R _[−]_ [) in order to make the state notation consistent. However, it is better to use the]
‘ _−_
’ notation for the reference in order to reinforce that the reference exponential coordinates do not change in the update step.


**4.2.5** **Reset**


The reset step transforms the posterior **N** ˆ _X_ _[−]_ ( _t_ _k_ +1 ) [(] _[µ]_ [+] [(] _[t]_ _[k]_ [+1] [)] _[,]_ [ Σ] [+] [(] _[t]_ _[k]_ [+1] [))][ into a new distribution with zero offset]
**N** _X_ ˆ ( _t_ _k_ +1 ) [(0] _[,]_ [ Σ(] _[t]_ _[k]_ [+1] [))][ at the tangent coordinates at the new reference state. Note that in much of the EKF literature the re-]
set step is simply a reset of the reference


_X_ ˆ ( _t_ _k_ +1 ) = ˆ _X_ _[−]_ ( _t_ _k_ +1 ) exp **G** ( _µ_ [+] ( _t_ _k_ +1 ))


without any corresponding consideration of the consequences of the change of coordinates on the covariance Σ [+] ( _t_ _k_ +1 ). Theoretical arguments from both geometric [19] and analytic [20] perspectives, as well as empirical evidence [15], have conclusively
shown that the change in the reference state induces a change in the covariance Σ when the state space is not globally Euclidean.
Conceptually, changing the reference point of a concentrated Gaussian changes the coordinates in which the pdf is expressed
and should change the algebraic form of the covariance. The authors believe that failing to model the reset correctly is a major
source that leads to differences between the L-IEKF and R-IEKF in the literature.

**Remark 4.6.** _The reset step was initially introduced in [13, 15] as a curvature correction term based on the parallel transport_
_operator. Subsequent work [19, 26] proposed using the differential of the exponential map for the reset step. Since parallel_
_transport provides a first-order approximation to the differential of the exponential [26], the practical difference between these_
_approaches is negligible. When an analytic expression is available, it is recommended to use the differential of the exponential_
_map for improved accuracy and consistency._


The reset step is defined by [26]

**Definition 4.7** (L-IEKF reset) **.** _Let_ ( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] [+] L [)] _[ denote the L-IEKF state. Then the]_ [ reset step] _[ is defined by]_


_µ_ L = 0 _,_
_X_ ˆ L = ˆ _X_ L _[−]_ [exp] **G** [(] _[µ]_ [+] L [)] _[,]_

Σ L = _J_ L Σ [+] L _[J]_ L _[⊤]_ _[,]_


_where J_ L _is the Jacobian matrix defined by_


_J_ L := DL _[−]_ [1] (14)
exp **G** ( _µ_ [+] L [)] _[ ·]_ [ D] [∆] _[|]_ _[µ]_ L [+] [exp] **[G]** [(∆)] _[.]_


**Definition 4.8** (R-IEKF reset) **.** _Let_ ( _µ_ [+] R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] [+] R [)] _[ denote the R-IEKF state. Then the]_ [ reset step] _[ is defined by]_


_µ_ R = 0 _,_
_X_ ˆ R = exp **G** ( _µ_ [+] R [) ˆ] _[X]_ R _[−]_ _[,]_

Σ R = _J_ R Σ [+] R _[J]_ R _[⊤]_ _[,]_


_where J_ R _is the Jacobian matrix defined by_

_J_ R := DR _[−]_ exp [1] **G** ( _µ_ [+] R [)] _[ ·]_ [ D] [∆] _[|]_ _[µ]_ R [+] [exp] **[G]** [(∆)] _[.]_ (15)


7


P REPRINT


**Remark 4.9.** _Note that here the Jacobian matrices J_ L _and J_ R _are commonly referred to as the_ right _and_ left _Jacobians in most_
_literature, respectively [18]. We use the notation J_ L _and J_ R _to align with the handedness of the filter, as well as the fact that_
_these Jacobians are derived through the left and right trivialisation of the group, respectively._


The reset step transforms the posterior, which is a concentrated Gaussian with non-zero offset, into a zero-offset distribution
by choosing a new reference state. The distribution after reset is represented with **N** _X_ ˆ ( _t_ _k_ +1 ) [(0] _[,]_ [ Σ(] _[t]_ _[k]_ [+1] [))][ which concludes a]
complete filter iteration.


**4.3** **Left-invariant measurement model and update**


In Sec. 4.2.4, we considered the general measurement model (3) and the corresponding update step. However, there are certain
types of measurements that draw attention due to their nice linearisation properties, namely _left-invariant_ and _right-invariant_
measurements [1]. The common perception is that such measurements can lead to a state-independent linearisation matrix
when being used with the IEKF with the corresponding handedness, which improves the filter performance.


In this section, we will illustrate the left-invariant measurement model and the corresponding update step for the L-IEKF and
R-IEKF. The right-invariant measurement and the corresponding update step follow similarly.
**Definition 4.10** (Left-invariant measurement) **.** _A measurement y ∈_ R _[n]_ _is termed left-invariant if, for some_ ˚ _y ∈_ R _[n]_ _, it satisfies_
_the following property:_


˚
_y_ = _h_ ( _X_ ) + _η_ = _ρ_ ( _X,_ _y_ ) + _η,_ _η ∼_ **N** (0 _, R_ )


_where ρ_ : **G** _×_ R _[n]_ _→_ R _[n]_ _is a left group action, that is,_


_ρ_ ( _X_ 1 _X_ 2 _, y_ ) = _ρ_ ( _X_ 1 _, ρ_ ( _X_ 2 _, y_ )) _,_ _ρ_ ( _I, y_ ) = _y,_


_for all X_ 1 _, X_ 2 _∈_ **G** _and all y ∈_ R _[n]_ _._


˚
Given a left-invariant measurement _y_ = _ρ_ ( _X,_ _y_ ) + _η_, let _X_ _[′]_ _∈_ **G** and observe that

_ρ_ ( _X_ _[′]_ _, y_ ) = _ρ_ ( _X_ _[′]_ _, ρ_ ( _X,_ ˚ _y_ ) + _η_ ) = _ρ_ ( _X_ _[′]_ _X,_ ˚ _y_ ) + _ρ_ ( _X_ _[′]_ _, η_ )


where we exploit the linearity of the group action to factor out the noise process. This is a form of equivariance of the output

[14]. Note, however, that this operation transforms the noise.


In most literature [1], the perception is that the L-IEKF should be preferred when the measurement model is left-invariant,
and vice versa for the R-IEKF. Left-invariant measurements have been exploited in the L-IEKF formulation as follows. Let
(0 _,_ _X_ [ˆ] L _,_ Σ L ) denote the L-IEKF state. Then for a measurement _y_ = _h_ ( _X_ ) + _η_, one may define the pseudo measurement
_d_ = _ρ_ ( _X_ [ˆ] L _[−]_ [1] _[, y]_ [)][ and find that]

_d_ = _ρ_ ( _X_ [ˆ] L _[−]_ [1] _[, y]_ [) =] _[ ρ]_ [( ˆ] _[X]_ L _[−]_ [1] _[, h]_ [(] _[X]_ [) +] _[ η]_ [)]

= _ρ_ ( _X_ [ˆ] L _[−]_ [1] _[, ρ]_ [(] _[X,]_ [˚] _[y]_ [) +] _[ η]_ [)]

= _ρ_ ( _X_ [ˆ] L _[−]_ [1] _[, ρ]_ [( ˆ] _[X]_ [L] _[E]_ [L] _[,]_ [˚] _[y]_ [) +] _[ η]_ [)] _[.]_


Since the action _ρ_ is a linear group action, this simplifies to

_d_ = _ρ_ ( _X_ [ˆ] L _[−]_ [1] _[, ρ]_ [( ˆ] _[X]_ [L] _[E]_ [L] _[,]_ [˚] _[y]_ [)) +] _[ ρ]_ [( ˆ] _[X]_ L _[−]_ [1] _[, η]_ [)]


˚
= _ρ_ ( _E_ L _,_ _y_ ) + _ρ_ ( _X_ [ˆ] L _[−]_ [1] _[, η]_ [) =] _[ h]_ [(] _[E]_ [L] [) +] _[ ρ]_ [( ˆ] _[X]_ L _[−]_ [1] _[, η]_ [)] _[.]_


The linearisation about _E_ L = _I_ and _η_ = 0 yields

_d_ = ˚ _y_ + D _X_ _|_ _I_ _h_ ( _X_ ) _ε_ L + D _z_ _|_ _h_ ( ˆ _X_ L ) _[ρ]_ [( ˆ] _[X]_ L _[−]_ [1] _[, z]_ [)] _[η]_ [ +] _[ O]_ [(] _[|][η, ε]_ [L] _[|]_ [2] [)] _[.]_ (16)

where _E_ L = _I_ + _ε_ L + _O_ ( _|ε_ L _|_ [2] ). This leads to the L-IEKF measurement update with left-invariant measurements.

**Definition 4.11** (L-IEKF left-invariant measurement update) **.** _Let_ ( _µ_ _[−]_ L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] _[−]_ L [)] _[ denote the L-IEKF state with][ µ]_ _[−]_ L [= 0] _[, and let]_
_y be a left-invariant measurement as described in 4.10. The posterior L-IEKF state_ ( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] [+] L [)] _[ is obtained through the]_ [ left]
update step

_S_ L := _C_ L Σ _[−]_ L _[C]_ L _[⊤]_ [+] _[ D]_ [L] _[RD]_ L _[⊤]_ _[,]_

_K_ L := Σ _[−]_ L _[C]_ L _[⊤]_ _[S]_ L _[−]_ [1] _[,]_


_−_ 1 ˚
_µ_ [+] L [=] _[ K]_ [L] [(] _[ρ]_ [( ˆ] _[X]_ L _[−]_ _, y_ ) _−_ _y_ ) _,_

Σ [+] L [= (] _[I][ −]_ _[K]_ [L] _[C]_ [L] [)Σ] _[−]_ L _[,]_


_where C_ L _, D_ L _are the linearisation matrices defined by_


_C_ L := D _X_ _|_ _I_ _h_ ( _X_ ) _,_ (17)
_D_ L := D _z_ _|_ _h_ ( ˆ _X_ L _[−]_ [)] _[ρ]_ _X_ [ ˆ] L _[−]_ _−_ 1 ( _z_ ) _._ (18)


8


P REPRINT


As shown in Def. 4.11, by using the pseudo measurement _d_, the L-IEKF now admits a state-independent linearisation matrix
_C_ L = D _X_ _|_ _I_ _h_ ( _X_ ), which is the main reason why L-IEKF is always preferred over R-IEKF in this case. However, note that the
same pseudo-measurement construction is also possible for R-IEKF. Consider an R-IEKF and the same pseudo measurement
_d_ = _ρ_ ( _X_ [ˆ] R _[−]_ [1] _[, y]_ [)][, one now has]


_d_ = _ρ_ ( _X_ [ˆ] R _[−]_ [1] _[, y]_ [) =] _[ ρ]_ [( ˆ] _[X]_ R _[−]_ [1] _[, ρ]_ [(] _[X,]_ [˚] _[y]_ [) +] _[ η]_ [)]


ˆ ˚
= _ρ_ ( _X_ [ˆ] R _[−]_ [1] _[, ρ]_ [(] _[X]_ [ ˆ] _[X]_ R _[−]_ [1] _X_ R _,_ _y_ ) + _η_ )

= _ρ_ ( _X_ [ˆ] R _[−]_ [1] _[, ρ]_ [(] _[E]_ [R] [ ˆ] _[X]_ [R] _[,]_ [˚] _[y]_ [) +] _[ η]_ [)] _[.]_


Linearising about _E_ R = _I_ and _η_ = 0 yields


_d_ = ˚ _y_ + D _X_ _|_ _I_ _h_ ( _X_ ) Ad _X_ ˆ R _[−]_ [1] _[ε]_ [R] [+D] _[z]_ _[|]_ _[h]_ [( ˆ] _X_ R ) _[ρ]_ [( ˆ] _[X]_ R _[−]_ [1] _[, z]_ [)] _[η]_

+ _O_ ( _|η, ε_ R _|_ [2] ) _._ (19)


This leads to the left-invariant measurement updates for the R-IEKF using pseudo-measurements.


**Definition 4.12** (R-IEKF left-invariant measurement update) **.** _Let_ ( _µ_ _[−]_ R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] _[−]_ R [)] _[ denote the R-IEKF state with][ µ]_ _[−]_ R [= 0] _[, and let]_
_y be a left measurement as described in 4.10. The posterior R-IEKF state_ ( _µ_ [+] R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] [+] R [)] _[ is obtained through the]_ [ right update]
step


_S_ R := _C_ R Σ _[−]_ R _[C]_ R _[⊤]_ [+] _[ D]_ [R] _[RD]_ R _[⊤]_ _[,]_

_K_ R := Σ _[−]_ R _[C]_ R _[⊤]_ _[S]_ R _[−]_ [1] _[,]_


_−_ 1 ˚
_µ_ [+] R [=] _[ K]_ [R] [(] _[ρ]_ [( ˆ] _[X]_ R _[−]_ _, y_ ) _−_ _y_ ) _,_

Σ [+] R [= (] _[I][ −]_ _[K]_ [R] _[C]_ [R] [)Σ] _[−]_ R _[,]_


_where C_ R _, D_ R _are the linearisation matrices defined by_


_C_ R := D _X_ _|_ _I_ _h_ ( _X_ ) _·_ Ad _[∨]_ _X_ ˆ R _[−]_ _−_ 1 _,_ (20)

_D_ R := D _z_ _|_ _h_ ( ˆ _X_ R _[−]_ [)] _[ρ]_ [ ˆ] _X_ R _[−]_ _−_ 1 ( _z_ ) _._ (21)


**Remark 4.13.** _In much of the literature, it is always encouraged to use L-IEKF over the R-IEKF when a left-invariant mea-_
_surement is available, because of the state-independent linearisation matrix C_ L = D _X_ _|_ _I_ _h_ ( _X_ ) _in_ (16) _. However, as shown_
_in_ (16) _, when using the pseudo measurement d instead of y, the new noise process now depends on the linearisation matrix_
D _z_ _|_ _h_ ( ˆ _X_ L _[−]_ [)] _[ρ]_ [( ˆ] _[X]_ _[−]_ [1] _[, z]_ [)] _[, which is state-dependent. This finding is also observed in [27].]_


**5** **Equivalence of Left and Right IEKF**


In this section, we present our main claim that the L-IEKF and R-IEKF always yield equivalent estimates of the state at each
filter step.


**5.1** **Definition of equivalence**


The equivalence of the L-IEKF and R-IEKF is defined based on the underlying distribution of the state estimate represented by
the concentrated Gaussians.


**Lemma 5.1.** _Consider a L-CGD_ **N** [L] ˆ ˆ
_X_ L [(] _[µ]_ [L] _[,]_ [ Σ] [L] [)] _[ and a R-CGD]_ **[ N]** _X_ [R] R [(] _[µ]_ [R] _[,]_ [ Σ] [R] [)] _[ defined by]_ [ (4)] _[ and]_ [ (5)] _[ respectively. The two]_
_distributions are equivalent (as functions on_ **G** _) if_



ˆ
_µ_ R = Ad _X_ ˆ L _[µ]_ [L] _[,]_ _X_ R = ˆ _X_ L _,_ Σ R = Ad _[∨]_ _X_ ˆ L [Σ] [L] [Ad] _X_ _[∨]_ ˆ L



_⊤_
_._ (22)



_Proof._ We prove this lemma by showing that the log likelihood of left and right distributions is the same under the conditions
of the lemma, that is,


_L_ L ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) = _L_ R ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) _._


9


P REPRINT



This is shown by straightforward computation.


_L_ R ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R )

= [1] 2 _[|]_ [ log(] _[X]_ [ ˆ] _[X]_ R _[−]_ [1] [)] _[ −]_ _[µ]_ [R] _[|]_ [2] Σ _[−]_ R [1]

= 2 [1] _[|]_ [ log(] _[X]_ [ ˆ] _[X]_ L _[−]_ [1] [)] _[ −]_ [Ad] _X_ [ ˆ] L _[µ]_ [L] _[|]_ [2] (Ad _[∨]_ _X_ ˆL [Σ] [L] [Ad] _X_ _[∨]_ ˆL



_⊤_ ) _−_ 1



= [1] 2 _[|]_ [ Ad] _X_ [ ˆ] L [log( ˆ] _[X]_ L _[−]_ [1] _[X]_ [)] _[ −]_ [Ad] _X_ [ ˆ] L _[µ]_ [L] _[|]_ [2] (Ad _[∨]_ _X_ ˆL [Σ] [L] [Ad] _X_ _[∨]_ ˆL



_⊤_ ) _−_ 1



= 2 [1] _[|]_ [ log( ˆ] _[X]_ L _[−]_ [1] _[X]_ [)] _[ −]_ _[µ]_ [L] _[|]_ [2] Σ _[−]_ L [1]

= _L_ L ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) _,_


for any _X_ L = _X_ R _∈_ **G** .


Concretely, this lemma shows that the L-IEKF and R-IEKF, which use left and right concentrated Gaussians for state representation respectively, have the exact same log likelihood function when the states correspond according to the condition (22).
This leads to the following definition of equivalence between the L-IEKF and R-IEKF.

**Definition 5.2.** _Let_ ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) _and_ ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) _denote the states of the L-IEKF and R-IEKF, respectively. We say the_
_L-IEKF and R-IEKF states are_ equivalent _if_ (22) _holds._


**5.2** **Equivalence of filter steps**


In this section, we first present the main theorem, which shows that the evolution of the left and right filter estimates matches,
and hence the likelihood functions are equivalent. Its proof relies on the lemmas that are proven later in the section. Note that
we will re-introduce the time index _t_ _k_ _, t_ _k_ +1 when necessary to clarify the time evolution of the filter propagation.

**Theorem 5.3.** _Let_ ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) _and_ ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) _denote the states of the L-IEKF and R-IEKF, respectively. Assume that the_
_measurements y_ _k_ _admit left-invariance (Section 4.3). If the initial conditions of the states are equivalent (at a time t_ 0 _),_


_µ_ R ( _t_ 0 ) = 0 = Ad _X_ L ( _t_ 0 ) _µ_ L ( _t_ 0 )
_X_ ˆ R ( _t_ 0 ) = ˆ _X_ L ( _t_ 0 )


_⊤_
Σ R ( _t_ 0 ) = Ad _X_ _[∨]_ L ( _t_ 0 ) [Σ] [L] [(] _[t]_ [0] [)Ad] _[∨]_ _X_ L ( _t_ 0 ) _,_


_with µ_ L ( _t_ 0 ) = _µ_ R ( _t_ 0 ) = 0 _, then the states are equivalent for all time t ≥_ _t_ 0 _._


_Proof._ Lemma 5.5 proves that if the initial state of the L-IEKF and R-IEKF


( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) = ( _µ_ L ( _t_ _k_ ) _,_ _X_ [ˆ] L ( _t_ _k_ ) _,_ Σ L ( _t_ _k_ ))


and
( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) = ( _µ_ R ( _t_ _k_ ) _,_ _X_ [ˆ] R ( _t_ _k_ ) _,_ Σ R ( _t_ _k_ ))

are equivalent, then the filter state after propagation ( _µ_ _[−]_ L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] _[−]_ L [)][ and][ (] _[µ]_ _[−]_ R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] _[−]_ R [)][ are equivalent.]


Lemma 5.7 proves that if ( _µ_ _[−]_ L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] _[−]_ L [)][ and][ (] _[µ]_ _[−]_ R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] _[−]_ R [)][ are equivalent then the filter states after the measurement update]
( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] [+] L [)][ and][ (] _[µ]_ [+] R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] [+] R [)][ are equivalent.]


Lemma 5.8 proves that if ( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] [+] L [)][ and][ (] _[µ]_ [+] R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] [+] R [)][ are equivalent then the filter states after the reset step]


( _µ_ L ( _t_ _k_ +1 ) _,_ _X_ [ˆ] L ( _t_ _k_ +1 ) _,_ Σ L ( _t_ _k_ +1 )) = ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L )


and
( _µ_ R ( _t_ _k_ +1 ) _,_ _X_ [ˆ] R ( _t_ _k_ +1 ) _,_ Σ R ( _t_ _k_ +1 )) = ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R )


are equivalent.


By induction, this completes the proof.


**Remark 5.4.** _We only present the technical results with left-invariant measurements since this matches the setup in the INS_
_problem. However, the equivalence holds for any type of measurements, and it is straightforward to extend the proof to the_
_case of right-invariant measurements or general measurements. We omit the detailed proofs for other types of measurements._
_A similar analysis has recently been performed in [23] for the case of general measurement update._


10


P REPRINT


**Lemma 5.5** (Predict step equivalence) **.** _Let_ ( _µ_ L _,_ _X_ [ˆ] R _,_ Σ L ) _and_ ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) _be the states of the L-IEKF and R-IEKF, respec-_
_tively, with µ_ L = _µ_ R = 0 _. Suppose that the L-IEKF and R-IEKF states are equivalent (Def. 5.2) at a time t_ 0 _. Then the L-IEKF_
_and R-IEKF states remain equivalent for as long as the prediction dynamics are applied._


_Proof._ This is shown by applying the uniqueness of smooth ODE solutions. Let _P_ := Ad _X_ ˆ L [Σ] [L] [ Ad] _X_ _[⊤]_ ˆ L [where][ (0] _[, X]_ [L] _[,]_ [ Σ] [L] [)][ is]
the solution of the left-invariant prediction dynamics. Then _P_ ( _t_ 0 ) = Σ R ( _t_ 0 ) and the dynamics of _P_ are given by



˙
_P_ = [d] ˆ ˆ

d _t_ [Ad] _X_ _[∨]_ L [Σ] [L] [Ad] _X_ _[∨]_ L



_⊤_



_⊤_

= Ad _[∨]_ _X_ ˆ L [(] _[A]_ [L] [Σ] [L] [ + Σ] [L] _[A]_ L _[⊤]_ [+] _[ B]_ [L] _[QB]_ L _[⊤]_ [)Ad] _[∨]_ _X_ ˆ L



_⊤_

+ Ad _[∨]_ _X_ ˆ L [ad] _[∨]_ Λ( _X_ [ˆ] L _,v_ _m_ ) [Σ] [L] [Ad] _[∨]_ _X_ ˆ L



+ Ad _[∨]_ _X_ ˆ L [Σ] [L] [ad] _[∨]_ Λ( _X_ [ˆ] L _,v_ _m_ ) _⊤_ Ad _∨X_ ˆ L _⊤_



_−_ 1
) _P_



ˆ ˆ
= (Ad _[∨]_ _X_ L _[A]_ [L] [Ad] _X_ _[∨]_ L



_−_ 1 + Ad _∨X_ ˆ L [ad] _[∨]_ Λ( _X_ [ˆ] L _,v_ _m_ ) [Ad] _[∨]_ _X_ ˆ L



_−_ 1 ) _⊤_



+ _P_ (Ad _[∨]_ _X_ ˆ L _[A]_ [L] [Ad] _X_ _[∨]_ ˆ L



_−_ 1 + Ad _∨X_ ˆ L [ad] _[∨]_ Λ( _X_ [ˆ] L _,v_ _m_ ) [Ad] _[∨]_ _X_ ˆ L



_⊤_

+ Ad _[∨]_ _X_ ˆ L _[B]_ [L] _[QB]_ L _[⊤]_ [Ad] _[∨]_ _X_ ˆ L _._



where _A_ L and _B_ L are the linearisation matrices given in Def. 4.2. Observe that



Ad _[∨]_ ˆ ˆ
_X_ L _[A]_ [L] [Ad] _X_ _[∨]_ L



_−_ 1 + Ad _∨X_ ˆ L [ad] _[∨]_ Λ( _X_ [ˆ] L _,v_ _m_ ) [Ad] _[∨]_ _X_ ˆ L _−_ 1



= Ad _[∨]_ ˆ
_X_ L [(D] _[X]_ _[|]_ _X_ [ ˆ] L [Λ(] _[X, v]_ _[m]_ [)] _[ ·]_ [ DL] _X_ [ ˆ] L [(] _[I]_ [)]



_−_ 1 + Ad _∨X_ ˆ L [ad] _[∨]_ Λ( _X_ [ˆ] L _,v_ _m_ ) [Ad] _[∨]_ _X_ ˆ L



_−_ ad _[∨]_ ˆ
Λ( _X_ [ˆ] L _,v_ _m_ ) [)Ad] _X_ _[∨]_ L



_−_ 1



_−_ 1



while



= Ad _[∨]_ ˆ ˆ
_X_ L [D] _[X]_ _[|]_ _X_ [ ˆ] L [Λ(] _[X, v]_ _[m]_ [)] _[ ·]_ [ DL] _X_ [ ˆ] L [(] _[I]_ [)Ad] _X_ _[∨]_ L

= Ad _[∨]_ ˆ
_X_ L [D] _[X]_ _[|]_ _X_ [ ˆ] L [Λ(] _[X, v]_ _[m]_ [)] _[ ·]_ [ DR] [ ˆ] _X_ L [(] _[I]_ [)]

= _A_ R _,_


Ad _[∨]_ ˆ ˆ
_X_ L _[B]_ [L] [ = Ad] _X_ _[∨]_ L [Υ =] _[ B]_ [R] _[,]_



and hence (0 _,_ _X_ [ˆ] L _, P_ ) obey the R-IEKF prediction dynamics. Uniqueness of ODE solutions implies that _X_ [ˆ] L = _X_ ˆ R and
_P_ ( _t_ ) = Σ R ( _t_ ) for all time.


**Remark 5.6.** _The result in Lemma 5.5 depends only on the algebraic structure of the EKF equations. In particular, it does not_
_require group-affine dynamics or any other additional properties of the system._


The next result shows that the update step preserves the equivalence of the L-IEKF and R-IEKF solutions.


**Lemma 5.7** (Left-invariant measurement update equivalence) **.** _Let_ ( _µ_ _[−]_ L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] _[−]_ L [)] _[ and]_ [ (] _[µ]_ _[−]_ R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] _[−]_ R [)] _[ be the states of the L-]_
_IEKF and R-IEKF, respectively, with µ_ _[−]_ L [=] _[ µ]_ _[−]_ R [= 0] _[. Suppose that the states are equivalent (Def. 5.2) at the instant a]_
_left-invariant measurement y is received. If the respective update steps are applied to both the L-IEKF and R-IEKF, then the_
_posterior states_ ( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] [+] L [)] _[ and]_ [ (] _[µ]_ [+] R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] [+] R [)] _[ are equivalent as well.]_


_Proof._ There is no update to the reference and _X_ [ˆ] L _[−]_ [= ˆ] _[X]_ R _[−]_ [remain fixed in the update step.]

Recalling (17) and (20) then _C_ R = _C_ L Ad _[∨]_ _X_ ˆ R _[−]_ _−_ 1 . Similarly, from (18) and (21) then _D_ L = _D_ R . Thus one has


_S_ R = _C_ R Σ _[−]_ R _[C]_ R _[⊤]_ [+] _[ D]_ [R] _[RD]_ R _[⊤]_



= _C_ L Ad _[∨]_ _X_ ˆ R _[−]_ _−_ 1 Ad _[∨]_ _X_ ˆ L [Σ] L _[−]_ [Ad] _[∨]_ _X_ ˆ L _[−]_ _⊤_ Ad _∨X_ ˆ R _[−]_ _−_ 1 _⊤_ _C_ L _⊤_

+ _D_ L _RD_ L _[⊤]_
= _C_ L Σ _[−]_ L _[C]_ L _[⊤]_ [+] _[ D]_ [L] _[RD]_ L _[⊤]_ [=] _[ S]_ [L] _[.]_


11


P REPRINT



The updated offsets are related by


_−_ 1 ˚
_µ_ [+] R [=] _[ K]_ [R] [(] _[ρ]_ [( ˆ] _[X]_ R _[−]_ _, y_ ) _−_ _y_ )

= Σ _[−]_ R _[C]_ R _[⊤]_ _[S]_ R _[−]_ [1] [(] _[y][ −]_ _[h]_ [( ˆ] _[X]_ R _[−]_ [))]



_−_ 1 ) _⊤_ _S_ L _−_ 1


_−_ 1 ˚

_·_ ( _ρ_ ( _X_ [ˆ] R _[−]_ _, y_ ) _−_ _y_ )



= Ad _[∨]_ _X_ ˆ L _[−]_ [Σ] L _[−]_ [Ad] _[∨]_ _X_ ˆ L _[−]_



_⊤_ ( _C_ L Ad _∨X_ ˆ L _[−]_



_−_ 1 ˚
= Ad _[∨]_ _X_ ˆ L _[−]_ [Σ] L _[−]_ _[C]_ L _[⊤]_ _[S]_ L _[−]_ [1] [(] _[ρ]_ [( ˆ] _[X]_ R _[−]_ _, y_ ) _−_ _y_ )

= Ad _[∨]_ _X_ ˆ L _[−]_ _[µ]_ L [+] _[.]_


Finally, the updated covariances satisfy


Σ [+] R [= (] _[I][ −]_ _[K]_ [R] _[C]_ [R] [)Σ] _[−]_ R [= (] _[I][ −]_ [Σ] _[−]_ R _[C]_ R _[⊤]_ _[S]_ R _[−]_ [1] _[C]_ [R] [)Σ] _[−]_ R



_−_ 1 _⊤_ _−_ 1
) _S_ L _[C]_ [L] [)Σ] _[−]_ L [Ad] _[∨]_ _X_ ˆ L _[−]_



= ( _I −_ Ad _[∨]_ _X_ ˆ L _[−]_ [Σ] [L] [Ad] _X_ _[∨]_ ˆ L _[−]_


= Ad _[∨]_ _X_ ˆ L _[−]_ [(] _[I][ −]_ [Σ] L _[−]_ [Ad] _[∨]_ _X_ ˆ L _[−]_



_⊤_ ( _C_ L Ad _∨X_ ˆ L _[−]_


_⊤_ ( _C_ L Ad _∨X_ ˆ L _[−]_



_−_ 1 _⊤_ _−_ 1
) _S_ L _[C]_ [L] [Ad] _[∨]_ _X_ ˆ L _[−]_


_·_ Ad _[∨]_ ˆ ˆ
_X_ L _[−]_ [Σ] [L] [Ad] _X_ _[∨]_ L _[−]_



_−_ 1 )



_⊤_



_⊤_



= Ad _[∨]_ _X_ ˆ L _[−]_ [(] _[I][ −]_ [Σ] L _[−]_ _[C]_ L _[⊤]_ _[S]_ L _[−]_ [1] _[C]_ [L] [)Σ] _[−]_ L [Ad] _[∨]_ _X_ ˆ L _[−]_



_⊤_



= Ad _[∨]_ _X_ ˆ L _[−]_ [Σ] L [+] [Ad] _[∨]_ _X_ ˆ L _[−]_



_⊤_

_._



This completes the proof.


The final result required is to prove equivalence under the reset step.


**Lemma 5.8** (Reset step equivalence) **.** _Let_ ( _µ_ [+] L _[,]_ [ ˆ] _[X]_ L _[−]_ _[,]_ [ Σ] [+] L [)] _[ and]_ [ (] _[µ]_ [+] R _[,]_ [ ˆ] _[X]_ R _[−]_ _[,]_ [ Σ] [+] R [)] _[ be the states of the L-IEKF and R-IEKF, respec-]_
_tively, following an update step. If the states are equivalent_ (22) _then after the respective reset steps are applied to both the_
_L-IEKF and R-IEKF, the resulting states_ ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) _and_ ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) _are equivalent._


_Proof._ Consider the update of the reference states _X_ [ˆ] L _[−]_ [= ˆ] _[X]_ L [+] [and][ ˆ] _[X]_ R _[−]_ [= ˆ] _[X]_ R [+] [since the update does not change the reference.]
Given (22), one has


_X_ ˆ R = exp **G** ( _µ_ [+] R [) ˆ] _[X]_ R _[−]_
= exp **G** (Ad _X_ ˆ L _[−]_ _[µ]_ L [+] [) ˆ] _[X]_ L _[−]_ [= ˆ] _[X]_ L _[−]_ [exp] **G** [(] _[µ]_ [+] L [) = ˆ] _[X]_ [L] _[.]_


To prove the equivalence of the covariance matrices, we first analyse the relation between the linearisation matrices _J_ L (14) and
_J_ R (15) For any _ε ∈_ R _[m]_, one has



_J_ R [ _ε_ ] = [d]

d _s_



= [d]

d _s_



= [d]

d _s_



= [d]

d _s_



= [d]

d _s_



log _[∨]_ **G** [(exp] **G** [(] _[sε]_ _[∧]_ [) exp(] _[−][µ]_ R [+] [))]
���� _s_ =0


log _[∨]_ **G** [(exp] **G** [(] _[sε]_ _[∧]_ [) exp(] _[−]_ [Ad] _X_ [ ˆ] L _[−]_ _[µ]_ L [+] [))]
���� _s_ =0


_−_ 1
log _[∨]_ **G** [(exp] **G** [(] _[sε]_ _[∧]_ [) ˆ] _X_ L _[−]_ [exp(] _[−][µ]_ [+] L [) ˆ] _X_ L _[−]_ )
���� _s_ =0


log _[∨]_ **G** [( ˆ] _X_ L _[−]_ [exp] **G** [(] _[µ]_ L [+] [) exp(] _[−][µ]_ [+] L [)]
���� _s_ =0

exp **G** (Ad _X_ ˆ L _[−]_ _−_ 1 _sε_ _[∧]_ )( _X_ [ˆ] L _[−]_ [exp] **G** [(] _[µ]_ L [+] [))] _[−]_ [1] [)]


Ad _[∨]_ ˆ
���� _s_ =0 _X_ L _[−]_ [exp] **[G]** [(] _[µ]_ [+] L [)]

log _[∨]_ **G** [(exp] **G** [(] _[−][µ]_ L [+] [) exp] **G** [(Ad] _X_ ˆ L _[−]_ _−_ 1 _sε_ _[∧]_ ))



= Ad _[∨]_ _X_ ˆ L _[J]_ [L] [ Ad] _[∨]_ _X_ ˆ L _[−]_ _−_ 1 _ε,_


12


P REPRINT


Figure 1: The RMSE of each state variable and ANEES of the L-IEKF and R-IEKF. The shaded area represents the standard
deviation of the data across all trials.


and hence _J_ R = Ad _X_ ˆ L _[J]_ [L] [ Ad] _X_ [ ˆ] L _[−]_ _−_ 1 . Therefore, the reset covariance matrices are related by


Σ R = _J_ R Σ [+] R _[J]_ R _[⊤]_



= Ad _[∨]_ _X_ ˆ L _[J]_ [L] [Ad] _X_ _[∨]_ ˆ L _[−]_ _−_ 1 Ad _[∨]_ _X_ ˆ L _[−]_ [Σ] L [+] [Ad] _[∨]_ _X_ ˆ L _[−]_



_⊤_



(Ad _[∨]_ _X_ ˆ L _[J]_ [L] [ Ad] _X_ _[∨]_ ˆ L _[−]_ _−_ 1 ) _[⊤]_



= Ad _[∨]_ _X_ ˆ L _[J]_ [L] [Σ] L [+] _[J]_ L _[⊤]_ [Ad] _[∨]_ _X_ ˆ L



_⊤_



= Ad _[∨]_ _X_ ˆ L [Σ] L [+] [Ad] _[∨]_ _X_ ˆ L



_⊤_

_._



This completes the proof.


**Remark 5.9.** _Note that the reset step is critical in the whole equivalence proof, as the equivalence of the prediction step 5.5_
_relies on the filter states being zero-mean concentrated Gaussians at the start of the prediction step._


**6** **Simulation Results**


In this section, we test the L-IEKF and R-IEKF outlined in Section 4 on simulated data for the position-based INS problem. We
first present the primary results that demonstrate the equivalence of the L-IEKF and R-IEKF in practice, and then we investigate
the effect of discretisation on the equivalence. Finally, we also present an ablation study on the effect of the reset step on the
IEKF performance.


**6.1** **Inertial Navigation Systems**


We will use the problem of GNSS-aided inertial navigation system (INS) as a motivating example for the paper. The INS
problem is particularly of interest as it is a classical robotics system evolving on a Lie group, as well as a widely-studied
application of the IEKF [22] and other symmetry-based filters [21]. Consider a mobile robot equipped with an IMU that
provides gyroscope and accelerometer measurements, as well as a GNSS receiver that measures the global position of the


13


P REPRINT


Figure 2: The difference in the estimates of each state variable and the covariance matrices between the L-IEKF and R-IEKF.
The error is linearly dependent on the discretisation step length. Decreasing the step size makes the discretised solution close
to the true continuous solution and brings the trajectories together.


robot. Under the non-rotating, flat Earth assumption, the robot’s state can be represented by the position _**p**_ _∈_ R [3], the velocity
_**v**_ _∈_ R [3], and the orientation **R** _∈_ **SO** (3), with the noise-free dynamics given by


˙
**R** = **R** ( _**ω**_ _−_ _**b**_ _**ω**_ ) _[∧]_ _,_ (23a)

˙
_**v**_ = **R** ( _**a**_ _−_ _**b**_ _**a**_ ) + _**g**_ _,_ (23b)

˙
_**p**_ = _**v**_ _,_ (23c)
_**b**_ ˙ _**ω**_ = _**τ**_ _**ω**_ _,_ (23d)
_**b**_ ˙ _**a**_ = _**τ**_ _**a**_ _,_ (23e)


Here _**ω**_ _∈_ R [3] and _**a**_ _∈_ R [3] are the angular velocity and proper acceleration expressed in the body frame. The gravity vector is
denoted by _**g**_ _∈_ R [3] and is expressed in the world frame. The rigid body orientation, position and velocity ( **R** _,_ _**p**_ _,_ _**v**_ ) are termed
the _navigation states_, expressed in the reference or world frame, denoted by ( **R** _,_ _**p**_ _,_ _**v**_ ) _∈_ **SO** (3) _×_ R [3] _×_ R [3] . The two biases
_**b**_ _**ω**_ _∈_ R [3] and _**b**_ _**a**_ _∈_ R [3] are termed the _bias states_, expressed in the body frame, with dynamics modelled by unknown inputs _**τ**_ _**ω**_
and _**τ**_ _**a**_ sampled from Gaussian distributions.


In the IEKF framework, the navigation states are usually represented using the extended pose group _**F**_ = ( **R** _,_ _**p**_ _,_ _**v**_ ) _∈_ **SE** 2 (3)
(where _**F**_ stands for a Galilean frame), and the bias states are represented as _**b**_ = ( _**b**_ _**ω**_ _,_ _**b**_ _**a**_ ) _∈_ R [6] . The IEKF state space is then
given by the product group **G** = **SE** 2 (3) _×_ R [6], and we write an element of the state space as


_X_ = ( _**F**_ _,_ _**b**_ ) = ( **R** _,_ _**p**_ _,_ _**v**_ _,_ _**b**_ _**ω**_ _,_ _**b**_ _**a**_ ) _∈_ **G** _._


The GNSS receiver provides the global position measurement. The noise-free measurement model is given by

_h_ ( _X_ ) = _**p**_ + _η ∈_ R [3] _._ (24)


with _η ∼_ **N** (0 _, R_ ).


**6.2** **Experimental Setup**


In this experiment, we conducted a Monte-Carlo simulation with 600 trials of a simulated UAV equipped with an IMU and a
GNSS receiver. We use the initial 80 seconds from six sequences of the Euroc dataset [28] as the reference trajectories and
generate 100 runs for each sequence. Each run is initialised with a random state sampled from a Gaussian distribution with
20 _[◦]_ standard deviation per axis for the orientation and 1m for the position. The IMU biases are randomly generated every
run following a Gaussian distribution with 0 _._ 1rad/s _[√]_ ~~_s_~~ for the gyroscope and 0 _._ 1m/s [2] _[√]_ ~~_s_~~ for the accelerometer. The global
position measurements are corrupted by additive Gaussian noise with 0 _._ 2m standard deviation per axis. The UAV receives
GNSS measurements at a rate of 10Hz, while the IMU measurements are sampled at 200Hz. This experiment setup is the same
as the one used in [21].


14


P REPRINT


Figure 3: The difference between L-IEKF and R-IEKF with different sub-stepping frequencies in the prediction step. A
zoomed-in view of the rotation difference is shown in the inset.


The initial covariance matrices for both filters are set to be the initial Gaussian distribution which is used to sample the initial
state, converted to a L-CGD or R-CGD representation on **SE** 2 (3), that is, the initial states of two filters satisfy the equivalence
condition (Def. 5.2). In all comparisons, identical input data was provided to both filters.


**6.3** **Filter Equivalence**


In A, we show that for the natural discrete time system (25) the algebraic expressions for the L-IEKF and R-IEKF with reset
are identical. We do not simulate results for this case as the updates are equal up to machine precision.


For a hybrid system, it is necessary to numerically approximate the solution of the continuous-time system. Equivalence of
the filters no longer holds exactly since the standard integration schemes are not equivalent between left- and right- variants.
For the scenario considered, the IMU provides 20 samples for every GPS sample received. It is natural to approximate the
solution of the continuous-time system by using a simple numerical update for each IMU sample and only updating with GPS
measurements when they are available. However, even integrating at the IMU rate, the numerical approximation introduces
noticeable (if small) variation between the Left and Right variants of the filter. To reduce the discretisation error, we implement
a sub-stepping scheme in the prediction step: the continuous-time filter dynamics between two IMU measurement instants are
integrated at a higher internal rate. Concretely, we subdivide the IMU sample interval into _N_ equal sub-steps and apply the
IEKF prediction operation _N_ times while keeping the inertial input constant over each sub-step. Of course, this additional
precision in the solutions does not correspond to the physical reality of the system. However, it does converge to the true
continuous time solution of the sampled data system with zero order hold for the inputs and provides a good framework to
evaluate the contributions of the paper.


Fig. 1 provides results for the two filter implementations with a subsample rate of _N_ = 80, that is 80 steps for every IMU
measurement. The RMSE values for the navigation states and bias states, as well as the average normalised estimation error
squared (ANEES) [29] are computed. Both filters converge smoothly to the true state as shown in Fig. 1, with the ANEES
values close to 1, indicating that the filters are well-calibrated. It is clear that the RMSE values of the navigation states and bias
states for the L-IEKF and R-IEKF are nearly identical.


In Fig. 2, we plot the difference in the state estimates of the L-IEKF and R-IEKF for each state variable. The difference of
the covariance matrices is computed using the affine-invariant Riemannian distance (AIRM) of symmetric positive-definite
matrices [30] after applying the adjoint map, given by

_d_ AIRM (Σ L _,_ Σ _[′]_ R [) =] _[ ∥]_ [log(Σ] L _[−]_ [1] _[/]_ [2] Σ _[′]_ R [Σ] _[−]_ L [1] _[/]_ [2] ) _∥_ _F_ _,_


_⊤_

where Σ _[′]_ R [= Ad] _[∨]_ _x_ ˆ _[−]_ R [1] [Σ] [R] [Ad] _x_ _[∨]_ ˆ _[−]_ R [1] . The value of AIRM represents, in percentage terms, how much the standard deviation of two

covariance error-ellipsoids differs along each principal axis.


As shown in Fig. 2, a minor discrepancy in the rotation estimate is observed initially (approximately 0 _._ 0003 deg), which
decreases and remains around 0 _._ 0001 deg throughout the remainder of the trajectory. The rest of the state variables, including


15


P REPRINT


Figure 4: The RMSE and ANEES of the L-IEKF and R-IEKF with and without the reset step.


position, velocity, and biases, show no significant difference between the two filters. The AIRM value of the covariance matrices
remains at around 0 _._ 0004 throughout the trajectory, which corresponds to 0 _._ 04% difference between the standard deviations of
the two covariance matrices along each principal axis.


These results demonstrate the equivalence of the L-IEKF and R-IEKF (with reset) in practice.


**6.4** **Discretisation Analysis**


In this section, we study the error introduced by the discretisation of the IEKF filter equation. In this experiment, we implement
the L-IEKF and R-IEKF with different sub-stepping rates _N_ in the prediction step, differing from 1 to 80. The results are
shown in Fig. 3, with a zoomed-in view of the rotation difference in the inset to highlight the minor differences. Note that for
_N_ = 1 we are still propagating for every IMU measurement and only applying the reset step (every 20 samples) when a GPS
measurement is available.


It can be seen that when performing an explicit Euler integration with _N_ = 1, the average difference in the rotation estimate
is at the scale of 0 _._ 01 deg. As the sub-stepping rate increases, the differences in the state estimates and covariance matrices
between the L-IEKF and R-IEKF decrease almost linearly.


We claim that these results demonstrate that while discretisation introduces minor numerical differences between the implementations, these differences decrease with higher sampling frequencies and do not reflect any fundamental distinction between
the filters.


**6.5** **Reset Step Ablation Study**


The reset step is a key component in the equivalence proof. The original papers on the EKF [1] and TFG-IEKF [22] do not
include the reset step, relying instead on the underlying parallelism of a Lie group for the reset. Without the reset step, then the
Left- and Right- variants of the IEKF are certainly not equivalent, and it is of interest to consider what difference in performance
is present in this case. It is also of interest to ask whether the reset step improves the performance of the filter in general. In this
section, we conduct an ablation study to investigate the effect of the reset step on the performance of the IEKF.


We implement the L-IEKF and R-IEKF with and without the reset step. Results are shown in Fig. 4. Broadly, the filters have
similar responses and asymptotic performance, however, there are several important differences in the details. Consider the
top left plot Fig. 4 showing rotational error. Here, the L-IEKF (the filter that matches the error symmetry to the measurement
symmetry as is often recommended in the literature) demonstrates a significant improvement in performance during the transient


16


P REPRINT


(the first 15s of the response). The two algorithms with reset have identical responses (as expected) while the Right-IEKF
(that opposes the error and measurement symmetry) performs worse. These results have been consistently replicated for a
range of different scenarios and data and the authors believe that this reflects a substantive behaviour, although we only have
empirical evidence for this. After the initial transient period, however, the algorithms that implement the reset step benefit
from the improved stochastic properties of the modified covariance update. This effect has been noted in prior studies [20]
and while the authors have chosen parameters for this simulation that emphasise the effect, we have never seen an IEKF or
EqF filter implemented without reset outperform a filter implemented with reset in the asymptotic phase of the response. The
observations that are most striking in the attitude are replicated to a lesser degree across the other state variables, including
position and velocity. Similar trends are observed in the ANEES values.


The authors hypothesise that the initial performance advantage for the L-IEKF in the transient is related to the fact that the
measurement noise in GPS lies in a linear space R [3] and the Bayesian fusion step of the EKF is globally exact on Euclidean
space when the error and measurement symmetries are matched. The reset step introduces coupling and nonlinearities into
this update step due to the remapping of the covariance. We believe that during the transient when the error is very large,
the benefit of the globally exact fusion outweighs the benefit of the stochastic correction of the reset. However, during the
asymptotic phase, the Bayesian fusion in local coordinates does not incur the same performance loss and the benefit of the reset
step dominates. We have not obtained empirical or analytic evidence to support this hypothesis at this time.


**7** **Conclusion**


In this paper, we have demonstrated the mathematical and practical equivalence of the Left-Invariant Extended Kalman Filter (LIEKF) and the Right-Invariant Extended Kalman Filter (R-IEKF). Our theoretical analysis proves that when properly initialised
and implemented with the correct reset step, the two filters yield identical state estimates and equivalent probability distributions
regardless of the choice of handedness. The experimental results using a GNSS-aided inertial navigation system confirm the
theoretical findings. Furthermore, we show that for the INS problem, an L-IEKF without reset may well outperform the IEKF
implemented with reset step during the transient, but not during the asymptotic phase of the filter. This effect may well underlie
the community’s understanding that matching the filter symmetry to the measurement is important, however, we recommend
that the filter with reset is used as the default and then the choice of handedness is moot.


**A** **Equivalence of the L-IEKF and R-IEKF for discrete-time systems**


In the main result (Sec. 5.2), we proved that the prediction step of the L-IEKF and R-IEKF yields equivalent estimates for hybrid
systems. However, the equivalence no longer holds when the continuous-time filter dynamics are discretised and implemented
on a digital computer. In this section, we show that given a discrete-time system, the discrete L-IEKF and R-IEKF are equivalent
as well. We will only consider the prediction step of the L-IEKF and R-IEKF, as the update and reset steps remain identical in
the discrete-time case.


Consider a noise-free discrete-time system on a Lie group **G** given by


_X_ _k_ +1 = _F_ _v_ ( _X_ _k_ ) = _X_ _k_ Φ( _X_ _k_ _, v_ _k_ ) _,_


where _X_ _k_ _∈_ **G** is the true state at time step _k_, _F_ _v_ ( _X_ _k_ ) is the discrete-time flow induced by the velocity _v_ _k_ _∈_ L. One may
define the system evolution function with left trivialisation by Φ( _X_ _k_ _, v_ _k_ ) = _X_ _k_ +1 _X_ _k_ _[−]_ [1] _∈_ **G** . We make the assumption that the
process noise is left-invariant and enters the system as a Gaussian process on the Lie algebra g, i.e.


_X_ _k_ +1 = _X_ _k_ Φ( _X_ _k_ _, v_ _k_ ) exp **G** ( _w_ _k_ _[∧]_ [)] _[,]_ _w_ _k_ _∼_ **N** (0 _, Q_ _k_ ) (25)


where _Q_ _k_ is a positive-definite covariance matrix. This follows the definition of the general dynamical system provided in [31].
To enhance readability and avoid excessive use of subscripts, we will drop the subscript _k, k_ + 1 and use the notation _X, X_ _[−]_ to
align with the notation used in the main text.


**Remark A.1.** _If one considers a pure left-invariant continuous-time system with noise_


1
d _X_ = _X_ (Λ( _v_ )d _t_ + Υ[ _Q_ 2 _dw_ ])


_then if the velocity v_ = _v_ _k_ _is constant on short time intervals, the model can be integrated into an exact noisy discrete-time_
_model on the Lie-group_


_X_ _k_ +1 = _X_ _k_ exp **G** (Λ( _v_ _k_ ) _δt_ + _w_ _k_ _[∧]_ [)] _[,]_ _w_ _k_ _∼_ **N** (0 _, δt_ Υ _Q_ Υ _[⊤]_ ) (26)


_where the Gaussian process lives on the Lie-algebra_ g _. This construction differs from the general discrete-time model_ (25) _by_
_the higher-order terms in the Baker–Campbell– Hausdorff (BCH) expansion. One may choose to keep the first commutator_
_from the BCH expansion to obtain second-order accuracy in the noise model, however, the modelling choice does not affect the_
_equivalence proof._


17


P REPRINT


Given the discrete-time system (25) and the pre-observer system
_X_ ˆ _[−]_ = ˆ _X_ Φ( ˆ _X, v_ ) _,_


the left-invariant error and its dynamics are given by

_E_ L _[−]_ [= ˆ] _[X]_ L _[−]_ _−_ 1 _X_ L _−_
= Φ( _X_ [ˆ] L _, v_ ) _[−]_ [1] _E_ L Φ( _X_ [ˆ] L _E_ L _, v_ ) exp **G** ( _w_ _[∧]_ ) _._


Similarly, one can define the right-invariant error and its dynamics


_−_ 1
_E_ R _[−]_ [=] _[ X]_ R _[−]_ _[X]_ [ˆ] R _[−]_

= _E_ R _X_ [ˆ] R Φ( _E_ R _X_ [ˆ] R _, v_ ) exp **G** ( _w_ _[∧]_ )Φ( _X_ [ˆ] R _, v_ ) _[−]_ [1] [ ˆ] _X_ R _[−]_ [1] _[.]_

**Definition A.2** (L-IEKF discrete-time prediction step) **.** _Let_ ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) _denote the L-IEKF state with µ_ L = 0 _at time t_ _k_ _. The_
_discrete-time prediction step of the L-IEKF is given by_


_µ_ _[−]_ L [= 0] _[,]_
_X_ ˆ L _[−]_ [= ˆ] _[X]_ [L] [Φ( ˆ] _[X]_ [L] _[, v]_ [)] _[,]_

Σ _[−]_ L [=] **[ A]** [L] [Σ] [L] **[A]** L _[⊤]_ [+] **[ B]** [L] _[Q]_ **[B]** _[⊤]_ L _[,]_


_where_ **A** L _and_ **B** L _are the linearisation matrices defined by_

**A** L := DL Φ( ˆ _X_ L _,v_ ) _−_ 1 _·_ D _X_ _|_ _X_ ˆ L [Φ(] _[X, v]_ [)] _[ ·]_ [ DL] _X_ [ ˆ] L
+ Ad _[∨]_ Φ( _X_ [ˆ] L _,v_ ) _−_ 1 _,_


**B** L := _I._


**Definition A.3** (R-IEKF discrete-time prediction step) **.** _Let_ ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) _denote the R-IEKF state with µ_ R = 0 _at time t_ _k_ _._
_The discrete-time prediction step of the R-IEKF is given by_


_µ_ _[−]_ R [= 0] _[,]_
_X_ ˆ R _[−]_ [= ˆ] _[X]_ [R] [Φ( ˆ] _[X]_ [R] _[, v]_ [)] _[,]_

Σ _[−]_ R [=] **[ A]** [R] [Σ] [R] **[A]** R _[⊤]_ [+] **[ B]** [R] _[Q]_ **[B]** _[⊤]_ R _[,]_


_where_ **A** R _and_ **B** R _are the linearisation matrices defined by_

**A** R := Ad _[∨]_ _X_ ˆ R _[·]_ [DR] Φ( _X_ [ˆ] R _,v_ ) _[·]_ [ D] _[X]_ _[|]_ _X_ [ ˆ] R [Φ(] _[X, v]_ [)] _[ ·]_ [ DR] [ ˆ] _X_ R _[−]_ _[I,]_

**B** R := Ad _[∨]_ _X_ ˆ R _[−]_ _[.]_


**Lemma A.4.** _(Discrete-time prediction step equivalence) The discrete-time prediction steps of the L-IEKF and R-IEKF are_
_equivalent, i.e. Let_ ( _µ_ L _,_ _X_ [ˆ] L _,_ Σ L ) _and_ ( _µ_ R _,_ _X_ [ˆ] R _,_ Σ R ) _be the states of the L-IEKF and R-IEKF, respectively, with µ_ L = 0 _and_
_µ_ R = 0 _. Suppose that the L-IEKF and R-IEKF states are equivalent (Def. 5.2) before the prediction step, then the states after_
_the prediction step remain equivalent._


_Proof._ It is straightforward to see that the mean _µ_ and the reference state _X_ [ˆ] remain equivalent after the prediction step. To
prove the equivalence of the covariance matrices, it suffices to show that



**A** R = Ad _[∨]_ _X_ ˆ L _[−]_ **[A]** [L] [Ad] _X_ _[∨]_ ˆ L



_−_ 1
_,_ (27)



**B** R = Ad _[∨]_ _X_ ˆ L _[−]_ **[B]** [L] _[.]_ (28)



To prove (27), one has



Ad _[∨]_ ˆ ˆ
_X_ L _[−]_ **[A]** [L] [Ad] _X_ _[∨]_ L



_−_ 1



= Ad _[∨]_ _X_ ˆ L _[−]_ [DL] [Φ( ˆ] _X_ L _,v_ ) _−_ 1 D _X_ _|_ _X_ ˆ L [Φ(] _[X, v]_ [)DL] _X_ [ ˆ] L [Ad] _X_ _[∨]_ ˆ L



_−_ 1



+ Ad _[∨]_ _X_ ˆ L _[−]_ [Ad] _[∨]_ Φ( _X_ [ˆ] L _,v_ ) _−_ 1 Ad _[∨]_ _X_ ˆ L

= DL _X_ ˆ L _[−]_ [DR] [ ˆ] _X_ L _[−]_ [D] _[X]_ _[|]_ _X_ [ ˆ] L [Φ(] _[X, v]_ [)DL] _X_ [ ˆ] L [DR] [ ˆ] _X_ L [DR] [ ˆ] _X_ L

+ Ad _[∨]_ _X_ ˆ L _[−]_ [Ad] _[∨]_ Φ( _X_ [ˆ] L _,v_ ) _−_ 1 Ad _[∨]_ _X_ ˆ L

= Ad _[∨]_ ˆ
_X_ L [DR] Φ( _X_ [ˆ] L _,v_ ) [D] _[X]_ _[|]_ _X_ [ ˆ] L [Φ(] _[X, v]_ [)DR] _X_ [ ˆ] L _[−]_ _[I]_


= **A** R _._



_−_ 1


_−_ 1



The proof of condition (28) follows directly from the definition of **B** R and **B** L . This completes the proof of the lemma.


18


P REPRINT


**References**


[1] A. Barrau and S. Bonnabel, “The invariant extended kalman filter as a stable observer,” _IEEE Transactions on Automatic_
_Control_, vol. 62, no. 4, pp. 1797–1812, 2017. 1, 2, 8, 16


[2] P. S. Maybeck, _Stochastic models, estimation, and control_ . Academic press, 1982. 1


[3] T. D. Barfoot, _State estimation for robotics_ . Cambridge University Press, 2017. 1


[4] R. E. Kalman, “A new approach to linear filtering and prediction problems,” 1960. 1


[5] G. L. Smith, S. F. Schmidt, and L. A. McGee, _Application of statistical filter theory to the optimal estimation of position_
_and velocity on board a circumlunar vehicle_ . National Aeronautics and Space Administration, 1962. 1


[6] J. Thienel and R. Sanner, “A coupled nonlinear spacecraft attitude controller and observer with an unknown constant gyro
bias and gyro noise,” _IEEE Transactions on Automatic Control_, vol. 48, no. 11, pp. 2011–2015, 2003. 1


[7] R. Mahony, T. Hamel, and J.-M. Pflimlin, “Nonlinear complementary filters on the special orthogonal group,” _IEEE_
_Transactions on Automatic Control_, vol. 53, no. 5, pp. 1203–1218, 2008. 1


[8] S. Bonnabel, “Left-invariant extended kalman filter and attitude estimation,” in _2007 46th IEEE Conference on Decision_
_and Control_, 2007, pp. 1027–1032. 2


[9] S. Bonnable, P. Martin, and E. Sala¨un, “Invariant extended kalman filter: theory and application to a velocity-aided attitude
estimation problem,” in _Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009_
_28th Chinese Control Conference_, 2009, pp. 1297–1304. 2


[10] Y. Wang and G. S. Chirikjian, “Error propagation on the euclidean group with applications to manipulator kinematics,”
_IEEE Transactions on Robotics_, vol. 22, no. 4, pp. 591–602, 2006. 2, 3, 4


[11] A. W. Long, K. C. Wolfe, M. J. Mashner, G. S. Chirikjian _et al._, “The banana distribution is gaussian: A localization study
with exponential coordinates,” _Robotics: Science and Systems VIII_, vol. 265, 2013. 2


[12] A. Barrau and S. Bonnabel, “Invariant kalman filtering,” _Annual Review of Control, Robotics, and Autonomous Systems_,
vol. 1, no. 1, pp. 237–257, 2018. 2


[13] R. Mahony, P. van Goor, and T. Hamel, “Observer design for nonlinear systems with equivariance,” _Annual_
_Review of Control,_ _Robotics,_ _and Autonomous Systems_, vol. 5, no. 1, p. null, 2022. [Online]. Available:
[https://doi.org/10.1146/annurev-control-061520-010324 2, 3, 7](https://doi.org/10.1146/annurev-control-061520-010324)


[14] P. van Goor, T. Hamel, and R. Mahony, “Equivariant filter (eqf),” _IEEE Transactions on Automatic Control_, 2022. 2, 8


[15] Y. Ge, P. van Goor, and R. Mahony, “Equivariant filter design for discrete-time systems,” in _2022 IEEE 61st Conference_
_on Decision and Control (CDC)_ . IEEE, 2022, pp. 1243–1250. 2, 3, 7


[16] R. Hartley, M. Ghaffari, R. M. Eustice, and J. W. Grizzle, “Contact-aided invariant extended kalman filtering for robot
state estimation,” _The International Journal of Robotics Research_, vol. 39, no. 4, pp. 402–430, 2020. 2


[17] J. Han, W. Ouyang, M. Zhu, and Y. Wu, “On covariance switch-based invariant extended kalman filter for multi-source
fusion,” _Guidance, Navigation and Control_, 2024. 2, 4


[18] G. S. Chirikjian, _Stochastic Models, Information Theory, and Lie Groups, Volume 2: Analytic Methods and Modern_
_Applications_ . Springer, 2011. 2, 4, 8


[19] Y. Ge, P. van Goor, and R. Mahony, “A geometric perspective on fusing gaussian distributions on lie groups,” _IEEE_
_Control Systems Letters_, vol. 8, pp. 844–849, 2024. 2, 3, 7


[20] M. W. Mueller, M. Hehn, and R. D’Andrea, “Covariance correction step for kalman filtering with an attitude,” _Journal of_
_Guidance, Control, and Dynamics_, vol. 40, no. 9, pp. 2301–2306, 2017. 2, 3, 7, 17


[21] A. Fornasier, Y. Ge, P. van Goor, R. Mahony, and S. Weiss, “Equivariant symmetries for inertial navigation systems,”
_arXiv preprint arXiv:2309.03765_, 2023. 2, 13, 14


[22] A. Barrau and S. Bonnabel, “The geometry of navigation problems,” _IEEE Transactions on Automatic Control_, vol. 68,
no. 2, pp. 689–704, 2022. 2, 13, 16


[23] F. G. Maurer, E. A. Basso, H. M. Schmidt-Didlaukies, and T. H. Bryne. Equivalence of Left- and Right-Invariant
[Extended Kalman Filters on Matrix Lie Groups. arXiv.org. [Online]. Available: https://arxiv.org/abs/2506.01514v1 2, 3,](https://arxiv.org/abs/2506.01514v1)
10


[24] J. Ye, A. S. Jayaraman, and G. S. Chirikjian, “Uncertainty Propagation on Unimodular Matrix Lie Groups,” pp. 1–16.

[[Online]. Available: https://ieeexplore.ieee.org/abstract/document/10735369 3, 4](https://ieeexplore.ieee.org/abstract/document/10735369)


[25] S. J. Julier, J. K. Uhlmann, and H. F. Durrant-Whyte, “A new approach for filtering nonlinear systems,” in _Proceedings of_
_1995 American Control Conference-ACC’95_, vol. 3. IEEE, 1995, pp. 1628–1632. 4


[26] Y. Ge, P. van Goor, and R. Mahony. The Geometry of Extended Kalman Filters on Manifolds with Affine Connection.
[arXiv.org. [Online]. Available: https://arxiv.org/abs/2506.05728v1 7](https://arxiv.org/abs/2506.05728v1)


19


P REPRINT


[27] X. Li, J. Chen, H. Zhang, J. Wei, and J. Wu, “Error Dynamics in Affine Group Systems,” vol. 70, no. 4, pp. 2607–2614.

[[Online]. Available: https://ieeexplore.ieee.org/abstract/document/10741892 9](https://ieeexplore.ieee.org/abstract/document/10741892)

[28] M. Burri, J. Nikolic, P. Gohl, T. Schneider, J. Rehder, S. Omari, M. W. Achtelik, and R. Siegwart, “The EuRoC micro
[aerial vehicle datasets,” vol. 35, no. 10, pp. 1157–1163. [Online]. Available: https://doi.org/10.1177/0278364915620033](https://doi.org/10.1177/0278364915620033)
14

[29] X. R. Li, Z. Zhao, and X.-B. Li, “Evaluation of Estimation Algorithms: Credibility Tests,” vol. 42, no. 1, pp. 147–163.

[[Online]. Available: https://ieeexplore.ieee.org/document/5941029 15](https://ieeexplore.ieee.org/document/5941029)

[30] R. Bhatia, _Positive definite matrices_ . Princeton university press, 2009. 15

[31] A. Barrau and S. Bonnabel, “Invariant Kalman Filtering,” vol. 1, pp. 237–257. [Online]. Available: [https:](https://www.annualreviews.org/content/journals/10.1146/annurev-control-060117-105010)
[//www.annualreviews.org/content/journals/10.1146/annurev-control-060117-105010 17](https://www.annualreviews.org/content/journals/10.1146/annurev-control-060117-105010)


20


