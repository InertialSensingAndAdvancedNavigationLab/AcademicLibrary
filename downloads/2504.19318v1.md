1

## Unscented Particle Filter for Visual-inertial Navigation using IMU and Landmark Measurements


Khashayar Ghanizadegan and Hashim A. Hashim



_**Abstract**_ **—This paper introduces a geometric Quaternion-**
**based Unscented Particle Filter for Visual-Inertial Navigation**
**(QUPF-VIN) specifically designed for a vehicle operating with six**
**degrees of freedom (6 DoF). The proposed QUPF-VIN technique**
**is quaternion-based capturing the inherently nonlinear nature**
**of true navigation kinematics. The filter fuses data from a low-**
**cost inertial measurement unit (IMU) and landmark observations**
**obtained via a vision sensor. The QUPF-VIN is implemented**
**in discrete form to ensure seamless integration with onboard**
**inertial sensing systems. Designed for robustness in GPS-denied**
**environments, the proposed method has been validated through**
**experiments with real-world dataset involving an unmanned**
**aerial vehicle (UAV) equipped with a 6-axis IMU and a stereo**
**camera, operating with 6 DoF. The numerical results demonstrate**
**that the QUPF-VIN provides superior tracking accuracy com-**
**pared to ground truth data. Additionally, a comparative analysis**
**with a standard Kalman filter-based navigation technique further**
**highlights the enhanced performance of the QUPF-VIN.**


I. I NTRODUCTION
# A CCURATE navigation algorithms are crucial for au-tonomous ground and aerial vehicles, particularly in both

indoor and outdoor applications where Global Positioning
System (GPS) signals may be unavailable or unreliable. These
techniques are essential for tasks such as warehouse management, surveillance, road and pipeline inspection, package
delivery, and household robotics [1]–[3]. In such cases, GPSindependent navigation solutions become critical. In GPSdenied environments, autonomous vehicles rely on robust
algorithms capable of providing reliable estimates using costeffective inertial measurement units (IMUs). Navigation can be
achieved with low-cost onboard sensors, such as 6-axis IMUs
and either stereo or monocular cameras [1], [3]. A 6-axis IMU,
comprising a gyroscope and accelerometer, provides measurements of a vehicle’s angular velocity and linear acceleration.
Dead-reckoning, which has been extensively studied, is commonly used to estimate a vehicle’s navigation state (attitude
(orientation), position, and linear velocity), while operating
with six degrees of freedom (6 DoF) [1], [3]. This technique
relies solely on IMU data, using numerical integration based
on the vehicle’s initial state. However, dead-reckoning is prone
to error accumulation, making it unsuitable for long-distance
navigation [3]. Attitude-only estimation, on the other hand, can
be reliably achieved through IMU measurements using robust


This work was supported in part by National Sciences and Engineering
Research Council of Canada (NSERC), under the grants RGPIN-2022-04937
and DGECR-2022-00103.
K. Ghanizadegan and H. A. Hashim are with the Department of Mechanical
and Aerospace Engineering, Carleton University, Ottawa, Ontario, K1S-5B6,
Canada (e-mail: hhashim@carleton.ca).



attitude filters, including deterministic filters [4] and stochastic
approaches [3], [5], [6].
Pose estimation (attitude and position) of a vehicle navigating in three-dimensional (3D) space can be achieved through
sensor fusion, such as the integration of landmark measurements from a vision system and data from an IMU. Commonly
used filters for pose estimation include Kalman filters, the
Extended Kalman Filter (EKF), and nonlinear filters [7], [8].
However, these algorithms typically require knowledge of the
vehicle’s linear velocity, which poses a significant challenge in
GPS-denied environments. In practice, uncertain attitude and
position can be reconstructed through the fusion of vision data
and IMU measurements [9]. Nevertheless, deriving or optimizing linear velocity from reconstructed uncertain attitude and
position data proves impractical and unreliable. As a result,
there is a growing demand for robust navigation techniques
that can handle measurement uncertainties, provide accurate
attitude and position estimates, and observe the vehicle’s linear
velocity, which is often considered a hidden state [3]. True 6
DoF navigation kinematics are highly nonlinear [3], making
linear filters inadequate for accurate navigation estimation

[3], [10]. Kalman filters (KF) have been applied to visionbased navigation [11], with modifications such as the EKF

[11] introduced to account for system nonlinearity. Further
enhancements, like the Multiplicative EKF (MEKF) [2] and
the Multi-State Constraint Kalman Filter (MSCKF) [12], were
developed to improve accuracy and address consistency issues.
Additionally, Unscented Kalman Filters (UKF) [13] have been
proposed to better address the nonlinearity of kinematic models. However, the main limitation of KF is its disregard for navigation nonlinearities, while EKF linearizes the system around
a nominal point. MEKF, MSCKF, and UKF rely on parametric
statistical models that fail to capture the full complexity of
arbitrary distributions in nonlinear navigation systems. The
Particle Filter (PF) [14], which can capture arbitrary distributions, has been applied to navigation problems but struggles
numerically when dealing with relatively accurate sensors.
These sensors generate narrow distributions, causing particles
to receive near-zero probabilities if they deviate slightly from
the distribution’s peak, thus hindering effective guidance. The
Unscented PF (UPF) [15] addresses this limitation by using
UKF to propagate particles and estimate their mean and
covariance, resulting in better alignment with the posterior
distribution. This approach overcomes the shortcomings of PF
when dealing with narrow distributions [15].
_Contribution:_ This paper presents a geometric
Quaternion-based Unscented Particle Filter for VisualInertial Navigation (QUPF-VIN) that relies on sensor data


TABLE I: Nomenclature


_{B}_ / _{W}_ : Fixed body-frame / fixed world-frame


SO (3) : Special Orthogonal Group of order 3


S [3] : Three-unit-sphere


R _[n]_ [1] _[×][n]_ [2] : _n_ 1 -by- _n_ 2 real space


_q_ _k_ _,_ ˆ _q_ _k_ : True and estimated quaternion at step _k_


_p_ _k_ _,_ ˆ _p_ _k_ : True and estimated position at step _k_


_v_ _k_ _,_ ˆ _v_ _k_ : True and estimated linear velocity at step _k_


_r_ _e,k_, _p_ _e,k_, _v_ _e,k_ : Attitude, position, and velocity estimation error


_a_ _k_ _, a_ _m,k_ : True and measured acceleration at step _k_


_ω_ _k_ _, ω_ _m,k_ : True and measured angular velocity at step _k_


_n_ _ω,k_ _, n_ _a,k_ : Angular velocity and acceleration measurements
noise


_b_ _ω,k_ _, b_ _a,k_ : Angular velocity and acceleration measurements
bias


_C_ _×_ : Covariance matrix of _×_ .


_f_ _b_ _, f_ _w_ : landmark points coordinates in _{B}_ and _{W}_ .


_x_ _k_, _u_ _k_ : The state, and input vectors at the _k_ th time step


_z_ _k_ : True measurement



skew-symmetric of _x ∈_ R [3] such that



 _∈_ so(3) _,_ _x_ =





2




(1)




_x_ 1

 _x_ 2

 _x_ 3




[ _x_ ] _×_ =



0 _−x_ 3 _x_ 2

 _x_ 3 0 _−x_ 1

 _−x_ 2 _x_ 1 0



_{X_ _k_ [(] _[i]_ _|l_ [)] _[}]_ [,]

_{X_ _k_ [(] _[i]_ _|l_ [)] _[a]_ _[}]_ [,]
_{Z_ _k|l_ _}_



: Sigma points of state, augmented state, and

measurements



_{X_ _k_ [(] _[i]_ [)] _[}]_ : Particles at step _k_


from a 6-axis IMU and landmark measurements. The

proposed filter captures the nonlinear nature of navigation
kinematics and is designed and implemented in a geometric
discrete form at a low sampling rate. The effectiveness of
QUPF-VIN is validated using a real-world quadrotor dataset,
which includes low-cost IMU data and stereo images, and is
compared against ground-truth data. The proposed navigation
algorithm is suitable for implementation in both Unmanned
Aerial Vehicles (UAVs) and ground vehicles.


_Structure:_ The remainder of the paper is organized as
follows: Section II discusses important math notation and preliminaries. Section III presents the true navigation kinematics
and inertial measurement data (IMU and landmarks). Section
IV introduces the QUPF-VIN, and steps of implementation.
Section V illustrates the output performance of the proposed
QUPF-VIN using a dataset obtained from real quadrotor flight
and compares QUPF-VIN performance to a baseline filter.
Finally, Section VI provides concluding remarks.


II. P RELIMINARY AND M ATH N OTATION


The set of _n_ 1 -by- _n_ 2 real number matrices are described by
R _[n]_ [1] _[×][n]_ [2] . For a vector _x ∈_ R _[n]_ _[x]_, the Euclidean norm is denoted
by _∥x∥_ = _√x_ _[⊤]_ _x ∈_ R. **I** _n_ _∈_ R _[n][×][n]_ denotes an identity matrix.

_{W}_ describes the world-frame fixed to the Earth while _{B}_
refers to the body-frame fixed to a moving vehicle. Table I lists
a set of important symbols used subsequently. [ _x_ ] _×_ denotes



vex( _·_ ) describes the inverse mapping where vex([ _x_ ] _×_ ) = _x ∈_
R [3] . For _D ∈_ R [3] _[×]_ [3], the anti-symmetric projection operator is
given by:

_P_ _a_ ( _D_ ) = [1] (2)

2 [(] _[D][ −]_ _[D]_ _[⊤]_ [)] _[ ∈]_ [so][(3)]


Orientation of a vehicle is denoted by _R ∈_ SO(3) where
SO(3) refers to the Special Orthogonal Group such that [16]:


SO(3) := � _R ∈_ R [3] _[×]_ [3] [��] _det_ ( _R_ ) = +1 _, R_ _[⊤]_ _R_ = **I** 3 � (3)


Unit-quaternion _q_ = [ _q_ _w_ _, q_ _x_ _, q_ _y_ _, q_ _z_ ] _[⊤]_ = [ _q_ _w_ _, q_ _v_ _[⊤]_ []] _[⊤]_ _[∈]_ [S] [3] [ where]
_q_ _v_ _∈_ R [3] and _q_ _w_ _∈_ R can be used to describe the vehicle’s
orientation where


S [3] := � _q ∈_ R [4] [��] _|q∥_ = 1� (4)


and the vehicle’s orientation is given by [16]:


_R_ _q_ ( _q_ ) = ( _q_ _w_ [2] _[−∥][q]_ _[v]_ _[∥]_ [2] [)] _[I]_ [3] [+ 2] _[q]_ _[v]_ _[q]_ _v_ _[⊤]_ [+ 2] _[q]_ _[w]_ [[] _[q]_ _[v]_ []] _[×]_ _[∈]_ [SO][(3)][ (5)]


Define _⊗_ as quaternion product of two quaternions such that
the quaternion product of _q_ 1 = [ _q_ _w_ 1 _, q_ _v_ 1 ] _[⊤]_ _∈_ S [3] and _q_ 2 =

[ _q_ _w_ 2 _, q_ _v_ 2 ] _[⊤]_ _∈_ S [3] is [16]:


_q_ 3 = _q_ 1 _⊗_ _q_ 2



The following quaternion subtraction operator is defined:


_q_ 1 _⊖_ _q_ 2 := _r_ _q_ ( _q_ 1 _⊗_ _q_ 2 _[−]_ [1] [)] _[ ∈]_ [R] [3] _[,]_ _∀q_ 1 _, q_ 2 _∈_ S [3] (11)



= _q_ _w_ 1 _q_ _w_ 2 _−_ _q_ _v_ _[⊤]_ 1 _[q]_ _[v]_ [2]
� _q_ _w_ 1 _q_ _v_ 2 + _q_ _w_ 2 _q_ _v_ 1 + [ _q_ _v_ 1 ] _×_ _q_ _v_ 2



_∈_ S [3] (6)
�



and the inverse quaternion of _q_ = [ _q_ _w_ _, q_ _v_ _[⊤]_ []] _[⊤]_ _[∈]_ [S] [3] [ is defined]
by _q_ _[−]_ [1] = [ _q_ _w_ _, −q_ _v_ _[⊤]_ []] _[⊤]_ _[∈]_ [S] [3] [.] _[ q]_ _[I]_ [= [1] _[,]_ [ 0] _[,]_ [ 0] _[,]_ [ 0]] _[⊤]_ [describes]
the quaternion identity such that _q ⊗_ _q_ _[−]_ [1] = _q_ _I_ . Angle-axis
parameterization describes the orientation as a rotation (angle)
_α ∈_ R around a unit vector (axis) _v_ = [ _v_ 1 _, v_ 2 _, v_ 3 ] _∈_ S [2] such
that
_r_ = _r_ _α,v_ ( _α, v_ ) = _αv ∈_ R [3] (7)


where the rotation matrix corresponding to the angle-axis
parameterization is defined by


_R_ _r_ ( _r_ ) = exp([ _r_ ] _×_ ) _∈_ SO(3)

= **I** 3 + sin( _α_ ) [ _v_ ] _×_ + (1 _−_ cos( _α_ )) [ _v_ ] [2] _×_ (8)



2) _−_ 1 _∈_ R and _v_ _R_ =
�



Note that _α_ _R_ = arccos Tr( _R_ 2) _−_ 1
�



1
sin _α_ _R_ [vex(] _[P]_ _[a]_ [(] _[R]_ [))] _[ ∈]_ [S] [2] [ [][16][]. Using the rotation vector] _[ r]_ [ in]
(7), one obtains



with



_q_ _r_ ( _r_ ) = _q_ _R_ ( _R_ _r_ ( _r_ )) _∈_ S [3]

= �cos( _α/_ 2) _,_ sin( _α/_ 2) _v_ _[⊤]_ [�] _[⊤]_ _∈_ S [3] (9)


_r_ _q_ ( _q_ ) = _r_ _α,v_ ( _α_ _R_ ( _R_ _q_ ( _q_ )) _, v_ _R_ ( _R_ _q_ ( _q_ ))) _∈_ R [3] (10)


3



And the quaternion-rotation vector addition and subtraction
operators are defined as:


_q ⊕_ _r_ := _q_ _r_ ( _r_ ) _⊗_ _q ∈_ S [3] _,_ _∀q ∈_ S [3] _, ∀r ∈_ R [3] (12)

_q ⊖_ _r_ := _q_ _r_ ( _r_ ) _[−]_ [1] _⊗_ _q ∈_ S [3] _,_ _∀q ∈_ S [3] _, ∀r ∈_ R [3] (13)


Consider _S_ = _{s_ _i_ _}_ to be scaler weights and let us define the
following term:


_D_ = � _s_ _i_ _q_ _i_ _q_ _i_ _[⊤]_ _[∈]_ [R] [4] _[×]_ [4]


The unit eigenvector associated to eigenvalue with the highest
magnitude can be obtained by:


WM( _Q, W_ ) = EigVector( _D_ ) _i_ _∈_ S [3] (14)


where _i_ = argmax( _|_ EigValue( _D_ ) _i_ _|_ ) _∈_ R, WM( _D, W_ ) denotes
weighted mean, and EigValue( _D_ ) _i_ refers to the _i_ th eigenvalue
of _D_ . The Gaussian probability density function of _a_ is defined
as follows:


P( _a_ ) = _N_ ( _a_ ~~_|a_~~ _, P_ _a_ )



step. The exact discretized system kinematics of (16) is given
by:


_q_ _k_ _q_ _k−_ 1

   







= exp( _M_ _ck−_ 1 _[dT]_ [)]








 (17)







_q_ _k_

_p_ _k_

_v_ _k_

1









_q_ _k−_ 1

_p_ _k−_ 1

_v_ _k−_ 1

1



with _M_ _k_ _[c]_ _−_ 1 [=] _[ M]_ _[ c]_ [(] _[q]_ _[k][−]_ [1] _[, ω]_ _[k][−]_ [1] _[, a]_ _[k][−]_ [1] [)][ and] _[ dT]_ [ being a sample]
time.


_B. VIN Measurement Model_


_IMU data:_ Let _ω_ _m,k_ _∈_ R [3] and _a_ _m,k_ _∈_ R [3] denotes the
measured angular velocity and linear acceleration at _k_ th time
step, respectively, such that
 _ωa_ _m,km,k_ = = _ω a_ _kk_ + + _b b_ _a,kω,k_ + + _n n_ _a,kω,k_ _∈ ∈_ RR [3][3]

(18)

 _b_ _b_ R [3]



_ω_ _m,k_ = _ω_ _k_ + _b_ _ω,k_ + _n_ _ω,k_ _∈_ R [3]

_a_ _m,k_ = _a_ _k_ + _b_ _a,k_ + _n_ _a,k_ _∈_ R [3]



(18)







_b_ _ω,k_ = _b_ _ω,k−_ 1 + _n_ _bω,k−_ 1 _∈_ R [3]

_b_ _a,k_ = _b_ _a,k−_ 1 + _n_ _ba,k−_ 1 _∈_ R [3]



_−_ [1]
= [exp] � 2



_∈_ R
(2 _π_ ) _[n]_ det( _P_ _a_ )




[1] 2 [(] _[a][ −]_ ~~_[a]_~~ ~~[)]~~ _[⊤]_ _[P]_ _a_ _[ −]_ [1] [(] _[a][ −]_ ~~_[a]_~~ ~~[)]~~ �



~~�~~



where _a ∈_ R _[n]_ obtained through a Gaussian distribution _a ∼_
_N_ ~~(~~ ~~_a_~~ _, P_ _a_ ), ~~_a_~~ _∈_ R _[n]_ denotes the mean of _a_, and _P_ _a_ _∈_ R _[n][×][n]_

describes covariance matrix related to _a_ .


III. P ROBLEM F ORMULATION AND S ENSOR D ATA


_A. Navigation Model_


Consider a vehicle travelling in 3D space where _ω ∈_ R [3] denotes its angular velocity and _a ∈_ R [3] describes its acceleration
measured with _ω, a ∈{B}_ . The vehicle’s position and linear
velocity are described by _p ∈_ R [3] and _v ∈_ R [3], respectively,
where _p, v_ _∈{W}_, whereas the vehicle’s orientation is
described in view of quaternion _q ∈_ S [3] and _q ∈{B}_ . The
navigation kinematics is described as follows [3], [17], [18]:
 _q_ ˙ = 2 [1] [Γ(] _[ω]_ [)] _[q][ ∈]_ [S] [3]


˙

 _p_ = _v ∈_ R [3] (15)



˙
_q_ = [1]



2 [Γ(] _[ω]_ [)] _[q][ ∈]_ [S] [3]



where _b_ _ω,k_ denotes angular velocity bias and _b_ _a,k_ denotes
linear acceleration bias. _n_ _ω,k_ _∈_ R [3], _n_ _bω,k_, _n_ _a,k_, and _n_ _ba,k_
describe noise vectors with zero mean (Gaussian distribution)
and _C_ _ω,k_, _C_ _a,k_, _C_ _bω,k_, and _C_ _ba,k_ covariance matrices. Using
(17) and (18), define the state vector _x_ _k_ :

_x_ _k_ = � _q_ _k⊤_ _p_ _[⊤]_ _k_ _v_ _k_ _[⊤]_ _b_ _[⊤]_ _ω,k_ _b_ _[⊤]_ _a,k_ � _⊤_ _∈_ R _m_ _x_ (19)


with _m_ _x_ = 16 being the state dimension. Let us introduce the
augmented and additive noise vectors as follows:
_n_ _x,k_ = � _n_ _⊤ω,k_ _n_ _[⊤]_ _a,k_ � _⊤_ _∈_ R _m_ _nx_
� _n_ _w,k_ = �0 _⊤_ 10 _×_ 1 _n_ _[⊤]_ _bω,k_ _n_ _[⊤]_ _ba,k_ � _⊤_ _∈_ R _m_ _nw_ (20)


where _m_ _n_ _x_ = 6 and _m_ _n_ _w_ = 16. Let _u_ _k_ be input vector at
time step _k_ :

_u_ _k_ = � _ω_ _m,k⊤_ _a_ _[⊤]_ _m,k_ � _⊤_ _∈_ R _m_ _u_ (21)


with _m_ _u_ = 6. Let the augmented state vector be defined as:

_x_ _[a]_ _k_ [=] � _x_ _⊤k_ _n_ _[⊤]_ _x,k_ � _⊤_ _∈_ R _m_ _a_ (22)


with _m_ _a_ = _m_ _x_ + _m_ _n_ _x_ . In view of (17), (18), (20), (21), and
(22), the overall discrete system kinematics is described by

_x_ _k_ = f( _x_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _[, u]_ _[k][−]_ [1] [) +] _[ n]_ _[w,k][−]_ [1] (23)


with f( _·_ ) : R _[m]_ _[a]_ _×_ R _[m]_ _[u]_ _→_ R _[m]_ _[x]_ being the state transition
matrix.
_Camera data:_ Consider _f_ _w,i_ _∈_ R [3] to represent the
coordinates of _i_ th landmark point (feature) in _{W}_ extracted
via a series of stereo camera observations at the _k_ th time step.
Let _f_ _b,i_ _∈_ R [3] denote the _i_ th landmark coordinates in _{B}_
found by triangulating [19] the features in the stereo images
obtained at time step k. These vectors are related to each other
as follows [3]:


_f_ _b,i_ = _R_ _q_ ( _q_ _k_ ) _[⊤]_ ( _f_ _w,i_ _−_ _p_ _k_ ) + _n_ _f,i_ _∈_ R [3] (24)


with _n_ _f,i_ being Gaussian white noise related to each landmark
measurement for all _i ∈{_ 1 _,_ 2 _, . . ., m_ _f_ _}_ and _m_ _f_ being the total
number of landmarks detected at the _k_ th sample time. It is



˙
_p_ = _v ∈_ R [3]



(15)







˙
_v_ = _g_ + _R_ _q_ ( _q_ ) _a ∈_ R [3]



where



0 _−ω_ _[⊤]_
Γ( _ω_ ) = � _ω_ _−_ [ _ω_ ] _×_



_∈_ R [4] _[×]_ [4]
�



and _g ∈{W}_ represents the gravitational acceleration vector.
The Model in (15) can be re-formulated as follows:


_q_ ˙˙ 12 [Γ(] _[ω]_ [)] _[q]_ 0 0 0 _q_

     










1 0 0 0
2 [Γ(] _[ω]_ [)] _[q]_
0 0 _I_ 3 0
0 0 0 _g_ + _R_ _q_ ( _q_ ) _a_
0 0 0 0













=








 (16)







_q_ ˙
_p_ ˙
_v_ ˙

0










_q_

_p_

_v_

1



~~�~~ � ~~�~~ ~~�~~
_M_ _[c]_ ( _q,ω,a_ )


Since the sensor data operates and and is collected in discrete
space, the equation in (16) can be discretized for filter derivation and implementation. Let the subscript _k_ of variable _x_ _k_
refers to a sampled signal _x_, _p_ _k_ _∈_ R [3] at the _k_ th discrete time


4



worth noting that landmark points vary among images captured
at different _k_ th sample time. Let us define the following
relations:
 _f_ _b_ = � _f_ _b,_ _[⊤]_ 1 _f_ _b,_ _[⊤]_ 2 _· · ·_ _f_ _b,m_ _[⊤]_ _f_ � _⊤_ _∈_ R [3] _[m]_ _[f]_
 _f_ _w_ = � _f_ _w, ⊤_ 1 _f_ _w,_ _[⊤]_ 2 _· · ·_ _f_ _w,m_ _[⊤]_ _f_ � _⊤_ _∈_ R 3 _m_ _f_ (25)



_⊤_
_f_ _b_ = � _f_ _b,_ _[⊤]_ 1 _f_ _b,_ _[⊤]_ 2 _· · ·_ _f_ _b,m_ _[⊤]_ _f_ � _∈_ R [3] _[m]_ _[f]_



_f_ _w_ = � _f_ _w, ⊤_ 1 _f_ _w,_ _[⊤]_ 2 _· · ·_ _f_ _w,m_ _[⊤]_ _f_ � _⊤_ _∈_ R 3 _m_ _f_


_⊤_
_n_ _f_ = � _n_ _[⊤]_ _f,_ 1 _n_ _[⊤]_ _f,_ 2 _· · ·_ _n_ _[⊤]_ _f,m_ _f_ � _∈_ R [3] _[m]_ _[f]_



(25)



_A. QUPF-VIN Initialization_


_Step 1. Initialization:_ QUPF-VIN initialization relies on

_⊤_
assigning an initial state estimate ˆ _x_ 0 _|_ 0 = � _x_ ˆ _[⊤]_ 0 _|_ 0 _,q_ _[,]_ [ ˆ] _[x]_ 0 _[⊤]_ _|_ 0 _,−_ � _∈_
R _[m]_ _[x]_ and covariance matrix _P_ 0 _|_ 0 . ˆ _x_ 0 _|_ 0 _,q_ _∈_ S [3] and ˆ _x_ 0 _|_ 0 _,−_ _∈_
R _[m]_ _[x]_ _[−]_ [4] refer to quaternion and non-quaternion components,
respectively. As straightforward quaternion subtraction is not
feasible, the custom quaternion subtraction presented in (11)
is utilized to enable quaternion subtraction. Consider the
following initialization:


_⊤_

ˆ ˆ

_x_ 0 _|_ 0 = � _x_ _[⊤]_ 0 _|_ 0 _,q_ _[,]_ [ ˆ] _[x]_ 0 _[⊤]_ _|_ 0 _,−_ � _∈_ R _[m]_ _[x]_ (28)

 _[m]_ _[−]_ _[×]_ _[m]_ _[−]_







From (25), the expression in (24) can be reformulated as
follows:


_f_ _b,k_ = _z_ _k_ = h( _x_ _k_ _, f_ _w_ ) + _n_ _f,k_ _∈_ R _[m]_ _[z]_ (26)


where


_n_ _f_ _∼_ _N_ (0 _, C_ _f_ _∈_ R _[m]_ _[z]_ _[×][m]_ _[z]_ ) (27)


Note that _m_ _z_ = 3 _m_ _f_ .


IV. QUPF-VIN D ESIGN


In this section, the objective is to develop a quaternion-based
unscented particle filter tailored for visual-inertial navigation
and applicable to vehicles travelling in GPS-denied regions.
The QUPF-VIN is based on the UKF [15], modified to
operate within the S [3] space and effectively manage the reduced
dimensionality of quaternions. Fig. 1 provides an illustrative
diagram of the proposed QUPF-VIN approach.



_⊤_

ˆ ˆ

_x_ 0 _|_ 0 = � _x_ _[⊤]_ 0 _|_ 0 _,q_ _[,]_ [ ˆ] _[x]_ 0 _[⊤]_ _|_ 0 _,−_ � _∈_ R _[m]_ _[x]_

 _P_ 0 _|_ 0 = diag( _P_ _x_ ˆ 0 _|_ 0 _,q_ _, P_ 0 _|_ 0 _,−_ ) _∈_



0 _|_ 0 _,q_ _[,]_ 0 _|_ 0 _,−_ (28)

_P_ 0 _|_ 0 = diag( _P_ _x_ ˆ 0 _|_ 0 _,q_ _, P_ 0 _|_ 0 _,−_ ) _∈_ R [(] _[m]_ _[x]_ _[−]_ [1)] _[×]_ [(] _[m]_ _[x]_ _[−]_ [1)]



where _P_ 0 _|_ 0 _,q_ _∈_ R [3] _[×]_ [3] and _P_ 0 _|_ 0 _,−_ _∈_ R [(] _[m]_ _[x]_ _[−]_ [4)] _[×]_ [(] _[m]_ _[x]_ _[−]_ [4)] .
_Step 2. Particle initialization:_ Given the initial covariance
and state estimates in (28), _m_ _p_ particles are conventionally
drawn as:


_X_ 0 [(] _[i]_ [)] _∼N_ (ˆ _x_ 0 _|_ 0 _, P_ 0 _|_ 0 ) _,_ _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_ (29)


However, the dimensions of ˆ _x_ 0 _|_ 0, and _P_ 0 _|_ 0 are not compatible
(see (28)). Define the following functions _x_ _[q]_ [2] _[r]_ ( _._ ) : R _[m]_ _[x]_ _→_
R _[m]_ _[x]_ _[−]_ [1] and _x_ _[r]_ [2] _[q]_ ( _._ ) : R _[m]_ _[x]_ _[−]_ [1] _→_ R _[m]_ _[x]_ such that



= _r_ _q_ ( _x_ _q_ ) _∈_ R _[m]_ _[x]_ _[−]_ [1] (30)
_x_ _−_
� � �

= _q_ _r_ ( _x_ _r_ ) _∈_ R _[m]_ _[x]_ (31)
_x_ _−_
� � �



_x_ _q_
_x_ _[q]_ [2] _[r]_
_x_ _−_
��


_x_ _r_
_x_ _[r]_ [2] _[q]_
_x_ _−_
��



_x_ _r_
=

_x_ _−_
�� �


= _x_ _q_

_x_ _−_
�� �



where _x_ _q_ _∈_ S [3], _x_ _r_ _∈_ R [3], and _x_ _−_ _∈_ R _[m]_ _[x]_ _[−]_ [4] . Hence, the
expression in (29) is re-described as follows:

_X_ ˜ 0 [(] _[i]_ [)] _∼N_ � _x_ _[q]_ [2] _[r]_ (ˆ _x_ 0 _|_ 0 ) _, P_ 0 _|_ 0 � _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_

(32)

� _X_ 0 [(] _[i]_ [)] = _x_ _[r]_ [2] _[q]_ ( _X_ [˜] 0 [(] _[i]_ [)] [)] _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_

















where _x_ _q_ _∈_ S [3], _x_ _r_ _∈_ R [3], and _x_ _−_ _∈_ R _[m]_ _[x]_ _[−]_ [4] . Hence, the
expression in (29) is re-described as follows:

_X_ ˜ 0 [(] _[i]_ [)] _∼N_ � _x_ _[q]_ [2] _[r]_ (ˆ _x_ 0 _|_ 0 ) _, P_ 0 _|_ 0 � _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_

(32)

� _X_ 0 [(] _[i]_ [)] = _x_ _[r]_ [2] _[q]_ ( _X_ [˜] 0 [(] _[i]_ [)] [)] _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_


where _X_ [˜] 0 [(] _[i]_ [)] _∈_ R _[m]_ _[x]_ _[−]_ [1] and _X_ 0 [(] _[i]_ [)] _∈_ R _[m]_ _[x]_ . The weights _w_ 0 [(] _[i]_ [)] corresponding to each particle are initialized as _m_ 1 _p_ [, representing]

equal confidence in all particles. The sigma points mean ˆ _x_ [(] 0 _[i]_ _|_ [)] 0
and covariance _P_ 0 [(] _|_ _[i]_ 0 [)] [of each particle are then initialized as:]


ˆ

 _x_ [(] 0 _[i]_ _|_ [)] 0 [=] _[ X]_ [ (] 0 _[i]_ [)] _[,]_ _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_

(33)

 [(] _[i]_ [)]



ˆ
_x_ [(] 0 _[i]_ _|_ [)] 0 [=] _[ X]_ [ (] 0 _[i]_ [)] _[,]_ _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_









(33)
_P_ 0 [(] _|_ _[i]_ 0 [)] [=] _[ P]_ [0] _[|]_ [0] _[,]_ _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_





No















Fig. 1: Illustrative diagram of QUPF-VIN implementation
algorithm.



_B. Prediction_


_Step 3. Augmentation:_ For every _i_ = _{_ 1 _,_ 2 _, . . ., m_ _p_ _}_, the
mean and covariance estimates are augmented to capture nonadditive noise such that:


_⊤_

_x_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 [=] � _x_ ˆ [(] _k_ _[i]_ _−_ [)] _[⊤]_ 1 _|k−_ 1 _[,]_ [ 0] _m_ _[⊤]_ _nx_ _×_ 1 � _∈_ R _[m]_ _[a]_ (34)

_P_ _k_ [(] _−_ _[i]_ [)] _[a]_ 1 _|k−_ 1 [=][ diag][(] _[P]_ [ (] _k−_ _[i]_ [)] 1 _|k−_ 1 _[, C]_ _[x,k]_ [)] _[ ∈]_ [R] [(] _[m]_ _[a]_ _[−]_ [1)] _[×]_ [(] _[m]_ _[a]_ _[−]_ [1)] [ (35)]

where ˆ _x_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 [and] _[ P]_ [ (] _k−_ _[i]_ [)] _[a]_ 1 _|k−_ 1 [represent the augmented ex-]
pected value and covariance matrix of each particle, respectively. The matrix _C_ _x,k_ representing the covariance matrix of
_n_ _x_ is defined by:


_C_ _x,k_ = diag( _C_ _ω,k_ _, C_ _a,k_ ) _∈_ R _[m]_ _[nx]_ _[×][m]_ _[nx]_ (36)


5



_Step 4. Sigma Point Calculations:_ Consider _δx_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j_ [:=]
� ~~�~~ ( _m_ _a_ _−_ 1 + _λ_ ) _P_ _k_ [(] _−_ _[i]_ [)] _[a]_ 1 _|k−_ 1 � _j_ _∈_ R _[m]_ _[a]_ _[−]_ [1] with _λ ∈_ R being a

tuning parameter. It is possible to divide ˆ _x_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 [and] _[ δ][x]_ [ˆ] _k_ [(] _[i]_ _−_ [)] _[a]_ 1 _,j_
into their attitude and non-attitude parts ˆ _x_ _k−_ 1 _|k−_ 1 _,q_ _∈_ S [3],
_δx_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j,r_ _[∈]_ [R] [3] [, and][ ˆ] _[x]_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,−_ _[∈]_ [R] _[m]_ _[a]_ _[−]_ [4] [,] _[ δ][x]_ [ˆ] [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j,−_ _[∈]_
R _[m]_ _[a]_ _[−]_ [4], as outlined below:
 _x_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 [=] �(ˆ _x_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,q_ [)] _[⊤]_ _[,]_ [ (ˆ] _[x]_ _k_ [(] _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,−_ [)] _[⊤]_ [�] _[⊤]_

(37)



_[⊤]_



Considering (11), the subtraction in (43) is obtained by:



�



_∈_ R _[m]_ _[a]_ _[−]_ [1] with _λ ∈_ R being a

_j_



( _m_ _a_ _−_ 1 + _λ_ ) _P_ _k_ [(] _−_ _[i]_ [)] _[a]_ 1 _|k−_ 1



_∈_ R _[m]_ _[x]_ _[−]_ [1]


(45)



_X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j_ _[⊖]_ _[x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 [=]



_X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j,q_ _[⊖]_ _[x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,q_
� _X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j,−_ _[−]_ _[x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,−_



�



_x_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 [=] �(ˆ _x_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,q_ [)] _[⊤]_ _[,]_ [ (ˆ] _[x]_ _k_ [(] _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,−_ [)] _[⊤]_ [�] _[⊤]_



_λ_
_w_ 0 _[m]_ [=]
_λ_ + ( _m_ _a_ _−_ 1) _[∈]_ [R]



Note that the weights _w_ _j_ _[m]_ and _w_ _j_ _[c]_ [in (][42][) and (][43][) are found]
by:
 _ww_ 0 _[m]_ 0 _[c]_ [=][=] _λ_ + ( _mλλ_ _a_ _−_ 1) _[∈]_ [R]
 _λ_ + ( _m_ _a_ _−_ 1) [+ 1] _[ −]_ _[α]_ [2] [ +] _[ β][ ∈]_ [R] (46)



1
_w_ _j_ _[m]_ [=] _[ w]_ _j_ _[c]_ [=] 2(( _m_ _a_ _−_ 1) + _λ_ ) _[∈]_ [R]



_λ_
_w_ 0 _[c]_ [=]
_λ_ + ( _m_ _a_ _−_ 1) [+ 1] _[ −]_ _[α]_ [2] [ +] _[ β][ ∈]_ [R]







(37)
_δx_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j_ [=] �( _δx_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j,r_ [)] _[⊤]_ _[,]_ [ (] _[δ][x]_ [ˆ] [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j,−_ [)] _[⊤]_ [�] _[⊤]_



(46)



In the light of (12), (13), and (37), the sigma points of the _i_ th
UKF of QUPF-VIN are found by:
 _XX_ _kk_ [(][(] _−_ _[i]_ _−_ _[i]_ [)][)] _[a]_ 1 _[a]_ 1 _||kk−−_ 11 _,,j_ 0 [= ˆ][= ˆ] = _[x][x]_ � [(] _k_ [(] _k_ _x_ ˆ _x_ ˆ _[i][i]_ _−−_ [(] _k_ [)][)][(] _k_ _[i][a][a]_ _−_ 11 _[i]_ [)] _−_ [)] _||_ _[a]_ 1 _kk_ _[a]_ 1 _|−−|kk−_ 11 _−_ 1 _[⊕][∈]_ 1 _,,q−_ [R] _[δ][⊕]_ [+] _[x]_ [ˆ] _[m]_ [(] _j_ _[ δ]_ _[i]_ _[a]_ _[δ]_ [)] _[x][x]_ _[a]_ [ˆ][ˆ] _k_ [(][(] _k_ _[i][i]_ _−−_ [)][)] _[a][a]_ 11 _,j,r,j,−_ � _∈_ R _[m]_ _[a]_

[(] _[i]_ [)] _[a]_ [(] _[i]_ [)] _[a]_ [ˆ] [(] _[i]_ [)] _[a]_







_X_ _k_ [(] _−_ _[i]_ [)] _[a]_ 1 _|k−_ 1 _,_ 0 [= ˆ] _[x]_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _[∈]_ [R] _[m]_ _[a]_



_j_ = _{_ 1 _, . . .,_ 2( _m_ _a_ _−_ 1) _}_



_X_ _k_ [(] _−_ _[i]_ [)] _[a]_ 1 _|k−_ 1 _,j_ [= ˆ] _[x]_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _[⊕]_ _[δ][x]_ [ˆ] [(] _j_ _[i]_ [)] _[a]_



=



_x_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,q_ _[⊕]_ _[δ][x]_ [ˆ] _k_ [(] _[i]_ _−_ [)] _[a]_ 1 _,j,r_
� _x_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,−_ [+] _[ δ][x]_ [ˆ] [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j,−_



�



_∈_ R _[m]_ _[a]_



_X_ _k_ [(] _−_ _[i]_ [)] _[a]_ 1 _|k−_ 1 _,j_ + _m_ _a_ [= ˆ] _[x]_ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _[⊖]_ _[δ][x]_ [ˆ] [(] _j_ _[i]_ [)] _[a]_







=



_x_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,q_ _[⊖]_ _[δ][x]_ [ˆ] [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j,r_
� _x_ ˆ [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _|k−_ 1 _,−_ _[−]_ _[δ][x]_ [ˆ] [(] _k_ _[i]_ _−_ [)] _[a]_ 1 _,j,−_



�



_∈_ R _[m]_ _[a]_ _,_



 _j_ = _{_ 1 _,_ 2 _, . . .,_ 2( _m_ _a_ _−_ 1) _}_

(38)
_Step 5. Propagation:_ Given IMU measurements, each sigma
point for each UKF is propagated through the state transition
function (23) to find predicted sigma points _X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j_ [. This can]
be shown as:

_X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j_ [= f(] _[X]_ [ (] _k−_ _[i]_ [)] _[a]_ 1 _|k−_ 1 _,j_ _[, u]_ _[k][−]_ [1] [)] _[ ∈]_ [R] _[m]_ _[x]_ (39)

Using the propagated sigma points, the mean ˆ _x_ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [and]

covariance matrix _P_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 [for each UKF should be computed.]
Consider:



with _α, β ∈_ R being tuning parameters.


_C. Update_


_Step 6. Predict Measurement:_ Every sigma point is passed
through the measurement function (26) to predict the measurement vector. The measurement sigma points _Z_ _k_ [(] _[i]_ _|_ [)] _k−_ 1 _,j_ [are]
obtained as follows:


_Z_ _k_ [(] _[i]_ _|_ [)] _k−_ 1 _,j_ [=] _[ h]_ [(] _[X]_ [ (] _k|_ _[i]_ _k_ [)] _−_ 1 _,j_ _[, f]_ _[w]_ [)] _[ ∈]_ [R] _[m]_ _[z]_ (47)


The covariance matrices _P_ _z_ [(] _k_ _[i]_ [)] _,z_ _k_ _[∈]_ [R] _[m]_ _[z]_ _[×][m]_ _[z]_ [ and] _[ P]_ _x_ [ (] _[i]_ _k_ [)] _,z_ _k_ _[∈]_
R [(] _[m]_ _[x]_ _[−]_ [1)] _[×][m]_ _[z]_ and the mean estimated measurement vector
_z_ ˆ _k_ [(] _[i]_ _|_ [)] _k−_ 1 _[∈]_ [R] _[m]_ _[z]_ [ for each UKF are found by:]



2( _m_ _a_ _−_ 1)

_z_ ˆ _k_ [(] _[i]_ _|_ [)] _k−_ 1 [=] � _w_ _j_ _[m]_ _[Z]_ _k_ [(] _[i]_ _|_ [)] _k−_ 1 _,j_ (48)

_j_ =0


2( _m_ _a_ _−_ 1)

_P_ _z_ [(] _k_ _[i]_ [)] _,z_ _k_ [=] � _w_ _j_ _[c]_ [[] _[Z]_ _k_ [(] _[i]_ _|_ [)] _k−_ 1 _,j_ _[−]_ _[z]_ [ˆ] _k_ [(] _[i]_ _|_ [)] _k−_ 1 [][] _[Z]_ _k_ [(] _[i]_ _|_ [)] _k−_ 1 _,j_ _[−]_ _[z]_ [ˆ] _k_ [(] _[i]_ _|_ [)] _k−_ 1 []] _[⊤]_

_j_ =0


+ _C_ _f_ (49)


2( _m_ _a_ _−_ 1)

_P_ _x_ [(] _[i]_ _k_ [)] _,z_ _k_ [=] � _w_ _j_ _[c]_ [[] _[X]_ [ (] _k|_ _[i]_ _k_ [)] _−_ 1 _,j_ _[⊖]_ _[x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 [][] _[Z]_ _k_ [(] _[i]_ _|_ [)] _k−_ 1 _,j_ _[−]_ _[z]_ [ˆ] _k_ [(] _[i]_ _|_ [)] _k−_ 1 []] _[⊤]_

_j_ =0

(50)



_x_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [=] � _x_ ˆ [(] _k_ _[i]_ _|_ [)] _k_ _[⊤]_ _−_



ˆ

[(] _k_ _[i]_ _|_ [)] _k_ _[⊤]_ _−_ 1 _,q_ _x_ [(] _k_ _[i]_ _|_ [)] _k_ _[⊤]_



_k|k−_ 1 _,−_



_X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j_ [=] � _X_ _k_ [(] _|_ _[i]_ _k_ [)] _[⊤]_



_k_ [(] _|_ _[i]_ _k_ [)] _[⊤]_ _−_ 1 _,q_ _X_ _k_ [(] _|_ _[i]_ _k_ [)] _[⊤]_



_⊤_
_∈_ R _[m]_ _[x]_ (40)
�


_⊤_
_∈_ R _[m]_ _[x]_ (41)
�



_k|k−_ 1 _,−_



where ˆ _x_ [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,q_ _[,][ X]_ [ (] _k|_ _[i]_ _k_ [)] _−_ 1 _,q_ _[∈]_ [S] [3] [, and][ ˆ] _[x]_ [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,−_ _[,][ X]_ [ (] _k|_ _[i]_ _k_ [)] _−_ 1 _,−_ _[∈]_
R _[m]_ _[x]_ _[−]_ [4] . Thereby, one has



QWA( _{X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j,q_ _[}][,][ {][w]_ _j_ _[m]_ _[}]_ [)]







 _∈_ R _m_ _x_ (42)



_x_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [=]









2( _m_ _a_ _−_ 1)
� _w_ _j_ _[m]_ _[X]_ [ (] _k|_ _[i]_ _k_ [)] _−_ 1 _,j,−_

_j_ =0



The _⊖_ operator in (50) follows the map in (45). The Kalman
gains _K_ _k_ [(] _[i]_ [)] [, estimation covariance matrices] _[ P]_ [ (] _k|_ _[i]_ _k_ [)] [and correction]

vectors _δx_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [are defined by:]

_K_ _k_ [(] _[i]_ [)] = _P_ _x_ [(] _[i]_ _k_ [)] _,z_ _k_ _[P]_ [ (] _z_ _k_ _[i]_ [)] _,z_ _[⊤]_ _k_ _[∈]_ [R] [(] _[m]_ _[x]_ _[−]_ [1)] _[×][m]_ _[z]_ (51)

_P_ _k_ [(] _|_ _[i]_ _k_ [)] [=] _[ P]_ [ (] _k|_ _[i]_ _k_ [)] _−_ 1 _[−]_ _[K]_ _k_ [(] _[i]_ [)] _[P]_ _z_ [ (] _k_ _[i]_ [)] _,z_ _k_ _[K]_ _k_ [(] _[i]_ [)] _[⊤]_ _∈_ R [(] _[m]_ _[x]_ _[−]_ [1)] _[×]_ [(] _[m]_ _[x]_ _[−]_ [1)]

(52)

_δx_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [: =] _[ K]_ _k_ [(] _[i]_ [)] [(] _[z]_ _[k]_ _[ −]_ _[z]_ [ˆ] _k_ [(] _[i]_ _|_ [)] _k−_ 1 [)] _[ ∈]_ [R] _[m]_ _[x]_ _[−]_ [1] (53)

Let us divide _δx_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [into its attitude (] _[δ][x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,r_ _[∈]_ [R] [3] [) and]

non-attitude ( _δx_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,−_ _[∈]_ [R] _[m]_ _[x]_ _[−]_ [4] [) components:]



_P_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 [=]


where



2( _m_ _a_ _−_ 1) _⊤_
� _w_ _j_ _[c]_ � _X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j_ _[⊖]_ _[x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 �� _X_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 _,j_ _[⊖]_ _[x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 �

_j_ =0

+ _C_ _w,k_ _∈_ R [(] _[m]_ _[x]_ _[−]_ [1)] _[×]_ [(] _[m]_ _[x]_ _[−]_ [1)] (43)



_⊤_
(54)
�



 _∈_ R [(] _[m]_ _[n]_ _w_ _[−]_ [1)] _[×]_ [(] _[m]_ _[n]_ _w_ _[−]_ [1)]

(44)



Then, the estimated state vector for each UKF ˆ _x_ _k_ [(] _[i]_ _|_ [)] _k_ [is defined]
by:
_x_ ˆ [(] _k_ _[i]_ _|_ [)] _k_ [= ˆ] _[x]_ [(] _k_ _[i]_ _|_ [)] _k−_ 1 _[⊕]_ _[δ][x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 (55)



_δx_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [=] � _δx_ ˆ [(] _k_ _[i]_ _|_ [)] _k_ _[⊤]_



ˆ

[(] _k_ _[i]_ _|_ [)] _k_ _[⊤]_ _−_ 1 _,r_ _δx_ [(] _k_ _[i]_ _|_ [)] _k_ _[⊤]_



_k|k−_ 1 _,−_



_C_ _w,k_ =



0 9 _×_ 9 0 3 _×_ 3 0 3 _×_ 3

0 9 _×_ 9 _C_ _bω,k_ 0 3 _×_ 3

0 9 _×_ 9 0 3 _×_ 3 _C_ _ba,k_


where


_x_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 _[⊕]_ _[δ][x]_ [ˆ] _k_ [(] _[i]_ _|_ [)] _k−_ 1 [=]



_x_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,q_ _[⊕]_ _[δ][x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,r_
� _x_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,−_ [+] _[ δ][x]_ [ˆ] [(] _k_ _[i]_ _|_ [)] _k−_ 1 _,−_



�



(56)



6


_Step 9. Particles weighted average:_ The weighted average
of the particles will be the estimated state vector at the current
time step. Let us divide each particle into its quaternion _X_ _k,q_ _∈_
S [3] and non-quaternion _X_ _k,−_ components. Hence, the estimated
state vector ˆ _x_ _k|k_ is defined by:



_Step 7. Particle and Weight calculations:_ Using the estimated vector ˆ _x_ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [and covariance matrix] _[ P]_ [ (] _k|_ _[i]_ _k_ [)] [as the mean]
and covariance matrix of a Gaussian distribution, the particles
_X_ _k_ [(] _[i]_ [)] are drawn similar to (32):

 _X_ ˜ _k_ [(] _[i]_ [)] _∼N_ � _x_ _[q]_ [2] _[r]_ [ �] _x_ ˆ _k_ [(] _[i]_ _|_ [)] _k−_ 1 � _, P_ _k_ [(] _|_ _[i]_ _k_ [)] �

(57)

 [(] _[i]_ [)] [2] [˜] [(] _[i]_ [)]



QWA �� _X_ _k,q_ [(] _[i]_ [)] � _,_ � _w_ _k_ [(] _[i]_ [)] ��







 _∈_ R _m_ _x_ (63)



_x_ ˆ _k|k_ =









_m_ _p_
� _w_ _k_ [(] _[i]_ [)] _[X]_ [ (] _k,_ _[i]_ _−_ [)]


_i_ =0



_X_ ˜ _k_ [(] _[i]_ [)] _∼N_ � _x_ _[q]_ [2] _[r]_ [ �] _x_ ˆ _k_ [(] _[i]_ _|_ [)] _k−_ 1 � _, P_ _k_ [(] _|_ _[i]_ _k_ [)] �



(57)
_X_ _k_ [(] _[i]_ [)] = _x_ _[r]_ [2] _[q]_ ( _X_ [˜] _k_ [(] _[i]_ [)] [)]







The weights _w_ _k_ [(] _[i]_ [)] corresponding to each particle at the current
time-step represent how accurate each particle is and they are
defined by:

_w_ ˜ _k_ [(] _[i]_ [)] = P � _z_ _k_ _|X_ _k_ [(] _[i]_ [)] � P � _X_ _k_ [(] _[i]_ [)] _[|X]_ [ (] _k−_ _[i]_ [)] 1 � + _ϵ_ (58)

P _X_ _k_ [(] _[i]_ [)] _[|][z]_ [1:] _[k]_ + _ϵ_
~~�~~ ~~�~~



_ϵ_ is added to avoid numerical instabilities for the case of zero
weight and division by zero. The probability terms in (58) are
calculated by:

P � _z_ _k_ _|X_ _k_ [(] _[i]_ [)] � = _N_ � _z_ _k_ _|_ h � _X_ _k_ [(] _[i]_ [)] � _, C_ _f_ �
P � _X_ _k_ [(] _[i]_ [)] _[|X]_ _k_ [ (] _−_ _[i]_ [)] 1 � = _N_ � _x_ _[q]_ [2] _[r]_ [ �] _X_ _k_ [(] _[i]_ [)] � _|x_ _[q]_ [2] _[r]_ [ �] _x_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 � _, P_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 �



P _z_ _k_ _|X_ _k_ [(] _[i]_ [)] = _N_ _z_ _k_ _|_ h _X_ _k_ [(] _[i]_ [)] _, C_ _f_
� � � � � �



P � _X_ _k_ [(] _[i]_ [)] _[|X]_ _k_ [ (] _−_ _[i]_ [)] 1 � = _N_ � _x_ _[q]_ [2] _[r]_ [ �] _X_ _k_ [(] _[i]_ [)] � _|x_ _[q]_ [2] _[r]_ [ �] _x_ ˆ [(] _k_ _[i]_ _|_ [)] _k−_ 1 � _, P_ _k_ [(] _|_ _[i]_ _k_ [)] _−_ 1 �







P � _X_ _k_ [(] _[i]_ [)] _[|][z]_ [1:] _[k]_ � = _N_ � _x_ _[q]_ [2] _[r]_ [ �] _X_ _k_ [(] _[i]_ [)] � _|x_ _[q]_ [2] _[r]_ [ �] _x_ ˆ [(] _k_ _[i]_ _|_ [)] _k_ � _, P_ _k_ [(] _|_ _[i]_ _k_ [)] �



(59)
Next, the weights are normalized as follows:



_w_ _k_ [(] _[i]_ [)] = _m_ _w_ _p_ ˜ _k_ [(] _[i]_ [)]
� _w_ ˜ _k_ [(] _[i]_ [)]


_i_ =1



(60)



The particles will also be set as the expected value of the
UKFs’ estimated state vectors which will be used in the next

iteration at 34. In other words:


_x_ [(] _k_ _[i]_ _|_ [)] _k_ [=] _[ X]_ [ (] _k_ _[i]_ [)]


_Step 10. Iterate:_ Go back to Step 2 and iterate with _k →_
_k_ + 1.


V. N UMERICAL R ESULTS


Fig. 2: A sample of matched landmark data points from left
to right frame of EuRoC dataset [21].


This section evaluates the effectiveness and robustness of

the proposed QUPF-VIN algorithm using a real-world dataset
from a quadrotor flight in 3D space, specifically the EuRoC
dataset [21]. The test platform is the Asctec Firefly hexrotor Micro Aerial Vehicle (MAV), operating in a GPSdenied indoor environment. Ground truth data, including true
position and orientation (quaternion), were collected using an
OptiTrack localization system. The measurements consist of
6-axis IMU data (linear acceleration and angular velocity)
and stereo images. The stereo images, captured at 20 Hz,
were obtained from an Aptina MT9V034 global shutter sensor,
while the IMU data, including linear acceleration and angular
velocity, were collected at 200 Hz using an ADIS16448 sensor.
Due to the difference in sampling rates between the IMU
and the camera, landmark measurements are not available for
every IMU data point. To address this challenge, the proposed
algorithm updates the state when image data is available.
Otherwise, the particles _X_ _k_ [(] _[i]_ [)] are set to the predicted state
vector ˆ _x_ [(] _k_ _[i]_ _|_ [)] _k−_ 1 [while image data is unavailable.]
For every set of stereo images, the landmark points are
defined via the Kanade-Lucas-Tomasi (KLT) approach [22].
As illustrative example, the landmark matching between two
instantaneous frame is presented in Fig. 2. The mapping



_Step 8. Resampling:_ To address the degeneracy challenging
problem of particle filters, resampling is performed once
the effective number of samples _m_ _eff_ _∈_ R falls below a
predefined threshold _m_ _thr_ _∈_ R [20]. The effective number
of samples is calculated by:


1
_m_ _eff_ = 2 (61)
~~�~~ ~~[�]~~ _w_ _k_ [(] _[i]_ [)]
~~�~~


The particles are then resampled if _m_ _eff_ is lower than a certain
threshold _m_ _thr_ . Consider the set � _X_ _k_ [(] _[i]_ [)] _[, P]_ _k_ [ (] _|_ _[i]_ _k_ [)] � as instances of

a random variable, associated with the probability set _{w_ _k_ [(] _[i]_ [)] _[}]_ [.]
During the resampling step, _m_ _p_ samples are drawn from
� _X_ _k_ [(] _[i]_ [)] _[, P]_ _k_ [ (] _|_ _[i]_ _k_ [)] � according to their corresponding probabilities.
Note that a single particle may be sampled multiple times.
After resampling, the weights are updated to reflect a uniform
distribution, as the distribution is now represented by the
number of particles rather than their individual weights. The
resampling process is formally expressed as:

�� _X_ _k_ [(] _[i]_ [)] _[, P]_ _k_ [ (] _|_ _[i]_ _k_ [)] � _, {w_ _k_ [(] _[i]_ [)] _[}]_ � _←_ Resample �� _X_ _k_ [(] _[i]_ [)] _[, P]_ [ (] _k|_ _[i]_ _k_ [)] � _, {w_ _k_ [(] _[i]_ [)] �)
(62)


7



1.5


1


0.5


0 20 40 60 80


4


3.5


3


2.5


2


1.5


1


0.5


0 20 40 60 80


5


4


3


2


1


0

0 20 40 60 80

Time [s]



2.2


2


1.8


1.6


1.4


1.2


1


0.8


4





**Dataset Trajectory**


2









-2 -2.5 -2 X (m)





X (m)



Fig. 3: Performance assessment using the EuRoC V1 02 medium dataset [21]. The left side shows UAV navigation (estimation)
trajectory 3D space where the position is depicted in black solid line while the orientation is represented by red, green, and
blue dashed lines. The right side presents normalized values of error vectors: orientation error _∥r_ _e,k_ _∥_, position error _∥p_ _e,k_ _∥_,
and linear velocity error _∥v_ _e,k_ _∥_ in blue solid lines.


associated with the subtraction operator provided in (11) is
used to define the orientation estimation error _r_ _e,k_ such that:


_r_ _e,k_ = _q_ _k_ _⊖_ _q_ ˆ _k_ (64)

with _r_ _e,k_ = � _r_ _e_ 1 _,k_ _r_ _e_ 2 _,k_ _r_ _e_ 3 _,k_ � _⊤_ _∈_ R 3 . Consider expressing the estimation errors of position and linear velocity at the
_k_ th sample step as follows:

_p_ _e,k_ = _p_ _k_ _−_ _p_ ˆ _k_ = � _p_ _e_ 1 _,k_ _p_ _e_ 2 _,k_ _p_ _e_ 3 _,k_ � _⊤_ _∈_ R 3 (65)

_v_ _e,k_ = _v_ _k_ _−_ _v_ ˆ _k_ = � _v_ _e_ 1 _,k_ _v_ _e_ 2 _,k_ _v_ _e_ 3 _,k_ � _⊤_ _∈_ R 3 (66)



Fig. 4: Estimation error: Rotation (left portion), position
(middle portion), and linear velocity (rightp protion).


triangulation approach in [19] were utilized to project the 2D
matched points into the 3D space, describing the landmark
pointThe filter was also compared to the EKF, which is a
commonly adopted base filter in this domain. To ensure a fair
comparison, both filters were initialized with the same values
and parameters. In Fig. 5 the magnitude of orientation (top),
position (middle), and velocity (bottom) estimation errors are
plotted against time. The EKF results are represented by solid
red lines, while the QUPF-VIN results are depicted by dashed
blue lines. As shown in Fig. 5, the proposed filter outperformed
the EKF in terms of accuracy and speed, specifically in reducing the magnitudes of orientation, position, and linear velocity
estimation errors.s in _{W}_ . The mapping S [3] _×_ S [3] _→_ R [3]



Fig. 3 presents the performance of QUPF-VIN using the
EuRoC V1 02 medium room dataset [21]. The left portion
of Fig. 3 shows the drone’s estimated position trajectory and
orientation during the navigation experiment with 6 DoF.
The right portion of Fig. 3 reveals the estimation errors for
orientation, position, and linear velocity. As illustrated in Fig.
3, the proposed algorithm exhibits rapid error convergence
to near-zero values, even when initialized with large errors,
confirming the robustness and reliability of the QUPF-VIN
algorithm. This confirms the robustness and reliability of the
proposed QUPF-VIN algorithm. To further evaluate the filter’s
performance, Fig. 4 plots each component of the orientation,
position, and linear velocity estimation errors over time,
demonstrating consistent convergence across all dimensions.
Additionally, the filter was compared to the EKF, a widely
used baseline in this field. For a fair comparison, both filters
were initialized with identical values and parameters. In Fig. 5,
the magnitudes of the orientation (top), position (middle), and
velocity (bottom) estimation errors are plotted against time,


with EKF results represented by solid red lines and QUPFVIN results by dashed blue lines. As shown in Fig. 5, the
proposed filter outperforms the EKF in both accuracy and
speed, significantly reducing the magnitude of the orientation,
position, and linear velocity estimation errors.



3


2


1





0

|Col1|Col2|Col3|Col4|Col5|Col6|Col7|EKF<br>QUPF-VIN|
|---|---|---|---|---|---|---|---|
|||||||||
|||||||||
|||||||||



0 10 20 30 40 50 60 70 80



8


[5] H. A. Hashim, “Gps-denied navigation: Attitude, position, linear velocity, and gravity estimation with nonlinear stochastic observer,” in _2021_
_American Control Conference (ACC)_ . IEEE, 2021, pp. 1149–1154.

[6] H. A. Hashim, L. J. Brown, and K. McIsaac, “Nonlinear stochastic
attitude filters on the special orthogonal group 3: Ito and stratonovich,”
_IEEE Transactions on Systems, Man, and Cybernetics: Systems_, vol. 49,
no. 9, pp. 1853–1865, 2018.

[7] H. A. Hashim and F. L. Lewis, “Nonlinear stochastic estimators on
the special euclidean group se (3) using uncertain imu and vision
measurements,” _IEEE Transactions on Systems, Man, and Cybernetics:_
_Systems_, vol. 51, no. 12, pp. 7587–7600, 2020.

[8] J. F. Vasconcelos, B. Cardeira, C. Silvestre, P. Oliveira, and P. Batista,
“Discrete-time complementary filters for attitude and position estimation: Design, analysis and experimental validation,” _IEEE Transactions_
_on Control Systems Technology_, vol. 19, no. 1, pp. 181–198, 2010.

[9] A. Fornasier, Y. Ng, R. Mahony, and S. Weiss, “Equivariant filter design
for inertial navigation systems with input measurement biases,” in _2022_
_International Conference on Robotics and Automation (ICRA)_ . IEEE,
2022, pp. 4333–4339.

[10] H. A. Hashim, A. E. Eltoukhy, and K. G. Vamvoudakis, “Uwb ranging
and imu data fusion: Overview and nonlinear stochastic filter for inertial
navigation,” _IEEE Transactions on Intelligent Transportation Systems_,
2023.

[11] J. Ali and M. Ushaq, “A consistent and robust kalman filter design for inmotion alignment of inertial navigation system,” _Measurement_, vol. 42,
no. 4, pp. 577–582, 2009.

[12] K. Sun and et al., “Robust stereo visual inertial odometry for fast
autonomous flight,” _IEEE Robotics and Automation Letters_, vol. 3, no. 2,
pp. 965–972, 2018.

[13] T. Cantelobre, C. Chahbazian, A. Croux, and S. Bonnabel, “A real-time
unscented kalman filter on manifolds for challenging auv navigation,”
in _2020 IEEE/RSJ International Conference on Intelligent Robots and_
_Systems (IROS)_ . IEEE, 2020, pp. 2309–2316.

[14] K. Hong, S. Kim, J. Park, and H. Bang, “Particle filter approach to
vision-based navigation with aerial image segmentation,” _Journal of_
_Aerospace Information Systems_, vol. 18, no. 12, pp. 964–972, 2021.

[15] R. Van Der Merwe, A. Doucet, N. De Freitas, and E. Wan, “The
unscented particle filter,” _Advances in neural information processing_
_systems_, vol. 13, 2000.

[16] H. A. Hashim, “Special orthogonal group SO(3), euler angles, angleaxis, rodriguez vector and unit-quaternion: Overview, mapping and
challenges,” _arXiv preprint arXiv:1909.06669_, 2019.

[17] H. A. Hashim, A. E. Eltoukhy, K. G. Vamvoudakis, and M. I. Abouheaf,
“Nonlinear deterministic observer for inertial navigation using ultrawideband and IMU sensor fusion,” in _2023 IEEE/RSJ International_
_Conference on Intelligent Robots and Systems (IROS)_ . IEEE, 2023,
pp. 3085–3090.

[18] H. A. Hashim, “Exponentially stable observer-based controller for vtoluavs without velocity measurements,” _International Journal of Control_,
vol. 96, no. 8, pp. 1946–1960, 2023.

[19] R. Hartley and A. Zisserman, _Multiple view geometry in computer vision_ .
Cambridge university press, 2003.

[20] X. Fu and Y. Jia, “An improvement on resampling algorithm of particle
filters,” _IEEE Transactions on Signal Processing_, vol. 58, no. 10, pp.
5414–5420, 2010.

[21] M. Burri, J. Nikolic, P. Gohl, T. Schneider, J. Rehder, S. Omari, M. W.
Achtelik, and R. Siegwart, “The EuRoC micro aerial vehicle datasets,”
_The International Journal of Robotics Research_, vol. 35, no. 10, pp.
1157–1163, 2016.

[22] J. Shi and Tomasi, “Good features to track,” in _1994 Proceedings of_
_IEEE Conference on Computer Vision and Pattern Recognition_, 1994,
pp. 593–600.



4


2


0




|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|EKF<br>QUPF-VIN|
|---|---|---|---|---|---|---|---|---|
||||||||||
||||||||||
||||||||||



0 10 20 30 40 50 60 70 80



10





5


0

|Col1|Col2|Col3|Col4|Col5|Col6|Col7|EKF|
|---|---|---|---|---|---|---|---|
||||||||QUPF-VIN|
|||||||||
|||||||||
|||||||||



0 10 20 30 40 50 60 70 80

Time [s]


Fig. 5: Comparison results of EKF (literature in red) and the
proposed QUPF-VIN (in blue).


VI. C ONCLUSION

This article investigated the navigation problem of a vehicle
operating with six degrees of freedom. A novel geometric
Quaternion-based Unscented Particle Filter for Visual-Inertial
Navigation (QUPF-VIN) has been developed to estimate the
vehicle’s navigation state (orientation, position, and linear
velocity) while mitigating measurement uncertainties. The
proposed filter effectively addressed kinematic nonlinearities
and ensures computational efficiency, even at low sampling
rates. The proposed algorithm has been structured using unit
quaternions to accurately model true navigation kinematics
and avoid singularities. The algorithm leveraged sensor fusion
from a vision unit (e.g., monocular or stereo camera) and a 6axis IMU. The performance of the QUPF-VIN was evaluated
using a real-world dataset of an indoor drone flight, which
included stereo camera images and IMU data collected at a
low sampling rate. The results demonstrated good navigation
performance, with tracking errors approaching zero. Furthermore, the proposed filter outperformed a baseline EKF in
comparison.


R EFERENCES


[1] H. A. Hashim, “Advances in UAV Avionics Systems Architecture,
Classification and Integration: A Comprehensive Review and Future
Perspectives,” _Results in Engineering_, vol. 25, p. 103786, 2025.

[2] D. P. Koch and et al., “Relative multiplicative extended kalman filter
for observable gps-denied navigation,” _The International Journal of_
_Robotics Research_, vol. 39, no. 9, pp. 1085–1121, 2020.

[3] H. A. Hashim, M. Abouheaf, and M. A. Abido, “Geometric stochastic
filter with guaranteed performance for autonomous navigation based on
imu and feature sensor fusion,” _Control Engineering Practice_, vol. 116,
p. 104926, 2021.

[4] H. A. Hashim, L. J. Brown, and K. McIsaac, “Nonlinear pose filters
on the special euclidean group se (3) with guaranteed transient and
steady-state performance,” _IEEE Transactions on Systems, Man, and_
_Cybernetics: Systems_, vol. 51, no. 5, pp. 2949–2962, 2019.


