## **MoE-Gyro: Self-Supervised Over-Range** **Reconstruction and Denoising for MEMS Gyroscopes**

**Feiyang Pan** [1] _[†]_ **, Shenghe Zheng** [2] _[†]_ **, Chunyan Yin** [1] _[∗]_ **, Guangbin Dou** [1] _[∗]_

1 Southeast University 2 Harbin Institute of Technology

```
                 230238437@seu.edu.cn

```

**Abstract**


MEMS gyroscopes play a critical role in inertial navigation and motion control applications but typically suffer from a fundamental trade-off between measurement
range and noise performance. Existing hardware-based solutions aimed at mitigating this issue introduce additional complexity, cost, and scalability challenges.
Deep-learning methods primarily focus on noise reduction and typically require
precisely aligned ground-truth signals, making them difficult to deploy in practical
scenarios and leaving the fundamental trade-off unresolved. To address these challenges, we introduce **Mixture of Experts for MEMS Gyroscopes (MoE-Gyro)**, a
novel self-supervised framework specifically designed for simultaneous over-range
signal reconstruction and noise suppression. **MoE-Gyro** employs two experts: an
Over    - Range Reconstruction Expert (ORE), featuring a Gaussian-Decay Attention
mechanism for reconstructing saturated segments; and a Denoise Expert (DE),
utilizing dual-branch complementary masking combined with FFT-guided augmentation for robust noise reduction. A lightweight gating module dynamically routes
input segments to the appropriate expert. Furthermore, existing evaluation lack a
comprehensive standard for assessing multi-dimensional signal enhancement. To
bridge this gap, we introduce **IMU Signal Enhancement Benchmark (ISEBench)**,
an open-source benchmarking platform comprising the GyroPeak-100 dataset and
a unified evaluation of IMU signal enhancement methods. We evaluate **MoE-Gyro**
using our proposed **ISEBench**, demonstrating that our framework significantly
extends the measurable range from ±450°/s to ±1500°/s, reduces Bias Instability
by 98.4%, and achieves state-of-the-art performance, effectively addressing the
long-standing trade-off in inertial sensing.


**1** **Introduction**


MEMS gyroscopes are essential inertial sensors extensively utilized in navigation and control systems
such as autonomous vehicles, unmanned aerial vehicles (UAVs), robotics, and precision-guided
munitions[ 1, 2, 3 ]. In these high-dynamic applications, critical performance metrics of gyroscopes
include measurement range (full-scale angular velocity) and noise characteristics, notably Angle
Random Walk (ARW) and Bias Instability (BI). However, commercial MEMS gyroscopes typically
encounter a fundamental performance trade-off: enhancing the measurement range generally results
in elevated ARW and BI, whereas sensors optimized for low noise inherently possess a restricted
angular velocity measurement capability[ 4, 5 ]. This fundamental contradiction significantly limits
their effectiveness in high-angular-rate scenarios requiring precise inertial measurements.


Addressing this critical limitation without incurring additional sensor complexity or manufacturing
costs remains a significant and unresolved challenge in inertial sensor research. Traditional solutions


_∗_ Corresponding Author(yincy@seu.edu.cn; gdou@seu.edu.cn). _†_ Equal Contribution.


Preprint. Under review.


primarily involve structural and circuit-level strategies, such as resonant frequency tuning (modesplitting)[ 6, 7 ], closed-loop force-feedback control[ 8, 9 ], and multi-range readout electronics[ 10 ].
Although these methods deliver incremental gains, they require tighter fabrication tolerances and
more complex control circuitry, increasing both power draw and manufacturing cost [ 11 ]. Thus,
traditional strategies have yet to adequately resolve these critical trade-offs[ 12 ]. Recent advancements
in deep learning have emerged as promising solutions for mitigating noise in gyroscopes and, by
extension, in complete inertial - measurement - unit (IMU) signals (e.g., CNN[ 13 ], LSTM_GRU[ 14 ],
HEROS_GAN[ 15 ]). However, these approaches rely on fully supervised training and thus require
precisely time-synchronized noisy/clean rotation pairs data that are expensive to collect. Meanwhile,
current self-supervised methods (e.g., LIMU-BERT[ 16 ], IMUDB[ 17 ]) lack a unified framework
that handles both denoising and over-range reconstruction, leaving unresolved the core trade-off
that low-noise sensors accept only a limited angular rate range. Moreover, previous work is limited
to a few single-signal test environments, lacking a multidimensional benchmark that captures the
full spectrum of enhancement performance; a public suite spanning diverse operational scenarios is
essential for fair comparison and real progress.


To overcome the limitations above, we introduce **MoE-Gyro**, the first self-supervised unified architecture that tackles both over-range reconstruction and denoising. A lightweight gate dynamically routes
each input signal segment to two specialized experts, an Over-Range Reconstruction Expert (ORE)
and a Over-Range Reconstruction Expert (DE), thus cutting inference memory because, in practice,
only a single expert is active for most segments. Both experts are trained end-to-end on a shared
Masked Autoencoder(MAE) [ 18 ] backbone with purely self-supervised objectives, eliminating the
need for costly, time-synchronised ground-truth labels. We further introduce task-specific more optimisations. For the ORE, a Gaussian-Decay Attention (GD-Attn) module in the decoder automatically
focuses on the most relevant context for peak reconstruction, while a physics-informed energy regulariser (PINN) enforces consistency with the gyroscope’s mechanical model, boosting generalisation
across sensors. For the DE, we adopt a dual-branch complementary cross-mask that captures weak
signal features while smoothing high-frequency noise, and we employ FFT-guided noise injection
during training to strengthen the learned denoising mapping. Together, these innovations deliver a
unified, fully self-supervised solution that simultaneously broadens range and suppresses noise in
commercial MEMS gyroscopes. In addition, we release **ISEBench**, the first open-source benchmark
with a unified suite of evaluation metrics, providing a common benchmark for future research on
IMU signal enhancement. Our key contributions can be summarized as follows:


_•_ Unified self-supervised MoE framework that simultaneously reconstructs over-range signals and
reduces noise, breaking the long-standing range–noise trade-off without extra hardware.


_•_ We propose a Gaussian-Decay Attention (GD-Attn) and a physics-informed neural network (PINN)
loss, extending the measurable range of a typical _±_ 450 °/s MEMS gyroscope to _±_ 1500 °/s.


_•_ We design a dual-branch complementary masking strategy combined with FFT-guided augmentation, significantly reducing Bias Instability on the test set by 98.4% .


_•_ We release **ISEBench**, the first open source benchmark specifically tailored for comprehensive
evaluation of IMU signal enhancement, along with a dedicated dataset for over-range reconstruction,
facilitating fair comparisons and fostering rapid progress within the community.


**2** **Related Works**


**2.1** **IMU over-range signal reconstruction.**


Reconstructing saturated signal segments in IMUs remains a critical but significantly under explored
problem. Among the few representative studies, HEROS-GAN[ 15 ] formulates the problem as a
fully supervised generative task, relying heavily on paired saturated and reference data for training.
Alternatively, Matlab 2023b[ 19 ] release introduced a polynomial-based extrapolation function that
estimates saturated peaks from their neighboring points; however, this model-driven approach is
inherently sensitive to noise and struggles under highly dynamic conditions. However, existing
studies have not explored self-supervised approaches or integrated IMU-specific physical constraints
into the reconstruction task.


2


|Col1|Col2|
|---|---|
|||
|||









                 -                  Figure 1: Pipeline of MoE Gyro framework. During inference, a low quality signal stream is
segmented, routed by a gate to suitable expert, and the enhanced outputs are concatenated to form the

                                         final signal. During training, both experts are optimised in a fully self supervised manner on a shared
MAE backbone, each equipped with task-specific masking, attention, and loss mechanisms.


**2.2** **IMU signal denoise.**


                        In contrast to the sparse literature on over range reconstruction, signal enhancement research for IMUs
has largely centred on noise suppression. Classical, model - driven filters such as EMD denoising[ 20 ]
and Savitzky–Golay smoothing[ 21 ] can isolate and attenuate noise, yet they depend on accurate noise
priors, which often fail to transfer across sensors or operating conditions. More recent data - driven
approaches, including CNN[ 13 ], LSTM - GRU hybrids[ 14 ], and the IMUDB[ 17 ], replace explicit
priors with learned representations and have therefore attracted wider adoption.


**3** **Method**


**Motivation.** Although recent supervised and self-supervised models have markedly improved IMU
denoising, simply grafting multiple task heads onto one backbone to unify denoising and over-range
reconstruction proves unreliable. After normalization, clipped-peak errors dwarf background noise by
several orders of magnitude, so reconstruction gradients dominate training, and the network largely
ignores the denoising head. The resulting scale-imbalance leaves one task under-fitted and the other
only partially solved, curbing overall accuracy and generalization[22, 23, 24].


This observation motivates a decoupled, self-supervised Mixture-of-Experts design in which each
task is handled by a dedicated specialist while global features are shared only when beneficial. By
adopting a shared Masked Autoencoder (MAE) encoder combined with lightweight task-specific
decoders, each expert is allowed to specialize independently. Moreover, we introduce dedicated
task-oriented masking strategies, a Gaussian-Decay Attention mechanism, and physics-informed
constraints to ensure stable and targeted optimization. This modular, decoupled design ultimately
enables more effective training and significantly improved enhancement performance.


**Overview.** Figure 1 shows the **MoE-Gyro** architecture for self-supervised inertial signal enhancement. The raw signal is first segmented, and a gate then applies a simple heuristic to route each
segment to the Over-Range Reconstruction Expert (ORE), the Denoise Expert (DE), both experts, or
directly to the output. The ORE follows a standard MAE backbone but adds a task-specific threshold
mask to focus on in-range features, and inserts a Gaussian-Decay Attention block in the decoder to
selectively amplify peak region information during reconstruction. The DE adopts a dual-branch
MAE design in which two parameter-shared encoders/decoders operate on complementary masks,
allowing the network to capture intrinsic signal correlations while aggressively suppressing high

3


frequency noise. Finally, the gated outputs of the two experts are concatenated to yield the enhanced
signal. The precise routing and concating logic is summarized in Algorithm 1.


**3.1** **Over-range Reconstruction Expert**



**Gaussian-Decay Attention.** Windowed or
local attention has proved effective in vision
and language models because it reduces distraction from distant, less relevant context[ 25,
26 ]. Such locality is especially valuable for
over-range reconstruction, because the information required to restore a clipped peak is
concentrated within a short temporal window
around the peak. However, a fixed window
ignores sensor-specific dynamics and, being
a non-differentiable mask, cannot adapt itself during learning. Inspired by these issues, we introduce **Gaussian-Decay Atten-**
**tion (GD-Attn)**, which replaces the binary
window mask with a learnable, continuous
Gaussian bias. For a query–key pair ( _i, j_ ) separated by _d_ _ij_ = _|i −_ _j|_ steps, GD-Attn adds a



**Algorithm 1:** MoE route and concat


**Input:** segment _x_ [1: _L_ ]
**Output:** enhanced _y_ [1: _L_ ]

**1** _y ←_ _x_ ;

**2** _peak ←_ 3 consecutive clipped?;

**3** _noise ←_ run of _n_ samples _< τ_ ?;

**4** **if** _peak_ **then**

**5** _p_ ˆ _←_ PeakExpert( _x_ )

**6** **end**


**7** **if** _noise_ **then**

**8** _n_ ˆ _←_ DenoiseExpert( _x_ )

**9** **end**


**10** **for** _t ←_ 1 **to** _L_ **do**

**11** **if** _peak_ _**and**_ _x_ _t_ _clipped_ **then**

**12** _y_ _t_ _←_ _p_ ˆ _t_ ;

**13** **else if** _noise_ _**and**_ _|_ ˆ _x_ _t_ : _t_ + _n−_ 1 _| < τ_ **then**

**14** _y_ _t_ : _t_ + _n−_ 1 _←_ _n_ _t_ : _t_ + _n−_ 1 ; _t ←_ _t_ + _n_ ;

**15** **end**



learnable Gaussian bias _B_ _ij_ = _−_ 2 _dσ_ [2] _ij_ [2] [, where] **16** **end**
the single trainable parameter _σ_ is initialised **17** **return** _y_
to a nominal window size and clamped for stability. With queries _Q_, keys _K_, and values _V_, the
resulting attention is



**16** **end**



**17** **return** _y_



˜
Output = _A V,_ [˜] _A_ = softmax� _QK_ _[⊤]_ _/_ �



_d_ _k_ + _B_ � (1)



This Gaussian bias yields a soft, differentiable window whose effective width is learned end-to-end;
as _σ →∞_ the bias disappears and GD-Attn reduces to standard global attention, whereas finite _σ_
smoothly down-weights distant tokens and concentrates capacity on the peak region.


**Correlation Loss.** Pure _L_ 2 reconstruction matches amplitudes but overlooks local dynamics, often
smoothing peaks. To recover both trend and extrema we define a two-term _correlation loss L_ corr :



�( _x_ _t_ _−_ _x_ ˆ _t_ ) [2] (2)

_t∈E_



1
_L_ corr = _|M|_



1

� (∆ _x_ _t_ _−_ ∆ˆ _x_ _t_ ) [2] + _λ_ sign

_t∈M_ _|E|_



where ∆ _x_ _t_ = _x_ _t_ _−_ _x_ _t−_ 1 and ∆ˆ _x_ _t_ are first-order differences of the ground-truth and reconstructed
signals; _M_ is the set of masked time steps; _E_ = _{ t ∈M |_ sign(∆ _x_ _t_ ) _̸_ = sign(∆ _x_ _t_ +1 ) _}_ marks
sign-change (peak/valley) positions within the mask; and _λ_ sign weights the extremum term ( _λ_ sign = 1
by default). The first term aligns local slopes, while the second preserves peak and valley amplitudes,
jointly yielding sharper and more faithful reconstructions.


**Physics-informed energy loss (PINN).** To improve generalisation and ensure that the reconstructed
waveform remains physically plausible, we add a physics-informed regulariser derived from the
displacement–power relationship of an IMU’s proof mass. Let _x_ _t_ denote the reconstructed angularrate (or acceleration) sequence inside the masked region _M_ . We compute the first and second discrete
derivatives ∆ _x_ _t_ = _x_ _t_ _−_ _x_ _t−_ 1 _,_ ∆ [2] _x_ _t_ = _x_ _t_ +1 _−_ 2 _x_ _t_ + _x_ _t−_ 1 _,_ and define the instantaneous _specific_
_power e_ _t_ = (∆ [2] _x_ _t−_ 1 + ∆ [2] _x_ _t_ ) ∆ _x_ _t_ _._ Averaging over the mask gives the normalised energy



¯ 1
_E_ =
_|M|_



� _e_ _t_ _,_ _E_ norm = _σ_ ( _E_ [¯] ) (3)

_t∈M_



where _σ_ ( _·_ ) is the sigmoid. Extremely low or high power violates the mass–spring dynamics implicit
in most MEMS sensors, so we penalise both extremes with a barrier term

_L_ pinn = _−_ log� _E_ norm � _−_ _κ_ log�1 _−_ _E_ norm � (4)


4


where _κ_ balances the two sides ( _κ_ =1 in all experiments). This loss drives the reconstructed segment
toward a moderate energy level, complementing the _L_ 2 and correlation objectives.


**3.2** **Denoise expert**


**Dual-branch complementary masking.** The Denoise Expert employs a **dual-branch MAE** whose
two branches share all encoder and decoder weights[ 27, 28 ]. For each length- _L_ segment we construct
two fixed 50 % masks in a cross pattern so that every even patch index is visible to branch A and
masked for branch B, and vice-versa. Formally, _M_ _A_ _∪M_ _B_ = _{_ 1 _, . . ., L}_ and _M_ _A_ _∩M_ _B_ = ∅,
guaranteeing complementarity. Each branch receives the same noisy input but reconstructs only its
own masked positions, which prevents information leakage while ensuring that no salient sample is
ever hidden from both branches. After patch embedding the two masked sequences are processed
by the shared encoder, padded with mask tokens, and decoded. The partial reconstructions _y_ _A_ and
_y_ _B_ are fused as _y_ final = _y_ _A_ _·M_ **A** + _y_ _B_ _·M_ **B** _,_ yielding a full-length denoised signal. Weight sharing
regularises the model and promotes the extraction of universal features, enabling more effective
suppression of high-frequency random noise.


**FFT-guided training augmentation.** Inspired by noise-injection strategies proven effective in
speech enhancement[ 29, 30 ], we introduce an FFT-guided noise-injection scheme that synthesises
spectrally matched corruption to create realistic training pairs. We create realistic pairs on-the-fly by
injecting weak but genuine motion snippets, guided by the noise power spectrum: (1) Noise–floor
estimation: For each raw noise segment we compute its FFT and obtain the power-spectral density
(PSD). The median PSD value serves as the local noise floor _P_ noise . (2) Weak-signal injection: We
randomly sample a short motion clip _s_ ( _t_ ) from a separate repository of real IMU recordings (e.g.,
walking, hand-held rotations). The clip is amplitude-scaled to _α s_ ( _t_ ) with _α_ = _β_ _[√]_ _P_ noise _/_ max _t_ _|s_ ( _t_ ) _|_,
where _β_ is a constant. The scaled clip is then added to the raw noise, yielding _x_ mix ( _t_ ) = _x_ noise ( _t_ ) +
_α s_ ( _t_ ) . (3) Additional corruption: After analysing the PSD, we synthesise spectrally matched noise
(targeting the frequency bands that dominate QN, ARW, and BI) and add it to the mixture, producing
a heavier corruption that forces the model to learn a true denoising mapping rather than smoothing
_x_ mix _←_ _x_ mix + _x_ _[′]_ noise [(] _[t]_ [)] [. (4) Training target: The mixture] _[ x]_ [mix] [ is fed to the dual-branch MAE, while]
the reference signal is defined as _x_ clean = _x_ noise ( _t_ ) + _α s_ ( _t_ ), without the extra corruption. This
forces the network to suppress the added noise yet retain the weak real motion. This FFT-guided
augmentation supplies a realistic, controllable SNR and teaches the model to enhance subtle motion
cues rather than over-smooth them.


**4** **Datasets & Benchmark**


This section first details the datasets used for training and evaluation, and then describes **IMU**
**Signal Enhancement Benchmark (ISEBench)**, the unified benchmark we release for fair and
comprehensive assessment of IMU signal enhancement methods.


**4.1** **Datasets**


We conduct all experiments on three publicly available dataset. **GyroPeak-100** (released with this
paper) is a 100 Hz collection captured from the iPhone 14 on-board IMU with ground-truth peak
annotations and serves as the sole source for training and evaluating the over-range reconstruction
network. For the denoising task we adopt the Visual-Inertial dataset [ 17 ] and the Autonomous
Platform Inertial dataset [ 31 ], both down-sampled to 100 Hz for consistency. Together, these datasets
cover a broad spectrum of motion dynamics, providing a balanced and comprehensive testbed for the
proposed signal-enhancement pipeline. We follow an 80 / 20 split of each dataset for training and
testing, respectively, and all experiments are executed on a single NVIDIA RTX-4060 GPU.


**4.2** **ISEBench: IMU Signal Enhancement Benchmark**


To systematically and objectively evaluate the performance of the proposed inertial signal enhancement methods, we introduce and design a comprehensive testbench named **IMU Signal Enhancement**
**Benchmark (ISEBench)** . The **ISEBench** is specifically tailored for inertial measurement unit (IMU)
signal enhancement, providing a unified evaluation framework that covers multiple practical scenarios.


5


Table 1: Performance comparison on **ISEBench** . The best result is **boldfaced** and the second best is
underlined . For clarity, each P_MSE entry is written as _P_MSE_ _i_ _/P_MSE_ _RAW_, and all Allan-variance
metrics are reported as the percentage reduction relative to the raw signal (the omitted values are
provided in Appendix C).







|Model\Metric|Peak Rec. (τ = 450◦/s)<br>PSNR ↑ P_MSE ↓ Corr ↑<br>dB - -|Weak Sig.<br>SNR ↑<br>dB|Allan Variance<br>QN ↓ AR√W ↓ BI ↓<br>(◦/s) (◦/ h) (◦/h)|AVG.rank|
|---|---|---|---|---|
|RAW<br>Matlab 2023[19]<br>EMD[20]<br>SG_flter[21]<br>CNN[13]<br>LSTM_GRU[14]<br>KNN[31]<br>HEROS_GAN[15]<br>IMUDB[17]<br>**MoE-Gyro**|2.67<br>1<br>-<br>10.18<br>0<br>0<br>0<br>6.03<br>0.515<br>0.86<br>10.02<br>-25.8%<br>-3.1%<br>+5.4%<br>5.44<br>0.655<br>0.77<br>13.85<br>-91.1%<br>-85.9%<br>-96.8%<br>4.35<br>0.767<br>0.79<br>12.03<br>-85.0%<br>-86.3%<br>-90.0%<br>5.76<br>0.621<br>0.85<br>14.3<br>-62.5%<br>-35.9%<br>-79.4%<br>5.95<br>0.495<br>0.87<br>19.23<br>-80.8%<br>-85.0%<br>-93.1%<br>3.72<br>0.752<br>0.67<br>12.54<br>-85.7%<br>-34.3%<br>-47.5%<br>7.7<br>0.354<br>0.89<br>16.86<br>-92.8%<br>-51.6%<br>-58.3%<br>6.59<br>0.442<br>0.82<br>17.76<br>-85.8%<br>-87.8%<br>-93.7%<br>**8.19**<br>**0.325**<br>**0.92**<br>**24.19**<br>**-98.0%**<br>**-94.1%**<br>**-98.4%**|2.67<br>1<br>-<br>10.18<br>0<br>0<br>0<br>6.03<br>0.515<br>0.86<br>10.02<br>-25.8%<br>-3.1%<br>+5.4%<br>5.44<br>0.655<br>0.77<br>13.85<br>-91.1%<br>-85.9%<br>-96.8%<br>4.35<br>0.767<br>0.79<br>12.03<br>-85.0%<br>-86.3%<br>-90.0%<br>5.76<br>0.621<br>0.85<br>14.3<br>-62.5%<br>-35.9%<br>-79.4%<br>5.95<br>0.495<br>0.87<br>19.23<br>-80.8%<br>-85.0%<br>-93.1%<br>3.72<br>0.752<br>0.67<br>12.54<br>-85.7%<br>-34.3%<br>-47.5%<br>7.7<br>0.354<br>0.89<br>16.86<br>-92.8%<br>-51.6%<br>-58.3%<br>6.59<br>0.442<br>0.82<br>17.76<br>-85.8%<br>-87.8%<br>-93.7%<br>**8.19**<br>**0.325**<br>**0.92**<br>**24.19**<br>**-98.0%**<br>**-94.1%**<br>**-98.4%**|2.67<br>1<br>-<br>10.18<br>0<br>0<br>0<br>6.03<br>0.515<br>0.86<br>10.02<br>-25.8%<br>-3.1%<br>+5.4%<br>5.44<br>0.655<br>0.77<br>13.85<br>-91.1%<br>-85.9%<br>-96.8%<br>4.35<br>0.767<br>0.79<br>12.03<br>-85.0%<br>-86.3%<br>-90.0%<br>5.76<br>0.621<br>0.85<br>14.3<br>-62.5%<br>-35.9%<br>-79.4%<br>5.95<br>0.495<br>0.87<br>19.23<br>-80.8%<br>-85.0%<br>-93.1%<br>3.72<br>0.752<br>0.67<br>12.54<br>-85.7%<br>-34.3%<br>-47.5%<br>7.7<br>0.354<br>0.89<br>16.86<br>-92.8%<br>-51.6%<br>-58.3%<br>6.59<br>0.442<br>0.82<br>17.76<br>-85.8%<br>-87.8%<br>-93.7%<br>**8.19**<br>**0.325**<br>**0.92**<br>**24.19**<br>**-98.0%**<br>**-94.1%**<br>**-98.4%**|-<br>7.0<br>5.3<br>6.6<br>6.1<br>4.3<br>7.7<br>3.6<br>3.4<br>**1**|


Different from prior works that typically rely on isolated or single evaluation metrics, **ISEBench**
incorporates a structured metric set categorized into three distinct aspects to thoroughly quantify
enhancement performance.


**Evaluation Metrics: 1. Over-range Reconstruction Metrics:** Over-range reconstruction assesses

                      the model’s ability to recover over range peaks that are lost when the raw signal is clipped at a
dynamic - range threshold _τ_ before being fed to the network. During evaluation we supply the model
with the clipped input _x_ clip = clip( _x, ±τ_ ) while using the unclipped signal _x_ as ground truth, and
we compute all metrics only on those samples for which _|x| > τ_ . Concretely, we report **Peak**
**Signal-to-Noise Ratio (PSNR)**, which measures the reconstruction quality of the clipped portions;



�



( _|_ Peak max _| −_ _|τ_ _|_ ) [2]


_MSE_

�



_MSE_ = [1]

_N_



_N_
�( _x_ _t_ _−_ _x_ ˆ _t_ ) [2] _,_ PSNR = 10 log 10


_t_ =1



_._ (5)



**Correlation (Corr)**, the Pearson linear correlation[ 32 ] between the reconstructed and ground - truth
waveforms over the same peak regions; and **Peak Mean** **-** **Squared Error (PMSE)**, which provides a
point-wise accuracy measure at the detected peak locations. Let _P_ be the index set of local peaks;



1
PMSE =
_|P|_



�


_t∈P_



ˆ 2
� _y_ _t_ _−_ _y_ _t_ � _._ (6)



**2. Weak Signal Enhancement Metric:** This metric assesses the capability of the proposed approach
in extracting and enhancing low-amplitude signals: **Signal-to-Noise Ratio (SNR)** [ 33 ] evaluates weak
signal recovery effectiveness. **3. Static Noise Performance Metrics:** To characterize sensor performance in static (non-moving) conditions, we adopt standard inertial measurement unit performance
metrics defined by Allan variance[ 34 ], including: **Angle Random Walk (ARW)**, **Quantization**
**Noise (QN)** and **Bias Instability (BI)** .These metrics are computed following standard Allan variance
analysis methodology described comprehensively in prior studies. The formulas for the above seven
metrics are given in the Appendix A.


Together, these metrics constitute **ISEBench**, a unified and transparent yardstick for
inertial - signal–enhancement research. In the following experiments we leverage **ISEBench** to
benchmark our model against state-of-the-art baselines, highlighting its effectiveness.


**5** **Experiments**


**5.1** **Comparison with Previous Results**


For the quantitative comparison, we pit **MoE** **-** **Gyro** against nine carefully reproduced baselines drawn

                               from three methodological families: classic model driven signal processors (EMD, Savitzky–Golay
filtering, and the Matlab over-range signal reconstruction function); fully supervised deep networks

                                    (CNN, kNN, LSTM–GRU and HEROS_GAN); and the self supervised model, IMUDB. To ensure
fairness, all supervised baselines are retrained on matched data: clipped and full pairs from our Peak


6


Figure 2: Comparison of reconstruction
P_MSE. We compare **MoE-Gyro** with two representative baselines,a drop of more than 75 %
(dashed reference) marks high-quality recovery.



          Figure 3: Allan variance comparison. The red
curve corresponds to **MoE-Gyro** and shows the
best Allan-variance performance—raising the
device from consumer to nearly strategic grade.



database for over - range reconstruction and clean/noisy pairs from the _Autonomous Platform Inertial_
dataset for denoising. Each method is executed exactly as specified in its original paper, using the
authors’ code when available or a validated re - implementation otherwise. The resulting performance
in **ISEBench** is summarized in Table 1. **MoE-Gyro** attains the best average rank across all metrics.


We analyze the performance of different methods separately for over-range reconstruction and
denoising tasks. Regarding over-range reconstruction, Table 1 shows that classical model-driven
methods indeed raise PSNR and Corr, but their P_MSE remains large, revealing limited accuracy at
the peak locations. Because these methods extrapolate by incrementally fitting the visible portion
of the waveform. Meanwhile, we compare **MoE-Gyro** with the best data-driven baseline (HEROSGAN) and the best model-driven baseline (Matlab2023) by plotting the relative P_MSE reduction
at different angular velocity thresholds (Fig. 2). At 1500 _[◦]_ _/s_ our method still achieves high-quality
peak reconstruction, whereas HEROS-GAN deteriorates noticeably beyond 900 _[◦]_ _/s_ ; the model-driven
filter ceases to reconstruct peaks effectively once the angular velocity exceeds 600 _[◦]_ _/s_ . These results
further substantiate the limitations discussed above. **MoE-Gyro** outperforms all baselines thanks
to (i) an adaptive MAE mask that keeps peak-relevant patches, (ii) Gaussian-Decay Attention that
concentrates decoding on the clipped region, and (iii) a carefully engineered loss that restores local
dynamics (see ablations).


In terms of denoising performance, classical filters lower Allan-variance terms but also erase faint
motion, so SNR barely improves. Supervised deeplearning baselines, trained as single multitask networks, likewise sacrifice SNR because the much
larger reconstruction loss dominates optimisation.
By routing segments to a dedicated Denoise Expert
and training it with FFT-guided noise augmentation, **MoE-Gyro** delivers the highest SNR while
further reducing QN, ARW, and BI; Allan-variance
curves in Fig.3 visualise the gain.


**5.2** **Real-world Experiment**


Figure 4: Range                         - extension visualisation. At

To intuitively demonstrate the practical capability

an actual angular rate of –1731.8°/s, our

of our framework in handling severe over-range

method reconstructs the signal clipped at the

conditions, we randomly select a representative

450°/s sensor limit to –1453.7°/s.

segment from the test set for visualization (Fig. 4).
The segment includes measurements from a lowrange IMU (IM900, ±450°/s), the corresponding ground truth, and the enhanced output from our


7


Table 2: MoE ablation results.


Model PSNR _↑_ SNR _↑_ Mem _↓_


ORE+DE 8.19 24.58 129
SingleNet 7.23 12.9 64.7
**MoE-Gyro** **8.19** **24.19** **71.3**



Table 3: Impact of GD-Attn Placement


Setting PSNR _↑_ P_MSE _↓_ Corr _↑_


No GD-Attn 8.08 0.345 0.87
Encoder-only 8.03 0.345 0.88
Enc.+Dec. 8.27 0.335 0.90
**Decoder-only** **8.29** **0.324** **0.92**



**MoE-Gyro** . At the highlighted peak, the true angular velocity reaches -1731.8°/s, significantly
exceeding the measurement limit of the IM900 sensor. Despite this substantial clipping, **MoE-Gyro**
effectively reconstructs the peak to -1453.7°/s, accurately capturing key signal dynamics beyond
the nominal range. By contrast, the best competing method we tested lifts the same peak only to
-1287 °/s and exhibits pronounced waveform distortion around the apex, detailed traces are provided
in Appendix C. This capability suggests substantial potential for expanding the practical utility of
low-cost, limited-range inertial sensors.


**5.3** **Ablation Studies**


In this section, we conduct ablation experiments on the components of our method. By systematically
enabling or disabling each component, or substituting it with simpler counterparts, we quantify how
much performance each element contributes to the final system.


**Ablation on the MoE.** To assess the impact of the MoE architecture itself, we compare alternative

    -     expert invocation schemes with a single multi task network of equal size. Table 2 shows that the full
MoE - Gyro achieves virtually identical enhancement to calling both the ORE and DE, indicating that
the router and concatenation do not degrade either task. A single multi-task network of identical size
trails behind on both metrics, confirming the advantage of explicit task decoupling. Since most of
the time the MoE architecture calls only a single expert to process a segment, **MoE-Gyro** requires
roughly half GPU memory consumed when both experts are run unconditionally, while matching
their combined quality, demonstrating a clear efficiency gain.



Table 4: PINN vs. Second-Order Smoothness.



**Ablation on the Over-range Reconstruction**
**Expert.** We systematically evaluate the individual contributions of GD-Attn, the corre- Loss PSNR _↑_ P_MSE _↓_ Corr _↑_
lation loss, and the PINN regularizer in our Smoothness 8.02 0.354 0.88
Over-range Reconstruction Expert. First, we **PINN (** _κ_ =1 **)** **8.29** **0.324** **0.92**
investigate the optimal placement of the GDAttn module (Tab. 3). Results show decoderonly integration of GD-Attn achieves the largest improvement. This demonstrates GD-Attn’s critical
role in refining latent representations specifically at the decoding stage, effectively focusing reconstruction capacity on clipped regions.



Loss PSNR _↑_ P_MSE _↓_ Corr _↑_


Smoothness 8.02 0.354 0.88
**PINN (** _κ_ =1 **)** **8.29** **0.324** **0.92**



Second, we compare our proposed physicsinformed energy loss (PINN) against a conventional second-order smoothness prior (Tab.
4)[ 35, 36 ]. When evaluated on unseen
data, our PINN consistently outperforms the
smoothness regularizer, improving PSNR by
0.27 dB and reducing P_MSE by 8%, highlighting the strong generalization ability provided by the physics-based constraint.



Table 5: Component ablation results.


Model PSNR _↑_ P_MSE _↓_ Corr _↑_


No Components 7.68 0.369 0.88
GD-Attn 7.96 0.364 0.90

Corr 7.83 0.354 0.91

PINN 7.95 0.345 0.90

GD+Corr 8.21 0.350 0.91

GD+PINN 8.19 0.339 0.91

Corr+PINN 8.08 0.340 0.91

**All** **8.29** **0.324** **0.92**



Finally, we comprehensively explore all com
**All** **8.29** **0.324** **0.92**

binations to quantify their cumulative and
complementary effects (Tab. 5). Individually,
GD-Attn significantly improves peak restoration, correlation loss notably enhances waveform fidelity,
and PINN markedly stabilizes signal reconstruction. Jointly, these components interact positively,
resulting in the best overall trade-off in reconstruction quality and stability.



8


(a) Mask-ratio comparison (b) Mask-pattern comparison (c) FFT augmentation ablation


Figure 5: Ablation studies for the Denoise Expert. (a) Mask ratio: a 50 % mask yields the strongest
denoising effect; (b) Mask pattern: the cross mask outperforms block and random patterns; (c) FFT
augmentation: FFT-guided noise injection gives the largest performance gain.


**Ablation on the Denoise Expert.** We isolate and analyze three key design choices within the
denoising expert: mask strategy, weight sharing, and augmentation strategy. First, we optimize the
complementary mask ratio from 0% to 50% (Fig. 5a), finding that a dual-branch architecture with
a 50% mask ratio consistently yields superior noise suppression performance. Next, holding this
ratio fixed, we compare different mask patterns (Fig. 5b). A block mask removes large contiguous
regions and thus underperforms significantly, while random masking shows improvements on Allan
metrics but still exhibits suboptimal SNR due to residual noise leakage. Our deterministic cross mask
achieves the best balance, matching random masking on Allan metrics while outperforming in SNR,
attributed to complete temporal coverage and minimal information gaps.


We then examine the effectiveness of parame- Table 6: Weight-Sharing study
ter sharing between branches (Tab. 6). While
independent branches double model capac- Weight sharing SNR _↑_ GPU mem _↓_ Params _↓_
ity, full encoder-decoder weight sharing re- No share 24.51 116.8 27.8
duces parameters by 50% and GPU memory E share 24.35 76.2 17.15
usage by 45% with negligible impact on de- D share 24.27 105.0 24.64
noising quality. Partial sharing variants either **E+D share** **24.19** **64.4** **13.9**
reduce efficiency gains or degrade signal quality. Thus, full weight sharing represents the optimal complexity-performance trade-off and is adopted.


Finally, we evaluates the impact of our FFT-guided augmentation strategy(Fig. 5c). Compared to a
baseline without augmentation, Gaussian noise injection modestly improves SNR but leaves Allan
metrics largely unaffected. Our FFT-guided augmentation introducing spectrally matched synthetic
noise, achieves comprehensive gains across all metrics. These results validate the superiority of using
realistic spectral characteristics to train a more robust denoiser.


**6** **Conclusion**


In this work, we introduced **MoE-Gyro**, a novel self-supervised Mixture-of-Experts framework
tailored to simultaneously address the long-standing trade-off between measurement range and noise
performance in MEMS gyroscopes. **MoE-Gyro** leverages masked autoencoder (MAE) architectures
to independently optimize two dedicated experts: an Over-Range Reconstruction Expert (ORE),
enhanced by Gaussian-Decay Attention and physics-informed constraints for accurate reconstruction
of saturated signals; and a Denoise Expert (DE), utilizing complementary masking and FFT-guided
augmentation to significantly reduce noise without requiring labeled data. Additionally, we introduced
**ISEBench**, the first open-source evaluation benchmark designed for fair and comprehensive assessment of IMU signal-enhancement methods. Experiments on **ISEBench** demonstrated that **MoE-Gyro**
extends the measurable range from ±450 °/s to ±1500 °/s and reduces Bias Instability by 98.4%,
significantly surpassing existing baselines. Despite these advancements, the relatively large size of
our proposed architecture may pose challenges for resource-constrained embedded deployments;
future work could thus explore model compression techniques to enable more efficient deployment.
Our study opens a promising path to deep learning-based performance upgrades for MEMS inertial
sensors and establishes a solid baseline for future research in inertial signal enhancement.


9



Table 6: Weight-Sharing study



Weight sharing SNR _↑_ GPU mem _↓_ Params _↓_



No share 24.51 116.8 27.8

E share 24.35 76.2 17.15

D share 24.27 105.0 24.64

**E+D share** **24.19** **64.4** **13.9**


**References**


[1] R. Vivacqua, R. Vassallo, and F. Martins, “A low cost sensors approach for accurate vehicle
localization and autonomous driving application,” _Sensors_, vol. 17, no. 10, 2017.


[2] A. Ayala, L. Portela, F. Buarque, B. J. T. Fernandes, and F. Cruz, “Uav control in autonomous
object-goal navigation: a systematic literature review,” _Artificial Intelligence Review_, vol. 57,
no. 5, 2024.


[3] X. Niu, Y. Wu, and J. Kuang, “Wheel-ins: A wheel-mounted mems imu-based dead reckoning
[system,” 2021. [Online]. Available: https://arxiv.org/abs/1912.07805](https://arxiv.org/abs/1912.07805)


[4] S. A. Zotov, I. P. Prikhodko, B. R. Simon, A. A. Trusov, and A. M. Shkel, “Self-calibrated mems
gyroscope with am/fm operational modes, dynamic range of 180 db and in-run bias stability of
0.1 deg/hr,” in _2014 DGON Inertial Sensors and Systems (ISS)_, 2014, pp. 1–17.


[5] M. F. Zaman, A. Sharma, Z. Hao, and F. Ayazi, “A mode-matched silicon-yaw tuning-fork
gyroscope with subdegree-per-hour allan deviation bias instability,” _Journal of Microelectrome-_
_chanical Systems_, vol. 17, no. 6, pp. 1526–1536, 2008.


[6] J. Jia, X. Ding, Y. Gao, and H. Li, “Automatic frequency tuning technology for dual-mass mems
gyroscope based on a quadrature modulation signal,” _Micromachines_, vol. 9, no. 10, 2018.


[7] H. Zhang, C. Zhang, J. Chen, and A. Li, “A review of symmetric silicon mems gyroscope
mode-matching technologies,” _Micromachines_, vol. 13, no. 8, 2022.


[8] Y. Wang, Q. Fu, Y. Zhang, W. Zhang, D. Chen, L. Yin, and X. Liu, “A digital closed-loop sense
mems disk resonator gyroscope circuit design based on integrated analog front-end,” _Sensors_,
vol. 20, no. 3, 2020.


[9] H. Zhang, W. Chen, L. Yin, and Q. Fu, “An interface asic design of mems gyroscope with
analog closed loop driving,” _Sensors_, vol. 23, no. 5, 2023.


[10] R. Lv, W. Chen, and X. Liu, “A high-dynamic-range switched-capacitor sigma-delta adc for
digital micromechanical vibration gyroscopes,” _Micromachines_, vol. 9, no. 8, 2018.


[11] S. Yu, J. Sun, Y. Zhang, X. Xi, K. Lu, Y. Shi, D. Xiao, and X. Wu, “Real-time correction of
gain nonlinearity in electrostatic actuation for whole-angle micro-shell resonator gyroscope,”
_Microsystems & Nanoengineering_, vol. 10, 2024.


[12] Y. Li, R. Chen, X. Niu, Y. Zhuang, Z. Gao, X. Hu, and N. El-Sheimy, “Inertial sensing meets
machine learning: Opportunity or challenge?” _IEEE Transactions on Intelligent Transportation_
_Systems_, vol. 23, no. 8, pp. 9995–10 011, 2022.


[13] H. Chen, T. M. Taha, and V. P. Chodavarapu, “Towards improved inertial navigation by reducing
errors using deep learning methodology,” _Applied Sciences_, vol. 12, no. 7, 2022.


[14] S. Han, Z. Meng, X. Zhang, and Y. Yan, “Hybrid deep recurrent neural networks for noise
reduction of mems-imu with static and dynamic conditions,” _Micromachines_, vol. 12, no. 2,
2021.


[15] Y. Wang and Y. Zhao, “Heros-gan: Honed-energy regularized and optimal supervised gan
for enhancing accuracy and range of low-cost accelerometers,” 2025. [Online]. Available:
[https://arxiv.org/abs/2502.18064](https://arxiv.org/abs/2502.18064)


[16] H. Xu, P. Zhou, R. Tan, M. Li, and G. Shen, “Limu-bert: Unleashing the potential of unlabeled
data for imu sensing applications,” in _Proceedings of the 19th ACM Conference on Embedded_
_Networked Sensor Systems_, ser. SenSys ’21. New York, NY, USA: Association for Computing
Machinery, 2021, p. 220–233.


[17] K. Yuan and Z. J. Wang, “A simple self-supervised imu denoising method for inertial aided
navigation,” _IEEE Robotics and Automation Letters_, vol. 8, no. 2, pp. 944–950, 2023.


[18] K. He, X. Chen, S. Xie, Y. Li, P. Dollár, and R. Girshick, “Masked autoencoders are scalable
[vision learners,” 2021. [Online]. Available: https://arxiv.org/abs/2111.06377](https://arxiv.org/abs/2111.06377)


10


[19] The MathWorks Inc., _MATLAB R2023b_, The MathWorks, Inc., 2023. [Online]. Available:
[https://www.mathworks.com/products/matlab.html](https://www.mathworks.com/products/matlab.html)


[20] Y. Gan, L. Sui, J. Wu, B. Wang, Q. Zhang, and G. Xiao, “An emd threshold de-noising
method for inertial sensors,” _Measurement_, vol. 49, pp. 34–41, 2014. [Online]. Available:
[https://www.sciencedirect.com/science/article/pii/S0263224113005836](https://www.sciencedirect.com/science/article/pii/S0263224113005836)


[21] Q. Li, “Noise reduction of accelerometer signal with singular value decomposition and savitzkygolay filter,” _The Journal of Information and Computational Science_, vol. 10, pp. 4783–4793,
2013.


[22] Z. Chen, V. Badrinarayanan, C.-Y. Lee, and A. Rabinovich, “Gradnorm: Gradient
normalization for adaptive loss balancing in deep multitask networks,” 2018. [Online].
[Available: https://arxiv.org/abs/1711.02257](https://arxiv.org/abs/1711.02257)


[23] A. Kendall, Y. Gal, and R. Cipolla, “Multi-task learning using uncertainty to weigh losses for
[scene geometry and semantics,” 2018. [Online]. Available: https://arxiv.org/abs/1705.07115](https://arxiv.org/abs/1705.07115)


[24] O. Sener and V. Koltun, “Multi-task learning as multi-objective optimization,” 2019. [Online].
[Available: https://arxiv.org/abs/1810.04650](https://arxiv.org/abs/1810.04650)


[25] I. Beltagy, M. E. Peters, and A. Cohan, “Longformer: The long-document transformer,” 2020.

[[Online]. Available: https://arxiv.org/abs/2004.05150](https://arxiv.org/abs/2004.05150)


[26] T. Hu, J. Xu, C. Huang, H. Qi, Q. Huang, and Y. Lu, “Weakly supervised bilinear
attention network for fine-grained visual classification,” 2019. [Online]. Available:
[https://arxiv.org/abs/1808.02152](https://arxiv.org/abs/1808.02152)


[27] G. Bender, H. Liu, B. Chen, G. Chu, S. Cheng, P.-J. Kindermans, and Q. Le, “Can weight
sharing outperform random architecture search? an investigation with tunas,” 2020. [Online].
[Available: https://arxiv.org/abs/2008.06120](https://arxiv.org/abs/2008.06120)


[28] J. Prellberg and O. Kramer, “Learned weight sharing for deep multi-task learning by
natural evolution strategy and stochastic gradient descent,” 2020. [Online]. Available:
[https://arxiv.org/abs/2003.10159](https://arxiv.org/abs/2003.10159)


[29] Y. Xu, J. Du, L.-R. Dai, and C.-H. Lee, “A regression approach to speech enhancement based on
deep neural networks,” _IEEE/ACM Transactions on Audio, Speech, and Language Processing_,
vol. 23, no. 1, pp. 7–19, 2015.


[30] S. Braun and I. Tashev, “Data augmentation and loss normalization for deep noise suppression,”
[2020. [Online]. Available: https://arxiv.org/abs/2008.06412](https://arxiv.org/abs/2008.06412)


[31] D. Engelsman and I. Klein, “Data-driven denoising of stationary accelerometer signals,” _Mea-_
_surement_, vol. 218, p. 113218, 2023.


[32] K. Pearson, “Notes on regression and inheritance in the case of two parents,” _Proceedings of the_
_Royal Society of London_, vol. 58, pp. 240–242, 1895.


[33] C. Shannon, “Communication in the presence of noise,” _Proceedings of the IRE_, vol. 37, no. 1,
pp. 10–21, 1949.


[34] D. Allan, “Statistics of atomic frequency standards,” _Proceedings of the IEEE_, vol. 54, no. 2, pp.
221–230, 1966.


[35] E. Gudmundson, N. Sandgren, and P. Stoica, “Automatic smoothing of periodograms,” in _2006_
_IEEE International Conference on Acoustics Speech and Signal Processing Proceedings_, vol. 3,
2006, pp. III–III.


[36] N. Xu, B. Price, S. Cohen, and T. Huang, “Deep image matting,” in _Proceedings of the IEEE_
_Conference on Computer Vision and Pattern Recognition (CVPR)_, July 2017.


11


**A** **Metric Definitions in ISEB** **ENCH**


For completeness we list the analytical forms of the seven evaluation metrics used throughout
ISEB ENCH . Let _y_ = _{y_ _t_ _}_ _[N]_ _t_ =1 [be the ground-truth sequence,] [ ˆ] _[y]_ [ =] _[ {][y]_ [ˆ] _[t]_ _[}]_ _[N]_ _t_ =1 [the reconstructed (or]
denoised) sequence, and _P ⊆{_ 1 _, . . ., N_ _}_ the set of local peaks or valleys indices.


**A.1** **Over-range reconstruction metrics**


**Peak-averaged PSNR.** For each test segment _s_ we first locate its maximum absolute in-range value
Peak max [(] _[s]_ [)] [= max] _[t][∈][s]_ �� _y_ _t_ �� and then compute the dataset-level mean peak



Peak max = _S_ [1]



_S_
� Peak max [(] _[s]_ [)] _[.]_ (7)


_s_ =1



Let Clip denote the sensor’s full-scale range (e.g. _±_ 450 _[◦]_ _/_ s ). The peak-averaged PSNR is defined as







PSNR = 10 log 10













�



2
Peak max _−_ Clip�






 _._ (8)





1

_N_



_N_


ˆ

�( _y_ _t_ _−_ _y_ _t_ ) [2]


_t_ =1



Here the numerator reflects the _average recoverable headroom_ between the sensor’s clip level and
the typical (mean) peak amplitude, yielding a scale that is consistent across all segments.


**Correlation (Corr).** Corr measures the linear similarity between the reconstructed signal ˆ _y_ and the
ground truth _y_, serving as an indicator of reconstruction linearity. It is defined as:


_N_
Corr = � _t_ =1 [(] _[y]_ _[t]_ _[ −]_ _[y]_ [¯][)(] _[y]_ [ˆ] _[t]_ _[ −]_ _[y]_ [ˆ][)] (9)
~~��~~ _Nt_ =1 [(] _[y]_ _[t]_ _[ −]_ _[y]_ [¯][)] [2] ~~��~~ _Nt_ =1 [(ˆ] _[y]_ _[t]_ _[ −]_ _[y]_ [ˆ][)] [2]


where ¯ _y_ = _N_ 1 � _Nt_ =1 _[y]_ _[t]_ [ and] [ ˆ] _[y]_ [ =] _N_ 1 � _Nt_ =1 _[y]_ [ˆ] _[t]_ [ are the mean values of the true and reconstructed]
sequences, respectively, over _N_ samples.


**Peak Mean Squared Error (P_MSE).** P_MSE directly measures the average reconstruction error
at the clipped-peak locations, quantifying the fidelity of peak recovery. Let _P_ be the set of time
indices where the true signal exceeds the sensor’s range (i.e. the clipped samples). Then



1
P_MSE = _|P|_



�


_t∈P_



ˆ 2
� _y_ _t_ _−_ _y_ _t_ � (10)



where _y_ _t_ is the ground truth and ˆ _y_ _t_ the reconstructed value at sample _t_ .


**A.2** **Weak Signal Enhancement Metric**


**Signal-to-Noise Ratio (SNR).** SNR quantifies the relative power of the desired signal versus
background noise. Let _{s_ _t_ _}_ _[N]_ _t_ =1 [be the segment of interest and] _[ {][n]_ _[t]_ _[}]_ _[N]_ _t_ =1 [the corresponding noise-only]
sequence. We define



_N_



_P_ signal = [1]

_N_



_N_
�



� _s_ [2] _t_ _[,]_ _P_ noise = _N_ [1]

_t_ =1



_N_
� _n_ [2] _t_ _[.]_ (11)


_t_ =1



Then



SNR = 10 log 10 � _PP_ sinoisegnal


12



_._ (12)
�


**A.3** **Weak Signal Enhancement Metric**


**Allan Variance Computation.** Given a sequence of angular-rate measurements _{x_ _k_ _}_ sampled at
interval _T_ 0, we first form non-overlapping averages over clusters of length _τ_ = _m T_ 0 :



~~_x_~~ _i_ ( _τ_ ) = [1]

_m_



_im_
� _x_ _k_ _,_ _i_ = 1 _, . . ., M,_ (13)

_k_ =( _i−_ 1) _m_ +1



where _M_ = _⌊N/m⌋_ . The Allan variance at cluster time _τ_ is then



1
_σ_ [2]
_y_ [(] _[τ]_ [) =] 2( _M −_ 1)



_M_ _−_ 1

2

� � ~~_x_~~ _i_ +1 ( _τ_ ) _−_ ~~_x_~~ _i_ ( _τ_ )� _,_ (14)

_i_ =1



and the Allan deviation is _σ_ _y_ ( _τ_ ) =
�



_σ_ _y_ [2] ( _τ_ ).



From _σ_ _y_ ( _τ_ ) we derive three standard performance parameters:



QN = _[σ]_ _[−]_ [1] [(][1][)]
~~_√_~~ 3



�slope _−_ 1 at _τ_ = 1� (15)



1 (1) �slope _−_ 2 [1]

2



ARW = _σ_ _−_ 1



2 [1] [at] _[ τ]_ [ = 1] � (16)



BI = _σ_ _y,_ min



~~�~~



2 ln 2

(17)
_π_



Here, _σ_ _−_ 1 (1) denotes the value of _σ_ _y_ ( _τ_ ) at _τ_ = 1 extrapolated along the slope –1 region, and _σ_ _−_ 12 (1)

denotes the analogous intercept for the slope -1/2 region. Within the testbench, QN and ARW are
extracted from the log–log slopes of the raw signal’s Allan deviation curve and _σ_ _y,_ min is the minimum
deviation used to compute bias instability.


**B** **Derivation of the Physics-Informed Energy Loss**



**Mechanical background.** For a MEMS proof mass of unit mass ( _m_ =1 ) moving along one axis,
the instantaneous mechanical energy is _E_ ( _t_ ) = [1] _[v]_ [2] [(] _[t]_ [) +] [1] _[kx]_ [2] [(] _[t]_ [)] _[,]_ [ where] _[ x]_ [(] _[t]_ [)] [ and] _[ v]_ [(] _[t]_ [) = ˙] _[x]_ [(] _[t]_ [)] [ are]




[1] [1]

2 _[v]_ [2] [(] _[t]_ [) +] 2



the instantaneous mechanical energy is _E_ ( _t_ ) = [1] 2 _[v]_ [2] [(] _[t]_ [) +] [1] 2 _[kx]_ [2] [(] _[t]_ [)] _[,]_ [ where] _[ x]_ [(] _[t]_ [)] [ and] _[ v]_ [(] _[t]_ [) = ˙] _[x]_ [(] _[t]_ [)] [ are]

displacement and velocity, and _k_ is the effective spring constant. The specific power(time rate of
change of energy per unit mass) is



_P_ ( _t_ ) = [d] _[E]_ _a_ ( _t_ ) = ¨ _x_ ( _t_ ) _._ (18)

d _t_ [=] _[ a]_ [(] _[t]_ [)] _[ v]_ [(] _[t]_ [)] _[,]_



**Discrete approximation.** Our network reconstructs a discrete angular-rate (or acceleration) sequence _{x_ _t_ _}_ _t∈_ Z with unit sample period ( ∆ _t_ =1 ). We approximate the first and second derivatives
by
∆ _x_ _t_ = _x_ _t_ _−_ _x_ _t−_ 1 _,_ ∆ [2] _x_ _t_ = _x_ _t_ +1 _−_ 2 _x_ _t_ + _x_ _t−_ 1 _._ (19)


Substituting (16) into (17) and centring the acceleration term yields a discrete specific power



1 [1]

2 [∆] [2] _[x]_ _[t][−]_ [1] [ +] 2



1
_e_ _t_ = � 2




[1]

2 [∆] [2] _[x]_ _[t]_ �



∆ _x_ _t_ _._ (20)



� ~~�~~ � �

acc. at _t_


**Mask-averaged normalised energy.** Given the set _M_ of masked (to-be-reconstructed) indices, we
take the mean specific power



¯ 1
_E_ =
_|M|_



� _e_ _t_ _,_ (21)

_t∈M_



and pass it through a sigmoid _E_ norm = _σ_ ( _E_ [¯] ) _∈_ (0 _,_ 1) to bound the value and allow symmetrical
penalties on both extremes.


13


(a) (b) (c)


Figure 6: Additional Experiments. (a) Clipping-Threshold Analysis. **MoE-Gyro** maintains the best
performance across all tested saturation, model-driven methods improve in relative ranking as the
threshold rises. (b) Sensitivity analysis of _λ_ in loss; (c) Reconstruction by HEROS-GAN.


**Barrier formulation.** Very small _E_ norm corresponds to an over-damped (excessively smooth)
reconstruction, whereas values near one indicate unphysical high-frequency ringing. We therefore
introduce the barrier
_L_ pinn = _−_ log� _E_ norm � _−_ _κ_ log�1 _−_ _E_ norm � _._ (22)
where _κ_ balances the penalty on the high-energy side ( _κ_ =1 in our experiments). Minimising (20)
drives _E_ norm toward a moderate value, enforcing a physically plausible energy level while remaining
fully differentiable.


**C** **Supplementary Experiments and Data**


**Analysis on clipping threshold.** In the main text we report results for a clipping threshold of
_±_ 450 _[◦]_ _/_ s . To evaluate robustness under more severe saturation, we additionally clip all test signals at
_±_ 600 _[◦]_ _/_ s, _±_ 750 _[◦]_ _/_ s and _±_ 900 _[◦]_ _/_ s and repeat the reconstruction experiments. For each clipping range,
the corrupted signals are processed by our Over-Range Expert and the PSNR is computed.


As depicted in Figure 6a, increasing the clipping threshold naturally reduces the average recoverable
headroom Peak max _−_ Clip, leading to lower absolute PSNR values. Crucially, however, our OverRange Expert still delivers substantial PSNR gains over the raw clipped signals at every tested
threshold, demonstrating its robustness across sensors with varying measurement ranges.


**Loss-weight sensitivity.** The total reconstruction loss is _L_ = _L_ 2 + _λ_ _c_ _L_ corr + _λ_ _p_ _L_ pinn _._ We fix
_λ_ _p_ = 0 _._ 5 and vary _λ_ _c_ from 0.1 to 0.5, then fix _λ_ _c_ = 0 _._ 5 and vary _λ_ _p_ over the same range. As
shown in Figure 5(b), the highest PSNR is achieved at ( _λ_ _c_ _, λ_ _p_ ) = (0 _._ 5 _,_ 0 _._ 2) . We also evaluated the
symmetric setting ( _λ_ _c_ = _λ_ _p_ = 0 _._ 2), which underperformed the asymmetric combination. Therefore,
we adopt _λ_ _L_ 2 = 1, _λ_ _c_ = 0 _._ 5, and _λ_ _p_ = 0 _._ 2 for all over-range reconstruction experiments.


**Real-World Over-Range Reconstruction with HEROS-GAN.** To benchmark against the current
state of the art, we applied HEROS-GAN[ 15 ] to the same real-world test segment (Fig.6c). While
HEROS-GAN succeeds at reconstructing the overall waveform shape, it systematically underestimates
extreme values—recovering the highlighted peak to only –1287.3°/s—and introduces spurious
oscillations. This behavior underscores its limited capacity for precise peak recovery under severe
clipping.


**Supplementary Data for Table 1.** For completeness, all numerical entries omitted from Table 1
are reported here in Table 7.


**D** **Future Directions**


In this part, we discuss our plans for future work. **Current limitation:** The present **MoE-Gyro**
prototype contains a comparatively large number of parameters; although it runs in real time on a
desktop GPU, such model size still hinders low-cost embedded deployment.


14


Table 7: Full benchmark results corresponding to Table 1.



**Model\Metric**



**Peak Rec. (** _τ_ **= 450** _[◦]_ _/s_ **)** **Allan Variance**
**P_MSE** _↓_ **QN** _↓_ **ARW** _↓_ **BI** _↓_
( _[◦]_ _/s_ ) [2] ( _[◦]_ _/s_ ) ( _[◦]_ _/√h_ ) ( _[◦]_ _/h_ )



RAW 181456 0.0004 0.32 10.03

Matlab 2023 93371 0.0002956 0.31 +5.4%

EMD 118916 0.0000357 0.045 0.32
SG_filter 139175 0.00006 0.044 1.0
CNN 112750 0.00015 0.205 2.07
LSTM_GRU 89847 0.0000767 0.048 0.69
KNN 136533 0.0000573 0.21 5.27
HEROS_GAN 64302 0.0000287 0.155 4.18
IMUDB 80158 0.0000567 0.039 0.63
**MoE-Gyro** **59017** **0.000008** **0.019** **0.157**


**Planned extensions** . (1) Model compression. We will explore how to shrink the network while
preserving—or minimally degrading—its reconstruction and denoising accuracy. (2) Hardware codesign. We plan to fabricate an in-house, low-cost MEMS inertial unit and integrate it end-to-end with
**MoE-Gyro** . This co-design will allow us to demonstrate a complete, cost-effective pipeline—from
sensor to software—that breaks the range-noise trade-off in practical applications.


**E** **Broader Impacts**


This work aims to improve inertial-sensor signal quality through a self-supervised Mixture-ofExperts framework. Enhanced MEMS gyroscopes can benefit a wide spectrum of applications—from
consumer electronics and robotics to autonomous navigation—by enabling higher accuracy without
added hardware complexity. While better motion sensing may indirectly influence downstream
systems (e.g., drones, vehicles, or defense technologies), we do not foresee any immediate, unique
societal risks posed by the algorithm itself beyond those already associated with general improvements
in sensor signal processing.


15


