# GPS-IMU Sensor Fusion for Reliable Autonomous Vehicle Position Estimation

Simegnew Yihunie Alaba
_Department of Electrical and Computer Engineering_
_Mississippi State University_
Starkville, United States



_**Abstract**_ **—Global Positioning System (GPS) navigation pro-**
**vides accurate positioning with global coverage, making it a**
**reliable option in open areas with unobstructed sky views. How-**
**ever, signal degradation may occur in indoor spaces and urban**
**canyons. In contrast, Inertial Measurement Units (IMUs) consist**
**of gyroscopes and accelerometers that offer relative motion**
**information such as acceleration and rotational changes. Unlike**
**GPS, IMUs do not rely on external signals, making them useful in**
**GPS-denied environments. Nonetheless, IMUs suffer from drift**
**over time due to the accumulation of errors while integrating**
**acceleration to determine velocity and position. Therefore, fusing**
**the GPS and IMU is crucial for enhancing the reliability and**
**precision of navigation systems in autonomous vehicles, especially**
**in environments where GPS signals are compromised. To ensure**
**smooth navigation and overcome the limitations of each sensor,**
**the proposed method fuses GPS and IMU data. This sensor**
**fusion uses the Unscented Kalman Filter (UKF) Bayesian filtering**
**technique. The proposed navigation system is designed to be**
**robust, delivering continuous and accurate positioning critical for**
**the safe operation of autonomous vehicles, particularly in GPS-**
**denied environments. This project uses KITTI GNSS and IMU**
**datasets for experimental validation, showing that the GNSS-**
**IMU fusion technique reduces GNSS-only data’s RMSE. The**
**RMSE decreased from 13.214, 13.284, and 13.363 to 4.271,**
**5.275, and 0.224 for the x-axis, y-axis, and z-axis, respectively.**
**The experimental result using UKF shows promising direction**
**in improving autonomous vehicle navigation using GPS and**
**IMU sensor fusion using the best of two sensors in GPS-denied**
**environments.**
_**Index Terms**_ **—Autonomous Vehicle Position, Global Positioning**
**System, Inertial Measurement Unit, Sensor Fusion, Unscented**
**Kalman Filter**


I. I NTRODUCTION


In autonomous vehicle navigation, integrating Global Positioning System (GPS) and Inertial Measurement Units (IMU)
has become a cornerstone for achieving reliable and precise
location tracking, particularly in challenging environments.
While GPS offers extensive coverage and high positional
accuracy in open spaces [1], its performance degrades in
indoor or urban canyons where signals are obstructed [2].
Conversely, IMUs provide valuable motion data independently
of external signals, making them indispensable in GPS-denied
areas. However, the utility of IMUs is hindered by their
susceptibility to drift over time, which accumulates errors in
velocity and position estimations derived from acceleration
data.

To mitigate the limitations of each sensor type, the fusion
of GPS and IMU data emerges as a crucial strategy. This



fusion aims to leverage the global positioning capabilities
of GPS with the relative motion insights from IMUs, thus
enhancing the robustness and accuracy of navigation systems
in autonomous vehicles. The application of advanced Bayesian
filtering techniques, particularly the Extended Kalman Filter
(EKF) [3] and Unscented Kalman Filter (UKF) [4], facilitates the effective integration of these sensors. This approach
ensures seamless and reliable navigation, which is vital for
the reliable operation of autonomous vehicles, especially in
environments where GPS signals are compromised.
This project, which utilizes the KITTI GNSS and IMU
datasets for validation, demonstrates its potential through
realistic experimental setups. These initiatives contribute to the
development of the technological infrastructure for self-driving
vehicles and tackle the crucial safety and efficacy issues facing
the industry at present.


II. L ITERATURE R EVIEW


The GPS and IMU fusion is essential for autonomous

vehicle navigation. It addresses limitations when these sensors
operate independently, particularly in environments with weak
or obstructed GPS signals, such as urban areas or indoor
settings. Given the rising demand for robust autonomous navigation, developing sensor fusion methodologies that ensure
reliable vehicle navigation is essential.
Various filtering techniques are used to integrate GNSS/GPS
and IMU data effectively, with Kalman Filters [5] and their
variants, such as the Extended Kalman Filter (EKF), the Unscented Kalman Filter (UKF), etc. Caron _et al._ [6] introduced
a multisensor Kalman filter technique incorporating contextual
variables to improve GPS/IMU fusion reliability, especially in
signal-distorted environments. Lee _et al._ [7] put forth a sensor
fusion method that combines camera, GPS, and IMU data,
utilizing an EKF to improve state estimation in GPS-denied
scenarios. Different innovative sensor fusion methods push
the boundaries of autonomous vehicle navigation. Suwandi
_et al._ [8] demonstrated a cost-effective approach to vehicle
navigation by focusing on low-cost IMU and GPS sensor
fusion to improve navigation. Atia _et al._ [9] combined MEMS,
IMU, GPS, and road network maps with an EKF and Hidden
Markov model-based map-matching to provide accurate lane
determination without high-precision GNSS technologies. Li
and Xu [10] introduced a method for sensor fusion navigation


in GPS-denied areas. This approach fuses cheaper sensors with
a sliding mode observer and a federated Kalman filter.
Liu _et al._ [11] developed an enhanced Adaptive Kalman
Filter (IAE-AKF) with an attenuation factor to handle noise
effectively, resulting in a 20% improvement in navigation
accuracy. Meng _et al._ [12] employed the Global Navigation
Satellite System (GNSS), IMU, DMI, and LiDAR to counteract inaccuracies caused by GNSS signal jumps and multipath interference in urban settings. Tao _et al._ [13] introduced
a multisensor fusion strategy that integrates GNSS, IMU,
and visual data with global pose graph optimization, yielding
superior results on a ROS simulation platform using the
KITTI dataset. Yusef _et al._ [14] employed a Deep Visual
Inertial Odometry framework to improve accuracy in lowGNSS areas. At the same time, Park [15] used an adaptive
Kalman filter for vehicle position estimation to address GPS
outages, validated in real-world tests. Gruyer and Pollard

[16] enhanced navigation in GPS-denied environments using
proprioceptive sensors with an Interacting Multiple Model
(IMM) filter. Godoy _et al._ [17] proposed a Particle Swarm
Optimization-based filter integrating multiple sensors with
digital maps, showing promise in reducing reliance on GPS
in accurate vehicle testing.
Although these studies propose novel methods to improve
autonomous vehicle navigation, most rely on locally collected
data, making their results difficult to reproduce. This work
addresses this issue using a publicly available dataset, allowing others to improve autonomous driving navigation with
real, representative, and accessible data. This proposed fusion
technique leverages the strengths of both GNSS and IMU
to maintain continuous operation, even if one sensor fails. It
uses the publicly accessible KITTI dataset for testing, allowing
others to replicate and validate the results. By experimenting
with GPS-only and fused data, this study demonstrates the
importance of sensor fusion for safe navigation in real-world
conditions. This approach bridges the gap between theoretical models and practical applications, experimenting with a
dataset representative of the real driving scenario.


III. M ETHOD


Fig. 1 shows the proposed sensor fusion model for autonomous vehicle navigation. It fuses data from two primary
sources: an IMU and a GNSS. With its accelerometers and

gyroscopes, the IMU provides real-time information about
the vehicle’s acceleration and rotational movements, offering
continuous data crucial for navigating without relying on
external signals.
On the other hand, GNSS offers absolute positioning and
velocity data that are essential for high-precision location
tracking when the vehicle has a clear path to the sky. The
UKF fuses the data from the two sensors. Unlike simpler
models, the UKF is uniquely suited for handling the non-linear
nature of the data integration challenge posed by autonomous
vehicle navigation. By processing the high-rate, raw motion
data from the IMU and the periodic positional corrections from
the GNSS, the UKF corrects for any potential drift from the



Fig. 1: The proposed architecture.


IMU and enhances its output, providing an accurate estimate
of the vehicle’s ’Pose’—its precise location and orientation in
space. This pose estimate is not merely a set of coordinates; it’s
a dynamic vehicle’s position representation. It is continuously
updated and adjusted, ensuring the vehicle ’knows’ where it
is, where it needs to go, and how to get there safely. This
is vital for the vehicle’s decision-making processes, such as
navigating complex routes, avoiding obstacles, and ensuring
passenger safety. The proposed work illustrates an equilibrium
between robustness and accuracy, aiming to achieve seamless
navigation functionality, particularly in demanding settings
where GNSS signals may not be dependable or accessible.

The mathematical representation of the system comprises
process and measurement models. The dynamic connection
between the states at two consecutive time steps is managed
by the process truth model, which can be defined as follows:


_x_ _t_ = _f_ ( _x_ _t−_ 1 _, u_ _t−_ 1 ) + _w_ _t−_ 1 _,_ (1)


where _x_ _t_ indicates the estimated state after an interval _σ_,
derived from the preceding state vector _x_ _t−_ 1 . The variable
_u_ _t−_ 1 functions as the input to the state space equations, and
_w_ _t−_ 1 reflects the noise affecting the process.

Data from the GNSS receiver introduce errors in the ve
hicle’s position, velocity, and orientation estimates. When a
measurement from the GNSS receiver is obtained, the GNSS
measurement model is defined as:


_y_ _p_ = _p_ + _n_ _p_ _,_ (2)


where _p ∈_ ( _x, y, z_ ), _n_ _p_ represents the measurement noise
and _y_ _p_ = _C_ _E_ _[G]_ [[] _[x]_ _[e]_ _[, y]_ _[e]_ _[, z]_ _[e]_ []][. Here, (] _[x]_ _[e]_ _[, y]_ _[e]_ _[, z]_ _[e]_ [) are Earth-centered]
Earth-fixed (ECEF) rectangular coordinates [12], [19].







_y_ _[e]_

_z_ _[e]_







 (( _RR_ _NN_ + + _h h_ ) cos) cos _ϕ ϕ_ cos sin _λ λ_

� _R_ _N_ (1 _−_ _e_ [2] ) + _h_ � sin _ϕ_







(3)




 _x_ _[e]_

_y_ _[e]_

_z_ _[e]_





 =



where


_R_ _N_ is the normal radius


_h_ is the ellipsoidal height


_λ_ is the longitude


_ϕ_ is the latitude


_e_ is the eccentricity _._


The normal radius _R_ _N_ is defined as: _R_ _N_ = ~~_√_~~ 1 _−ea_ [2] sin [2] _ϕ_ [.]



Then, the update process continues:


¯
_x_ _t|t−_ 1 = _f_ ( _x_ _t−_ 1 _, u_ _t−_ 1 )



_x_ _[−]_ _t_ [=]


_P_ _t_ _[−]_ [=]



2 _n_
� _W_ _i_ _[m]_ _[x]_ [¯] _i,t|t−_ 1


_i_ =0


2 _n_
� _W_ _i_ _[c]_ � _x_ ¯ _i,t|t−_ 1 _−_ _x_ _[−]_ _t_ �� _x_ ¯ _i,t|t−_ 1 _−_ _x_ _[−]_ _t_ � _⊤_ + _Q,_


_i_ =0



(6)



The Earth’s eccentricity can also be expressed as _e_ =
~~�~~



_a_ [2] _−b_ [2]



where ¯ _x_ _t_ represents the predicted mean, _P_ [¯] _t_ represents the
predicted covariance, and _W_ _i_ _[m]_ and _W_ _i_ _[c]_ [are the weights for]
the mean and covariance, respectively, associated with the i-th
sigma point, as defined by [4]:


_κ_
_W_ 0 _[m]_ [=]
_n_ + _κ_


_κ_
_W_ 0 _[c]_ [=]
_n_ + _κ_ [+ (1] _[ −]_ _[α]_ [2] [ +] _[ β]_ [)]


1
_W_ _i_ _[m]_ = _W_ _i_ _[c]_ [=] _i_ = 1 _,_ 2 _, . . .,_ 2 _n_
2( _n_ + _κ_ ) _[,]_


where _β_ is a parameter that allows for incorporating prior
knowledge about the distribution of the state vector **x** . In
Gaussian distributions, the optimal value for _β_ is 2 [4].
**Measurement Step:** This step involves calculating the
sigma points followed by the measurement update. The sigma
points calculation is:


_X_ ¯ _t_ = � _x_ ¯ _t_ _x_ ¯ _t_ _±_ _[√]_ _n_ + _κP_ _t_ � (7)


where ¯ _x_ _t_ represents the predicted mean from the time update
at time _t_ and _P_ [¯] _t_ denotes the predicted covariance. Then, the
measurement update is done using the following equation.


_Y_ ¯ _t_ = _g_ ( ¯ _X_ _t_ ) (8)



_a_ [2]
where _a_ = 6 _,_ 378 _,_ 137 m and _b_ = 6 _,_ 356 _,_ 752 _._ 3142 m are
the semi-major and semi-minor axes of the Earth’s ellipsoid,
respectively. The transition matrix from the ECEF frame to
the global frame _G_, denoted by _C_ _E_ _[G]_ [, is given as [19]:]



 _._ (4)





_C_ _E_ _[G]_ [=]



 _−_ sin _−_ sin _λ_ cos _ϕ_ _ϕ_ _−_ sin _−_ cos _λ_ sin _ϕ_ _ϕ_ cos0 _λ_

 _−_ cos _λ_ cos _ϕ_ _−_ cos _λ_ sin _ϕ_ _−_ sin _λ_



The covariance matrix of the GNSS measurement noise is **R** =

Σ GNSS .

The UKF is an advanced method for fusing GNSS and
IMU data. Compared to the classic KF, it offers more accurate
estimations of the state of a process that evolves non-linearly.
The KF method relies on linear dynamics and measurements,
whereas the UKF can handle non-linear systems without
linearization. The UKF’s strength lies in its efficient use of
the unscented transform. This involves selecting a minimal
set of sample points around the mean, accurately capturing
the state distribution’s mean and covariance. These points are
then propagated through the non-linear system, preserving the
distribution’s properties more effectively than linearization and
enhancing the UKF’s robustness. In contrast, the standard KF
may not be accurate enough when dealing with significant
non-linearity, as it relies on linear approximations. In contrast,
the UKF approach assumes that estimating a probability
distribution is simpler than estimating a non-linear function.
Generally, the UKF implementation involves the prediction
and measurement steps.

**Prediction Step:** At time step _t_, the prediction step involves
calculating the sigma points and updating the process by
predicting mean and covariance [19]. The sigma points can
be calculated using:



_y_ ¯ _t_ =



2 _n_
� _W_ _i_ _[m]_ _[Y]_ [¯] _[i,t]_ (9)


_i_ =0



_P_ _y_ _t_ =



2 _n_
� _W_ _i_ _[c]_ [( ¯] _[Y]_ _[i,t]_ _[−]_ _[y]_ [¯] _[t]_ [)] _[ ·]_ [ ( ¯] _[Y]_ _[i,t]_ _[−]_ _[y]_ [¯] _[t]_ [)] _[T]_ [ +] _[ R]_ (10)


_i_ =0



_P_ _x_ _t_ _y_ _t_ =



2 _n_
� _W_ _i_ _[c]_ [( ¯] _[X]_ _[i,t]_ _[−]_ _[x]_ [¯] _[t]_ [)] _[ ·]_ [ ( ¯] _[Y]_ _[i,t]_ _[−]_ _[y]_ [¯] _[t]_ [)] _[T]_ (11)


_i_ =0



¯
_X_ _t−_ 1 = � _x_ _t−_ 1 _x_ _t−_ 1 _±_ �



( _n_ + _κ_ ) _P_ _t−_ 1 � _,_ (5)



_K_ _t_ = _P_ _x_ _t_ _y_ _t_ _·_ ( _P_ _y_ _t_ ) _[−]_ [1] (12)


_v_ _t_ = _y_ _p,t_ _−_ _y_ ¯ _t_ (13)


_x_ _t_ = ¯ _x_ _t_ + _K_ _t_ _· v_ _t_ (14)


_P_ _t_ = _P_ _t_ _[−]_ _[−]_ _[K]_ _[t]_ _[·][ P]_ _[y]_ _t_ _[·][ K]_ _t_ _[T]_ (15)


where _Y_ [¯] _t_ signifies the sigma points projected through the
measurement function _h_, while ¯ _y_ _t_ represents the predicted
measurement based on weighted sigma points. The predicted



where ¯ _x_ _t−_ 1 denotes the sigma points of the state vector **x** at the
prior time step _t_ _−_ 1. The state vector **x** has a dimension of _n_ .
The spread of the sigma points is defined by _κ_ = _α_ [2] ( _n_ + _γ_ ) _−n_ .
The parameter _α_ determines the spread, while _γ_ is a secondary
scaling factor, typically set to one. The initial condition must
be known _x_ 0 _∼_ _N_ ( _x_ 0 _, P_ 0 ).


Fig. 2: Position errors in x, y, and z-coordinates using GNSS only.



measurement covariance _P_ _y_ _t_ and the state-measurement crosscovariance matrix _P_ _x_ _t_ _y_ _t_ are also derived from this process. _K_ _t_
denotes the Kalman gain, _v_ _t_ is the innovation term, and _x_ _t_ and
_P_ _t_ reflect the updated state and covariance at time _t_ .
Overall, the UKF is a more robust approach in situations
where the Kalman Filter’s linear assumptions are insufficient,
especially in autonomous navigation and robotics, where accuracy in the face of non-linear behaviors is crucial.


IV. E XPERIMENTS

The experiment uses the KITTI GNSS and IMU dataset

[18]. The GNSS and IMU data are essential for tasks that
involve vehicle pose estimation and tracking in autonomous
driving. The GNSS provides geographic location information,
while the IMU provides insights into the vehicle’s movements
through space, such as acceleration and orientation. Together,
these data sets enable high-precision tracking and navigation,
which is crucial in developing and testing autonomous systems. The dataset provides a dynamic and challenging realworld environment, with traffic scenarios recorded to reflect
various driving conditions. It has served as a benchmark
for many studies focusing on improving the accuracy and
robustness of autonomous driving technologies.
The experiment is conducted using a GNSS observation
frequency of 1 Hz. Similarly, the IMU uses a 0.01 rad/s gyroscope, a 0.05 m/s [2] accelerometer, a 0.000001 rad/s [2] gyroscope
bias, and a 0.0001 m/s [3] accelerometer bias. The position and
velocity estimation using UKF results are demonstrated in the
experiments. The UKF is a variant of the Kalman Filter that is
more suitable for dealing with non-linear systems. It captures
the mean and covariance of the probability distribution of the
system state by passing carefully chosen sample points through
the non-linearities. The errors observed in the x, y, and z
coordinates, as depicted in Figures 2 and 3, serve as indicators
of tracking accuracy over time. The GNSS-only results show
the errors are larger than the fusion of GNSS and IMU data
for navigation, as shown in Fig. 2. The fusion figure, Fig. 3,
for the x and y directions reveals the GNSS frequency that
provides the most precise location estimates, characterized by
a lower mean error and minimal fluctuations around zero. On
the other hand, the z-coordinate aims to identify the frequency
that yields the smallest and most uniform error, highlighting a
better tracking performance in three-dimensional space despite



the inherent higher precision of GPS in the horizontal plane.
Overall, these errors are essential in assessing the effectiveness
of the fusion system.
Fig. 4 demonstrating the position estimation in the xy-plane
illustrates that the UKF estimated track closely aligns with the
GPS measurements. The degree of tightness of the UKF track
around the GPS measurements indicates the accuracy of the
filter’s performance. Similarly, the RMSE across the X, Y, and
Z axes are calculated to show the fusion model’s robustness.

The RMSE using GNSS-only shows 13.214, 13.284, and
13.363 for the X, Y, and Z axes, respectively. The fusion of
the GNSS and IMU reduces the RMSE to 4.271, 5.275, and
0.224 for the x, y, and z axes, respectively, as shown in Table
I. For real-time implementation, certain challenges, such as
sensor calibration and synchronization, need to be considered
when incorporating sensor fusion technology into autonomous
vehicles. Developing strong software algorithms, ensuring
adequate hardware infrastructure, and conducting extensive
testing in real-world scenarios are essential to addressing
these challenges. This is crucial to guaranteeing autonomous
vehicles’ accuracy, reliability, and safety.


TABLE I: Comparison of RMSE for GNSS-only and GNSSIMU fusion.


RMSE
Method
X-axis Y-axis Z-axis


GNSS 13.214 13.284 13.363

GNSS-IMU 4.271 5.275 0.224


V. C ONCLUSION


The fusion model leveraging the UKF employs the KITTI
dataset for validation, combining real-time IMU data with
GNSS absolute positioning to refine autonomous vehicle navigation. The IMU’s real-time motion data and the GNSS’s
absolute positioning capabilities are integrated to estimate
precise and reliable poses. This is crucial to helping individuals
remain aware of their surroundings and perform important
navigation-related tasks, especially when faced with obstacles
that might interfere with GNSS signals. This work highlights
the UKF’s superiority in processing nonlinear sensor outputs
and reinforces the fusion model’s potential for enhancing
the reliability and efficiency of autonomous vehicle systems.


Fig. 3: Position errors in x, y, and z-coordinates using fusion of GNSS and IMU.


Fig. 4: Positions in meters at GNSS frequency of 1 Hz.



Sensor fusion typically combines data from multiple sensors
to improve navigation. It is also crucial during practical
applications for maintaining position and orientation estimates
if one of the sensors fails, allowing the navigation process
to continue without interruption. Adding LiDAR or radar
sensors to autonomous vehicle navigation systems can improve
the precision and dependability of position and orientation
estimates by enhancing GNSS and IMU fusion. LiDAR’s highresolution 3D mapping capabilities enable accurate obstacle
detection and localization, while radar’s long-range detection
and weather-resilience qualities enhance overall robustness.
Fusing these sensors with GNSS and IMU can enhance the
navigation system’s reliability, ensuring continuous operation
even during sensor failure. This leads to improved safety
and navigation accuracy across various environments and
conditions. Additionally, carefully developing existing filtering
techniques, such as EKF, or customizing existing filters may



improve performance.


R EFERENCES


[1] D. M. Bevly, ”Global positioning system (GPS): A low-cost velocity
sensor for correcting inertial sensor errors on ground vehicles,” _J. Dyn._
_Sys., Meas., Control_, vol. 126, pp. 255–264, 2004.

[2] X. Li, W. Chen, and C. Chan, ”A reliable multisensor fusion strategy
for land vehicle positioning using low-cost sensors,” _Proceedings of_
_the Institution of Mechanical Engineers, Part D: Journal of Automobile_
_Engineering_, vol. 228, pp. 1375–1397.

[3] H. W. Sorenson, ”Kalman filtering techniques,” _Advances in control_
_systems_, vol. 3, pp. 219–292, 1966.

[4] E. A. Wan and R. Van Der Merwe, ”The unscented Kalman filter for
nonlinear estimation,” _Proceedings of the IEEE 2000 adaptive systems_
_for signal processing, communications, and control symposium (Cat. No._
_00EX373)_, pp. 153–158, 2000.

[5] R. E. Kalman and others, ”Contributions to the theory of optimal
control,” _Bol. soc. mat. mexicana_, vol. 5, pp. 102–119, 1960.

[6] F. Caron, E. Duflos, D. Pomorski, and P. Vanheeghe, ”GPS/IMU data
fusion using multisensor Kalman filtering: introduction of contextual
aspects,” _Information fusion_, vol. 7, pp. 221–230, 2006.


[7] Y. Lee, J. Yoon, H. Yang, C. Kim, and D. Lee, ”Camera-GPS-IMU sensor fusion for autonomous flying,” _2016 Eighth International Conference_
_on Ubiquitous and Future Networks (ICUFN)_, pp. 85–88, 2016.

[8] B. Suwandi,T. Kitasuka, and M. Aritsugi, ”Low-cost IMU and GPS
fusion strategy for apron vehicle positioning,” _TENCON 2017-2017_
_IEEE Region 10 Conference_, pp. 449–454, 2017.

[9] M. M. Atia, A. R. Hilal, C. Stellings, E. Hartwell, J. Toonstra, W. B.
Miners, and O. A. Basir,”A low-cost lane-determination system using
GNSS/IMU fusion and HMM-based multistage map matching,” _IEEE_
_Transactions on Intelligent Transportation Systems_, vol. 18, pp. 3027–
3037, 2017.

[10] X. Li and Q. Xu, ”A reliable fusion positioning strategy for land
vehicles in GPS-denied environments based on low-cost sensors,” _IEEE_
_Transactions on Industrial Electronics_, vol. 64, pp. 3205–3215, 2016.

[11] Y. Liu, X. Fan, C. Lv, J. Wu, L. Li, and D. Ding, ”An innovative
information fusion method with adaptive Kalman filter for integrated
INS/GPS navigation of autonomous vehicles,” _Mechanical systems and_
_signal processing_, vol. 100, pp. 605–616, 2018.

[12] X. Meng, H. Wang, and B. Liu, ”A robust vehicle localization approach
based on gnss/imu/dmi/lidar sensor fusion for autonomous vehicles,”
_Sensors_, vol. 17, pp. 2140, 2017.

[13] X. Tao, B. Zhu, S. Xuan, J. Zhao, H. Jiang, J. Du, and W. Deng,
”A multi-sensor fusion positioning strategy for intelligent vehicles
using global pose graph optimization,” _IEEE transactions on vehicular_
_technology_, vol. 71, pp. 2614–2627, 2021.

[14] A. Yusefi, A. Durdu, F. Bozkaya, S. Tı˘glıo˘glu, A. Yılmaz, and C. Sungur,
”A Generalizable D-VIO and Its Fusion with GNSS/IMU for Improved
Autonomous Vehicle Localization,” _IEEE Transactions on Intelligent_
_Vehicles_, 2023.

[15] G. Park, ”Optimal vehicle position estimation using adaptive unscented
Kalman filter based on sensor fusion,” _Mechatronics_, vol. 99, pp. 103144,
2024.

[16] D. Gruyer and E. Pollard, ”Credibilistic IMM likelihood updating
applied to outdoor vehicle robust ego-localization,” _14th International_
_Conference on Information Fusion_, pp. 1–8, 2011.

[17] J. Godoy, D. Gruyer, A. Lambert, and J. Villagra, ”Development of an
particle swarm algorithm for vehicle localization,” _2012 IEEE Intelligent_
_Vehicles Symposium_, pp. 1114–1119, 2012.

[18] A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, ”Vision meets robotics:
The kitti dataset,” _The International Journal of Robotics Research_,
vol. 32, pp. 1231–1237, 2013.

[19] A. Noureldin, T. B. Karamat, and J. Georgy, ”Fundamentals of inertial
navigation, satellite-based positioning and their integration,” _Springer_
_Science & Business Media_ 2012.


